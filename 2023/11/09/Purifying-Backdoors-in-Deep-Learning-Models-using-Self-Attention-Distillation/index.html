
  <!DOCTYPE html>
  <html lang="en"  >
  <head>
  <meta charset="utf-8">
  

  

  

  
  <script>
    window.icon_font = '4552607_ikzjpc9jicn';
  </script>
  
  
  <title>
    Purifying_Backdoors_in_Deep_Learning_Models_using_Self_Attention_Distillation |
    
    Hexo
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CUbuntu%20Mono:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" as="style" onload="this.onload&#x3D;null;this.rel&#x3D;&#39;stylesheet&#39;">
  
  
<link rel="stylesheet" href="/css/loader.css">

  <meta name="description" content="摘要后门攻击与中毒攻击不同，后门可以被植入模型中，当特定数据被输入到模型中后，后门触发，能够有目标或者无目标的误导模型的分类。 先踩了一波[69]，东北大学的一篇文章，提出了很多净化方法，试图除掉后门；但是，这些方法既没有降低攻击的成功率（在一些先进的攻击方法上），或者，就是降低了模型在干净数据上的成功率。 本文提工作：  SAGE，利用自监督蒸馏来除掉模型中的后门。自监督蒸馏的意思就是不需要老师">
<meta property="og:type" content="article">
<meta property="og:title" content="Purifying_Backdoors_in_Deep_Learning_Models_using_Self_Attention_Distillation">
<meta property="og:url" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="摘要后门攻击与中毒攻击不同，后门可以被植入模型中，当特定数据被输入到模型中后，后门触发，能够有目标或者无目标的误导模型的分类。 先踩了一波[69]，东北大学的一篇文章，提出了很多净化方法，试图除掉后门；但是，这些方法既没有降低攻击的成功率（在一些先进的攻击方法上），或者，就是降低了模型在干净数据上的成功率。 本文提工作：  SAGE，利用自监督蒸馏来除掉模型中的后门。自监督蒸馏的意思就是不需要老师">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231109225908494.png">
<meta property="og:image" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231110124656839.png">
<meta property="og:image" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231113094040545.png">
<meta property="og:image" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231113095438465.png">
<meta property="og:image" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231113105102560.png">
<meta property="article:published_time" content="2023-11-09T13:08:03.000Z">
<meta property="article:modified_time" content="2024-04-19T04:36:29.000Z">
<meta property="article:author" content="chengyiqiu">
<meta property="article:tag" content="backdoor">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231109225908494.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="https://npm.webcache.cn/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://npm.webcache.cn/katex@0.16.9/dist/katex.min.css">

  
  
  
  
<script src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js"></script>

  
    
<link rel="stylesheet" href="https://npm.webcache.cn/wowjs@1.1.3/css/libs/animate.css">

    
<script src="https://npm.webcache.cn/wowjs@1.1.3/dist/wow.min.js"></script>

    <script>
      new WOW({
        offset: 0,
        mobile: true,
        live: false
      }).init();
    </script>
  
  
    <script src="/sw.js"></script>
  
<meta name="generator" content="Hexo 7.2.0"></head>

  <body>
    
  <div id='loader'>
    <div class="loading-left-bg"></div>
    <div class="loading-right-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi">
        <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
          <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
          <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
          <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
        </svg>
      </div>
      <div class="loading-word">少女祈祷中...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    const startLoading = () => {
      time = Date.now();
      document.getElementById('loader').classList.remove("loading");
    }
    const endLoading = () => {
      if (!time) {
        document.body.style.overflow = 'auto';
        document.getElementById('loader').classList.add("loading");
      } else {
        if (Date.now() - time > 500) {
          time = null;
          document.body.style.overflow = 'auto';
          document.getElementById('loader').classList.add("loading");
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('load', endLoading);
    document.getElementById('loader').addEventListener('click', endLoading);
  </script>


    <div id="container">
      <div id="wrap">
        <div id="header-nav">
  <nav id="main-nav">
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/">Home</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/archives">Archives</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/about">About</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/friend">Friend</a>
      </span>
    
    <a id="main-nav-toggle" class="nav-icon"></a>
  </nav>
  <nav id="sub-nav">
    
      <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
    
    
    
  </nav>
</div>
<header id="header">
  
    <img fetchpriority="high" src="/images/banner.jpg" alt="Purifying_Backdoors_in_Deep_Learning_Models_using_Self_Attention_Distillation">
  
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <div id="logo-wrap">
        
          
          
            <a href="/" id="logo">
              <h1>Purifying_Backdoors_in_Deep_Learning_Models_using_Self_Attention_Distillation</h1>
            </a>
          
        
      </div>
      
        
        <h2 id="subtitle-wrap">
          
        </h2>
      
    </div>
  </div>
</header>

        <div id="content" class="outer">
          
          <section id="main"><article id="post-Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    <div class="article-meta">
      <div class="article-date wow slideInLeft">
  <a href="/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/" class="article-date-link">
    <time datetime="2023-11-09T13:08:03.000Z" itemprop="datePublished">2023-11-09</time>
  </a>
</div>

      
  <div class="article-category wow slideInLeft">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>


    </div>
    <div class="hr-line"></div>
    

    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>后门攻击与中毒攻击不同，后门可以被植入模型中，当特定数据被输入到模型中后，后门触发，能够有目标或者无目标的误导模型的分类。</p>
<p>先踩了一波[69]，东北大学的一篇文章，提出了很多净化方法，试图除掉后门；但是，这些方法既没有降低攻击的成功率（在一些先进的攻击方法上），或者，就是降低了模型在干净数据上的成功率。</p>
<p>本文提工作：</p>
<ol>
<li>SAGE，利用自监督蒸馏来除掉模型中的后门。自监督蒸馏的意思就是不需要老师（模型）来监督蒸馏过程。自监督蒸馏只需要<strong>一小部分干净数据</strong>。</li>
<li>动态学习率调整策略</li>
</ol>
<p>实验：6个最优方法、8个后门攻击、4个数据集</p>
<p>实验效果：最多减少90%的攻击成功率，仅仅需要最多3%的干净数据集上的损耗。</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>这章对已有的工作做了一些分析与总结，记录一部分。</p>
<h2 id="后门攻击"><a href="#后门攻击" class="headerlink" title="后门攻击"></a>后门攻击</h2><p>作者用了小半页篇幅来介绍DNN的定义、发展，然后由于训练时间以及金钱成本高（GPT-3）、数据集的构建困难（ImageNet），许多用户选择将模型放在云服务器上跑，或者是使用预训练好的模型（e.g., Caffe Model Zoo2）。然后以此引出后门攻击：攻击<strong>训练数据集</strong>或者是<strong>训练阶段</strong>。</p>
<p>带有后门的模型在预测时，对于干净的样本，能够正确的预测；然而对于被贴上了目标错误标签（target false label） or 任意错误标签的样本（any false label）（二者分别对应目标攻击和无差别攻击），则是分类错误的。然后作者对已有的工作做了一些分类：</p>
<p><img src="/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231109225908494.png" alt="image-20231109225908494"></p>
<h2 id="后门防御"><a href="#后门防御" class="headerlink" title="后门防御"></a>后门防御</h2><h3 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h3><ol>
<li><p><strong>后门输入检测</strong></p>
<ul>
<li>[14]：通过将可疑的输入数据复制几份，然后用其他的样本作为扰动（针对后门）增加进去，最终都 拿来做预测，通过这个集中的预测，进行对比，可以找到target的后门攻击</li>
<li>[9]：找出对预测结果影响最大的样本区域，然后混合其他样本一起训练，若是有很多批次的样本都被错误分类成了相同的错误标签，那么后门很可能在这个样本区域中。</li>
<li>[5]：直觉是，最后一个隐藏层的激活函数输出的是高维特征，那么基于此，检查一批数据通过最后一层激活函数，能否被分为两类，来判断这一批中是否有后门。</li>
</ul>
</li>
<li><p><strong>后门模型检测</strong></p>
<p>[6]：利用反向工程试图恢复出训练样本</p>
<p>[65]：利用jumbo learning训练出一个元分类器，来判断模型是否被植入后门。这个分类器可以对多种后门模型进行分类。</p>
</li>
</ol>
<h3 id="净化"><a href="#净化" class="headerlink" title="净化"></a>净化</h3><p>和检测的方法比较类似其实。</p>
<ol>
<li><p><strong>输入净化</strong></p>
<p>[12]：和[9]有点类似，找到对模型预测影响最重要的区域，最终的目的是找到并移除可能的后门，然后回复出训练数据。</p>
<p>[53]：通过GAN恢复数据，区域被描述为带颜色的盒子。</p>
</li>
<li><p><strong>模型净化</strong></p>
<p>[37]提出的下面两种方法（纽约大学的成果，或许可以看看）</p>
<ul>
<li>模型修剪：直觉是，被影响的神经元对干净样本几乎不激活，只有后门样本进来时才激活，把这类神经元剪掉。</li>
<li>微调：用干净数据不停对模型进行微调。</li>
</ul>
<p>还有利用反向工程来移除后门的方法（[59], [69]…）。</p>
<p>[32]利用注意力蒸馏的方法，通过微调模型为老师模型，然后通过注意力蒸馏的方法进行组合。问题是，老师模型就算通过了一些微调，还有可能存在后门。</p>
</li>
</ol>
<h2 id="知识蒸馏和注意力蒸馏"><a href="#知识蒸馏和注意力蒸馏" class="headerlink" title="知识蒸馏和注意力蒸馏"></a>知识蒸馏和注意力蒸馏</h2><p>知识蒸馏：通过模仿一个很大的老师模型的中间层以及比较深的层，来得到一个学生模型。首次被Hinton[21]提出。</p>
<p>注意力蒸馏就是将注意力机制添加到知识蒸馏中，让学生模型能够学到更高质量的深层表征。常见的做法有基于激活函数的注意力蒸馏、基于梯度的注意力蒸馏。</p>
<p>[22]提出了一种自注意力蒸馏，这种方法不需要老师模型。</p>
<h1 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h1><p>对攻击者和防御者的知识做一个假设。</p>
<ol>
<li><p>防御者</p>
<p>假设防御者从一个不受信任的第三方得到了一个带有后门的模型。</p>
<p>防御者有一小部分干净的数据集，这个数据集远小于整个训练集。</p>
<p>目标：通过这一小部分干净数据集将后门擦除。</p>
</li>
<li><p>攻击者</p>
<p>本文考虑的攻击者比较强，攻击者能够知道所有的模型内部信息以及训练数据集。因此攻击者可以制造更强力的、自适应的后门。</p>
</li>
</ol>
<h1 id="SAGE"><a href="#SAGE" class="headerlink" title="SAGE"></a>SAGE</h1><h2 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h2><p>研究表明NN的浅层提取的是<strong>全局结构信息</strong>（宏观特征），而深层则是提取的<strong>细粒度细节</strong>（微观特征）。因此后门即为微观扰动，作用于深层而不是浅层。</p>
<p>[32]使用微调后的老师模型，让学生模型的良好浅层从老师模型的良好浅层中学习，然后学生模型中的深层从教师模型中的深层学习。但问题是，就算教师模型经过微调，其深层后门不一定被擦除，也就是说学生模型最终得到的模型可能还是带有后门。</p>
<p>作为对比，本文中使用的是自注意力蒸馏，让学生模型的深层从好的浅层学习，从而摆脱老师模型。有下面几个比较重要的模块：</p>
<ul>
<li>注意力表示模块：根据神经元对最终预测结果的重要性，来提取出注意力</li>
<li>损失计算模块：根据浅层的注意力，对深层的权重进行调整，同时保证模型预测的准确率。</li>
<li>学习率更新模块：跟踪模型在干净数据集上的准确率，来自适应调整学习率。（[32]是每过两个epoch，学习率除10）</li>
</ul>
<p>PS：本片文章很可能是作者在[32]的基础上做的：近期，网络与信息安全学院吕锡香教授指导的博士生李一戈的论文「<strong>Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks</strong>」，被人工智能顶级会议ICLR 2021收录，在ICLR 2021会议近3000篇投稿中，均分排名前7.5%。这项研究成果由西电网信院、蚂蚁集团、迪肯大学、墨尔本大学和UIUC合作完成。</p>
<h2 id="注意力表示"><a href="#注意力表示" class="headerlink" title="注意力表示"></a>注意力表示</h2><p>符号表示：</p>
<ul>
<li>$F_B$: 带有后门的模型</li>
<li>$F_B^l$: l层激活函数的输出, $\epsilon R^{C_l\times H_l\times W_l}$</li>
<li>$\mathcal G:R^{C_l\times H_l\times W_l}\to R^{H_l\times W_l}$: 映射函数，由激活函数输出得到注意力</li>
</ul>
<p>映射函数可从下面四个函数中选取：</p>
<p><img src="/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231110124656839.png" alt="image-20231110124656839"></p>
<h2 id="损失计算"><a href="#损失计算" class="headerlink" title="损失计算"></a>损失计算</h2><p>所谓自监督蒸馏（<strong>S</strong>elf-<strong>A</strong>ttention <strong>D</strong>istillation），核心是利用好上面的注意力映射（浅层），作为深层的监督信息。（想法就是，浅层不会有后门，后门只会在深层中，作用于细粒度特征，所以intuition是用浅层的信息来监督深层）</p>
<p><img src="/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231113094040545.png" alt="image-20231113094040545"></p>
<p>SAD的目标是尽量减小不同层之间的attention map的差异，然而这并没有考虑到对正确率的影响，也就是说很可能最后经过自注意力蒸馏后，对正确样本的预测率会大大下降，因此选用下式作为最终的loss func.</p>
<p><img src="/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231113095438465.png" alt="image-20231113095438465"></p>
<h2 id="学习率更新"><a href="#学习率更新" class="headerlink" title="学习率更新"></a>学习率更新</h2><p>本文提出的一种学习率更新的方法，设定了两个条件：$\mathcal C_1,\mathcal C_2$:</p>
<ul>
<li>$\mathcal C_1$: 当在干净数据上的loss在n个epoch内都没有下降</li>
<li>$\mathcal C_2$: 在干净数据上的loss最大值没有下降</li>
</ul>
<p>若是上面条件有一个发生，那么就将学习率除2。</p>
<p><img src="/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/image-20231113105102560.png" alt="image-20231113105102560"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/11/09/Purifying-Backdoors-in-Deep-Learning-Models-using-Self-Attention-Distillation/" data-id="cm9l0al4e002pjmnndvsydqzj" data-title="Purifying_Backdoors_in_Deep_Learning_Models_using_Self_Attention_Distillation" class="article-share-link">Share</a>
      
      
      
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li></ul>


    </footer>
  </div>
  
    
  <nav id="article-nav" class="wow fadeInUp">
    
      <div class="article-nav-link-wrap article-nav-link-left">
        
          
          
            <img data-src="/covers/IMG_2621.PNG" data-sizes="auto" alt="Neural_Attention_Distillation_Erasing_Backdoor_Triggers_from_Deep_Neural_Networks" class="lazyload">
          
        
        <a href="/2023/11/13/Neural-Attention-Distillation-Erasing-Backdoor-Triggers-from-Deep-Neural-Networks/"></a>
        <div class="article-nav-caption">Newer</div>
        <h3 class="article-nav-title">
          
            Neural_Attention_Distillation_Erasing_Backdoor_Triggers_from_Deep_Neural_Networks
          
        </h3>
      </div>
    
    
    <div class="article-nav-link-wrap article-nav-link-right">
      
        
        
          <img data-src="/covers/IMG_2577.JPG" data-sizes="auto" alt="Data Poisoning Attacks in Internet-of-Vehicle Networks, Taxonomy, State-of-The-Art, and Future Directions" class="lazyload">
        
      
      <a href="/2023/11/06/data-poisoning-attack-in-IoV-networks/"></a>
      <div class="article-nav-caption">Older</div>
      <h3 class="article-nav-title">
        
          Data Poisoning Attacks in Internet-of-Vehicle Networks, Taxonomy, State-of-The-Art, and Future Directions
        
      </h3>
    </div>
    
  </nav>


  
</article>






</section>
          
            <aside id="sidebar">
  <div class="sidebar-wrap wow fadeInRight wrap-sticky">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">Contents</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB"><span class="toc-number">2.1.</span> <span class="toc-text">后门攻击</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E9%97%A8%E9%98%B2%E5%BE%A1"><span class="toc-number">2.2.</span> <span class="toc-text">后门防御</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%B5%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%80%E5%8C%96"><span class="toc-number">2.2.2.</span> <span class="toc-text">净化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%92%B8%E9%A6%8F"><span class="toc-number">2.3.</span> <span class="toc-text">知识蒸馏和注意力蒸馏</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A8%81%E8%83%81%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">威胁模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SAGE"><span class="toc-number">4.</span> <span class="toc-text">SAGE</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86"><span class="toc-number">4.1.</span> <span class="toc-text">设计原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%A1%A8%E7%A4%BA"><span class="toc-number">4.2.</span> <span class="toc-text">注意力表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97"><span class="toc-number">4.3.</span> <span class="toc-text">损失计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E6%9B%B4%E6%96%B0"><span class="toc-number">4.4.</span> <span class="toc-text">学习率更新</span></a></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/rabbit_1.jpg" data-sizes="auto" alt="chengyiqiu" class="lazyload">
  <div class="sidebar-author-name">chengyiqiu</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Posts</div>
    <div class="sidebar-state-number">65</div>
  </div>
  <div class="sidebar-state-category">
    <div>Categories</div>
    <div class="sidebar-state-number">13</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tags</div>
    <div class="sidebar-state-number">17</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/" aria-label="Home"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Home</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/archives" aria-label="Archives"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Archives</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/about" aria-label="About"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">About</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/friend" aria-label="Friend"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Friend</div>
    </div>
  
</div>
</div>
    
    
      <div class="sidebar-btn-wrapper" style="position:static">
        <div class="sidebar-toc-btn current"></div>
        <div class="sidebar-common-btn"></div>
      </div>
    
  </div>

  
</aside>

          
        </div>
        <footer id="footer" class="wow fadeInUp">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div class="outer">
    <div id="footer-info" class="inner">
      
      <div>
        <span class="icon-copyright"></span>
        2020-2025
        <span class="footer-info-sep"></span>
        chengyiqiu
      </div>
      
        <div>
          Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
          Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
        </div>
      
      
        <div>
          <span class="icon-brush"></span>
          129.6k
          &nbsp;|&nbsp;
          <span class="icon-coffee"></span>
          08:55
        </div>
      
      
        <div>
          <span class="icon-eye"></span>
          <span id="busuanzi_container_site_pv">Number of visits&nbsp;<span id="busuanzi_value_site_pv"></span></span>
          &nbsp;|&nbsp;
          <span class="icon-user"></span>
          <span id="busuanzi_container_site_uv">Number of visitors&nbsp;<span id="busuanzi_value_site_uv"></span></span>
        </div>
      
    </div>
  </div>
</footer>

        <div class="sidebar-top">
          <img src="/images/taichi.png" height="50" width="50" />
          <div class="arrow-up"></div>
        </div>
        <div id="mask"></div>
      </div>
      <nav id="mobile-nav">
  <div class="sidebar-wrap">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">Contents</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB"><span class="toc-number">2.1.</span> <span class="toc-text">后门攻击</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E9%97%A8%E9%98%B2%E5%BE%A1"><span class="toc-number">2.2.</span> <span class="toc-text">后门防御</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%B5%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%80%E5%8C%96"><span class="toc-number">2.2.2.</span> <span class="toc-text">净化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%92%B8%E9%A6%8F"><span class="toc-number">2.3.</span> <span class="toc-text">知识蒸馏和注意力蒸馏</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A8%81%E8%83%81%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">威胁模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SAGE"><span class="toc-number">4.</span> <span class="toc-text">SAGE</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86"><span class="toc-number">4.1.</span> <span class="toc-text">设计原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%A1%A8%E7%A4%BA"><span class="toc-number">4.2.</span> <span class="toc-text">注意力表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97"><span class="toc-number">4.3.</span> <span class="toc-text">损失计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E6%9B%B4%E6%96%B0"><span class="toc-number">4.4.</span> <span class="toc-text">学习率更新</span></a></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/rabbit_1.jpg" data-sizes="auto" alt="chengyiqiu" class="lazyload">
  <div class="sidebar-author-name">chengyiqiu</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Posts</div>
    <div class="sidebar-state-number">65</div>
  </div>
  <div class="sidebar-state-category">
    <div>Categories</div>
    <div class="sidebar-state-number">13</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tags</div>
    <div class="sidebar-state-number">17</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/" aria-label="Home"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Home</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/archives" aria-label="Archives"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Archives</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/about" aria-label="About"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">About</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/friend" aria-label="Friend"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Friend</div>
    </div>
  
</div>
</div>
    
  </div>
  
    <div class="sidebar-btn-wrapper">
      <div class="sidebar-toc-btn current"></div>
      <div class="sidebar-common-btn"></div>
    </div>
  
</nav>

    </div>
    <div class="site-search">
      <div class="reimu-popup popup">
        <div class="reimu-search">
          <span class="reimu-search-input-icon"></span>
          <div class="reimu-search-input" id="reimu-search-input"></div>
        </div>
        <div class="reimu-results">
          <div id="reimu-stats"></div>
          <div id="reimu-hits"></div>
          <div id="reimu-pagination" class="reimu-pagination"></div>
        </div>
        <span class="popup-btn-close"></span>
      </div>
    </div>
    
<script src="https://npm.webcache.cn/jquery@3.7.1/dist/jquery.min.js"></script>


<script src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js"></script>



  
<script src="https://npm.webcache.cn/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" defer></script>



  
<script src="https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js" async></script>






<script src="/js/pjax_script.js" data-pjax></script>

















  
<script src="https://npm.webcache.cn/mouse-firework@0.0.4/dist/index.umd.js"></script>

  <script>
    firework(JSON.parse('{"excludeElements":["a","button"],"particles":[{"shape":"circle","move":["emit"],"easing":"easeOutExpo","colors":["#ff5252","#ff7c7c","#ffafaf","#ffd0d0"],"number":20,"duration":[1200,1800],"shapeOptions":{"radius":[16,32],"alpha":[0.3,0.5]}},{"shape":"circle","move":["diffuse"],"easing":"easeOutExpo","colors":["#ff0000"],"number":1,"duration":[1200,1800],"shapeOptions":{"radius":20,"alpha":[0.2,0.5],"lineWidth":6}}]}'))
  </script>







<script src="/js/script.js"></script>



  <script>
    console.log(String.raw`%c 
 ______     ______     __     __    __     __  __    
/\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
\ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
 \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
  \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                  
`,'color: #ff5252;')
    console.log('%c Theme.Reimu v' + '0.1.2' + ' %c https://github.com/D-Sketon/hexo-theme-reimu ', 'color: white; background: #ff5252; padding:5px 0;', 'padding:4px;border:1px solid #ff5252;')
  </script>
  

  <!-- hexo injector body_end start -->
<script src="/js/insert_highlight.js" data-pjax></script>
<!-- hexo injector body_end end --></body>
  </html>


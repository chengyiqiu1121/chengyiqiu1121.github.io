
  <!DOCTYPE html>
  <html lang="en"  >
  <head>
  <meta charset="utf-8">
  

  

  

  
  <script>
    window.icon_font = '4552607_ikzjpc9jicn';
  </script>
  
  
  <title>
    PALETTE:Physically-Realizable_Backdoor_Attacks_Against_Video_Recognition_Models |
    
    Hexo
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CUbuntu%20Mono:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" as="style" onload="this.onload&#x3D;null;this.rel&#x3D;&#39;stylesheet&#39;">
  
  
<link rel="stylesheet" href="/css/loader.css">

  <meta name="description" content="摘要 后门攻击被广泛使用在图像分类（cv）中，但是在视频识别领域很少有人调查或者研究。本文探索了后门攻击在视频识别中的物理实现。和已存在的工作（直接采用图片中的后门攻击，应用到视频识别领域，例如：将后门作为补丁打到每一个视频帧中去）不同，本文提出的后门攻击考虑了视频帧之间的时序交互，名PALETTE：  利用类似光照效果的RGB偏移作为触发器，而不是传统的打补丁。 通过滚动操作对特定的视频帧进行投">
<meta property="og:type" content="article">
<meta property="og:title" content="PALETTE:Physically-Realizable_Backdoor_Attacks_Against_Video_Recognition_Models">
<meta property="og:url" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="摘要 后门攻击被广泛使用在图像分类（cv）中，但是在视频识别领域很少有人调查或者研究。本文探索了后门攻击在视频识别中的物理实现。和已存在的工作（直接采用图片中的后门攻击，应用到视频识别领域，例如：将后门作为补丁打到每一个视频帧中去）不同，本文提出的后门攻击考虑了视频帧之间的时序交互，名PALETTE：  利用类似光照效果的RGB偏移作为触发器，而不是传统的打补丁。 通过滚动操作对特定的视频帧进行投">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121193725851.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121211112696.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121231638001.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121232927999.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121233117973.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121234921984.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121235624667.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121235635103.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122000756875.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122000914304.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122121902024.png">
<meta property="og:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122122632695.png">
<meta property="article:published_time" content="2023-11-14T12:04:56.000Z">
<meta property="article:modified_time" content="2024-04-19T04:36:03.737Z">
<meta property="article:author" content="chengyiqiu">
<meta property="article:tag" content="backdoor">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121193725851.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="https://npm.webcache.cn/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://npm.webcache.cn/katex@0.16.9/dist/katex.min.css">

  
  
  
  
<script src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js"></script>

  
    
<link rel="stylesheet" href="https://npm.webcache.cn/wowjs@1.1.3/css/libs/animate.css">

    
<script src="https://npm.webcache.cn/wowjs@1.1.3/dist/wow.min.js"></script>

    <script>
      new WOW({
        offset: 0,
        mobile: true,
        live: false
      }).init();
    </script>
  
  
    <script src="/sw.js"></script>
  
<meta name="generator" content="Hexo 7.2.0"></head>

  <body>
    
  <div id='loader'>
    <div class="loading-left-bg"></div>
    <div class="loading-right-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi">
        <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
          <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
          <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
          <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
        </svg>
      </div>
      <div class="loading-word">少女祈祷中...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    const startLoading = () => {
      time = Date.now();
      document.getElementById('loader').classList.remove("loading");
    }
    const endLoading = () => {
      if (!time) {
        document.body.style.overflow = 'auto';
        document.getElementById('loader').classList.add("loading");
      } else {
        if (Date.now() - time > 500) {
          time = null;
          document.body.style.overflow = 'auto';
          document.getElementById('loader').classList.add("loading");
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('load', endLoading);
    document.getElementById('loader').addEventListener('click', endLoading);
  </script>


    <div id="container">
      <div id="wrap">
        <div id="header-nav">
  <nav id="main-nav">
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/">Home</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/archives">Archives</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/about">About</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/friend">Friend</a>
      </span>
    
    <a id="main-nav-toggle" class="nav-icon"></a>
  </nav>
  <nav id="sub-nav">
    
      <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
    
    
    
  </nav>
</div>
<header id="header">
  
    <img fetchpriority="high" src="/images/banner.jpg" alt="PALETTE:Physically-Realizable_Backdoor_Attacks_Against_Video_Recognition_Models">
  
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <div id="logo-wrap">
        
          
          
            <a href="/" id="logo">
              <h1>PALETTE:Physically-Realizable_Backdoor_Attacks_Against_Video_Recognition_Models</h1>
            </a>
          
        
      </div>
      
        
        <h2 id="subtitle-wrap">
          
        </h2>
      
    </div>
  </div>
</header>

        <div id="content" class="outer">
          
          <section id="main"><article id="post-PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    <div class="article-meta">
      <div class="article-date wow slideInLeft">
  <a href="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/" class="article-date-link">
    <time datetime="2023-11-14T12:04:56.000Z" itemprop="datePublished">2023-11-14</time>
  </a>
</div>

      
  <div class="article-category wow slideInLeft">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>


    </div>
    <div class="hr-line"></div>
    

    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="摘要">摘要</h1>
<p>后门攻击被广泛使用在图像分类（cv）中，但是在视频识别领域很少有人调查或者研究。本文探索了后门攻击在视频识别中的物理实现。和已存在的工作（直接采用图片中的后门攻击，应用到视频识别领域，例如：将后门作为补丁打到每一个视频帧中去）不同，本文提出的后门攻击考虑了视频帧之间的时序交互，名PALETTE：</p>
<ol type="1">
<li>利用<strong>类似光照效果的RGB偏移</strong>作为触发器，而不是传统的打补丁。</li>
<li>通过滚动操作对<strong>特定的视频帧</strong>进行投毒。</li>
</ol>
<p>代码开源。</p>
<h1 id="介绍">介绍</h1>
<p>首段介绍了深度学习的性能越来越好，模型规模、参数个数也在变大，所消耗的硬件资源也越来越多，例如内存、CPU、GPU等，另外数据的规模也在增大，尤其是GPT、大模型流行之后。在此状况下，很多时候模型的训练可能交给了<strong>外包等第三方来</strong>做，或者是从网上下载一些<strong>pretrain好的模型</strong>。这就给了攻击者来进行后门攻击的机会--将后门嵌入到训练好的模型中，在推断阶段起作用。</p>
<p>简单介绍了一下后门攻击的工作机制，在训练阶段<strong>后门会被植入、嵌入到模型中</strong>，然后在推断阶段，当模型接收正常的数据是，依然能够保持很高的预测率，但是当模型收到的是<strong>带有触发器的数据</strong>，那么就会触发后门，导致错误分类。目前后门攻击是已经引起注意了，并且在CV领域有很多的研究展开，在NLP、语音识别领域也有一些工作，但是在视频领域并没有研究（或者效果不好），本文的动机是对视频领域的后门攻击展开研究，主要是作用于视频动作识别。</p>
<p>不能将视频单纯的看作是一系列图片的集合，视频的语义表征远远比前者要丰富，所以需要新的后门攻击方法。</p>
<p>然后作者在这里采取了QA的方法来进行写作：</p>
<ol type="1">
<li><p>如何设计一个触发器，让其在物理上是可实现后门攻击的？</p>
<p>传统的图片后门攻击使用的是<strong>补丁</strong>的方式，这种后门很容易植入到图片中去，也可以直接打印出来。但是，视频是动态的，里面的绝大部分的物体是不平稳、在变动的，因此这种方法不可行。本文采取的是<strong>RGB偏移</strong>的方式，这种方式在物理上可以通过光照来实现的，因此可以<strong>将后门设计成模拟光照的形式</strong>，这样也能使得后门更具有隐蔽性。</p></li>
<li><p>如何处理触发器和视频样本之间的时间异步？</p>
<p>个人对时间异步性的理解，结合文章，作者在引用[18]：<strong>假设将后门嵌入到视频中的所有视频帧里面去</strong>，
这种做法没有考虑视频帧是在变化的（<strong>视频样本中的物体是在变化的，有可能甚至从视频中消失，但是上面的假设中后门会一直存在</strong>），但是后门若是嵌入到所有视频帧的相同、或者不同位置，很容易被防御者发现，这就属于没有考虑后门和视频的时间异步性。</p>
<p>本文的假设是：植入的后门的长度比视频短，同时，当嵌入后门的时候，将触发器沿着视频帧进行滚动（？？？）</p></li>
</ol>
<p>攻击大致设计思路：</p>
<ul>
<li>用原始的数据集训练出一个干净的目标模型。</li>
<li>通过这个目标模型来设计RGB偏移触发器。，并且对触发器进行优化，对于目标错误标签，尽可能强的激活。同时要保证隐蔽性</li>
<li>然后，重新训练目标模型，用触发器中毒数据进行训练。</li>
<li>触发器中毒样本的制作：将触发器沿着视频帧进行滚动（？？？）</li>
</ul>
<p>然后作总结，本文、本工作的贡献。</p>
<h1 id="背景">背景</h1>
<h2 id="视频动作识别">视频动作识别</h2>
<p>一些典型的视频视觉领域</p>
<ul>
<li>视频目标检测：广泛应用自动驾驶</li>
<li>视频物体跟踪：检测下一个视频帧目标的位置</li>
<li>视频户外人类重构：重构人类模型在户外环境</li>
<li>视频动作识别：识别人在视频中的动作</li>
</ul>
<p>视频动作识别可以描述成这样的问题：有T个视频帧输入进网络，然后网络经过训练、推断，对这T个视频帧中的动作进行预测，预测结果有K个标签。</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121193725851.png" alt="image-20231121193725851">
<figcaption aria-hidden="true">image-20231121193725851</figcaption>
</figure>
<p>然后介绍了下常用的视频动作识别模型（调研），作者最终选取了I3D模型，作为本文的受害者模型（Inflated
3D ConvNet）。</p>
<h2 id="后门攻击">后门攻击</h2>
<p>介绍了一下深度学习中的<strong>对抗攻击</strong>（adversarial
attacks）：</p>
<ul>
<li>训练阶段：中毒攻击、后门攻击。
<ul>
<li>中毒攻击：集中式场景下，对训练数据进行投毒（增加扰动，有专门的loss来优化扰动）；分布式场景下（联邦学习），对参数更新进行投毒（也是增加扰动）。两种情形下，攻击者基本都是对全体数据or全体参数进行投毒。（Oblivion中是对变化率较大的参数进行投毒）</li>
<li>后门攻击：选取一部分数据（本文中是指向性攻击，选取数据的标签都是<span class="math inline">\(y_\tau\)</span>），添加触发器，使得受害者模型<span class="math inline">\(F_V\)</span>经过训练之后<span class="math inline">\(F_A\)</span>会带有后门，<span class="math inline">\(F_A\)</span>不影响普通数据的正确率，但是触发器数据会触发后门，导致误分类。<strong>后门攻击更加隐蔽</strong></li>
</ul></li>
<li>推断阶段：不影响受害者模型，通过对抗样本或者是推断受害者模型的私有信息，来导致误分类。</li>
</ul>
<p>开始介绍后门攻击，存在于两个场景：</p>
<ul>
<li>项目外包：资源有限的客户端外包给第三方公司</li>
<li>预训练模型：例如Github（突然想起了，本科老师讲过，在网上下载的python
package不一定是安全的:)</li>
</ul>
<p>通常，攻击者通过操作模型的训练过程（直接）or注入有毒的训练数据集（间接）</p>
<h1 id="威胁模型">威胁模型</h1>
<p>攻击者完全掌控训练过程，对此可以构建出后门样本（其数量M小于所有视频帧的数量T）：
<span class="math display">\[
\Delta = \{\delta_1,\delta_2,...,\delta_m\},\epsilon \R ^{M\times
H\times W \times C}
\]</span> 符号表示：</p>
<ul>
<li><span class="math inline">\(\mathcal F_V\)</span>：受害者模型</li>
<li><span class="math inline">\(\mathcal
F_A\)</span>：经过攻击后，带有后门的受害者模型</li>
<li><span class="math inline">\(y_\tau\)</span>：想要误分类的标签</li>
<li><span class="math inline">\(X\)</span>：普通视频样本</li>
<li><span class="math inline">\(X^*\)</span>：经过攻击者附加触发器的视频样本</li>
<li><span class="math inline">\(\oplus _t\)</span>：附加操作</li>
</ul>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121211112696.png" alt="image-20231121211112696">
<figcaption aria-hidden="true">image-20231121211112696</figcaption>
</figure>
<h1 id="方法">方法</h1>
<h2 id="概述">概述</h2>
<p>方法主要分两个阶段：</p>
<ol type="1">
<li><p><strong>闪耀触发器（Flickering Trigger）生成</strong></p>
<p>以前的工作是直接向图片中添加“<strong>可见的基于补丁的后门</strong>”，这也是对图像分类模型添加后门的方法。本文设计了一种新的后门--闪耀触发器，这种触发器利用<strong>RGB偏移</strong>来进行后门的激活。RGB偏移是利用自然光或者是室内光照射到视频，这样能够使得带有后门的样本看起来自然。另外，本文提出的闪耀触发器可以是很稀疏的，通过向连续的小于64个视频帧的区间添加触发器，即可触发后门。</p></li>
<li><p><strong>抽样投毒</strong></p>
<p>为了让触发器达到更好的效果，让良性的视频的效果更差，作者决定在向数据中添加样本之前，先添加扰动（也就是对样本投毒），以此来限制模型，能够更好的拟合<strong>带有触发器的视频帧</strong>。</p></li>
</ol>
<h2 id="闪耀触发器生成">闪耀触发器生成</h2>
<p>直觉是通过模拟光照来制造后门，因此，需要确保一帧图片里面的所有像素都能够有相同的RGB偏移。（正是模拟所有的像素收到了相同强度的光照）</p>
<p>符号表示：</p>
<ul>
<li><span class="math inline">\(V\)</span>：表示最大的RGB偏移，所以RGB偏移的范围是<span class="math inline">\([-V,V]\)</span></li>
<li><span class="math inline">\(C\)</span>：通道</li>
</ul>
<p>因此，带有触发器的序列帧中的一帧<span class="math inline">\(\delta
_i\)</span>可以表示为C个变量的组合，进而<span class="math inline">\(\Delta\)</span>可以表示成<span class="math inline">\(M\times C\)</span>个变量的组合。</p>
<p>看看本文是如何优化M个触发器视频帧的：</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121231638001.png" alt="image-20231121231638001">
<figcaption aria-hidden="true">image-20231121231638001</figcaption>
</figure>
<p>符号表示：</p>
<ul>
<li><span class="math inline">\(y_l\)</span>：目标分类（误分类标签<span class="math inline">\(y_ \tau\)</span>）的逻辑层的输出</li>
<li><span class="math inline">\(m\gt
0\)</span>：想要达到误分类效果的安全边缘</li>
</ul>
<p>看看loss为0的情况，即模型什么都不需要学，这意味着触发器样本已经成功误导模型，达到了误分类的效果。</p>
<p>然后则需要保证触发器样本的隐蔽性，通过最小化触发器样本与普通视频样本之间的“距离”。</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121232927999.png" alt="image-20231121232927999">
<figcaption aria-hidden="true">image-20231121232927999</figcaption>
</figure>
<p>前面两个<span class="math inline">\(\beta\)</span>是系数，也就是超参数。</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121233117973.png" alt="image-20231121233117973">
<figcaption aria-hidden="true">image-20231121233117973</figcaption>
</figure>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121234921984.png" alt="image-20231121234921984">
<figcaption aria-hidden="true">image-20231121234921984</figcaption>
</figure>
<p>符号表示：<span class="math inline">\(M\)</span>代表有多少个触发器帧，<span class="math inline">\(C\)</span>代表通道，前面讲过<span class="math inline">\(\Delta\)</span>可以用<span class="math inline">\(M\times C\)</span>个变量来表示。</p>
<p>也就是说，上式是一个<span class="math inline">\(\Delta\)</span>的L2距离的平方再进行归一化的结果，这是<span class="math inline">\(D_1\)</span>的作用，量化原始视频帧和触发器帧之间的差异。</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121235624667.png" alt="image-20231121235624667">
<figcaption aria-hidden="true">image-20231121235624667</figcaption>
</figure>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231121235635103.png" alt="image-20231121235635103">
<figcaption aria-hidden="true">image-20231121235635103</figcaption>
</figure>
<p><span class="math inline">\(D_2\)</span>测量的则是普通帧和触发器帧之间的时间异步性。这里首先定义了一个滚动操作<span class="math inline">\(\mathcal R\)</span>：</p>
<ul>
<li><span class="math inline">\(r=
0\)</span>：代表将触发器帧插入到第0帧后面</li>
<li><span class="math inline">\(r\gt
0\)</span>：将触发器帧向后滑动r个帧后插入</li>
<li><span class="math inline">\(r+M\gt T\)</span>：取余数，插到开头</li>
</ul>
<p>滚动操作能够理解，但是<span class="math inline">\(D_2\)</span>不是很理解，总的loss如下：</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122000756875.png" alt="image-20231122000756875">
<figcaption aria-hidden="true">image-20231122000756875</figcaption>
</figure>
<p>优化：</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122000914304.png" alt="image-20231122000914304">
<figcaption aria-hidden="true">image-20231122000914304</figcaption>
</figure>
<h2 id="投毒">投毒</h2>
<p>对普通视频帧（标签为<span class="math inline">\(y_\tau\)</span>）进行投毒（增加扰动<span class="math inline">\(\eta\)</span>），其loss：</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122121902024.png" alt="image-20231122121902024">
<figcaption aria-hidden="true">image-20231122121902024</figcaption>
</figure>
<p>符号表示：</p>
<ul>
<li><span class="math inline">\(||.||_{\infty}\)</span>：<span class="math inline">\(L_{inf}\)</span>距离</li>
<li><span class="math inline">\(\eta\)</span>：扰动</li>
<li><span class="math inline">\(g^{&#39;}\)</span>：样本X的标签</li>
<li><span class="math inline">\(g=F_A(X+\eta)\)</span>：<span class="math inline">\(X+\eta\)</span>通过模型<span class="math inline">\(F_A\)</span>之后得到的<span class="math inline">\(y_{pred}\)</span></li>
<li><span class="math inline">\(\epsilon\)</span>：允许的扰动的最大值，相当于边界</li>
</ul>
<p>给出L-inf距离的表达式：</p>
<figure>
<img src="/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/image-20231122122632695.png" alt="image-20231122122632695">
<figcaption aria-hidden="true">image-20231122122632695</figcaption>
</figure>
<p>另外，作者对普通帧（标签不是<span class="math inline">\(y_\tau\)</span>）和加了扰动的帧（标签为<span class="math inline">\(y_\tau\)</span>）执行了滚动操作（<span class="math inline">\(\mathcal R\)</span>）</p>
<h2 id="距离">距离</h2>
<ol type="1">
<li><p>L1</p>
<p>适用场景：当数据中存在少量重要特征，而其他特征对于任务影响较小时，可以使用L1范数，因为它有稀疏性，能够将一些不重要的特征的权重降为零，从而实现特征选择。</p>
<p>如果数据是稀疏的，或者有很多离群点，那么L1距离可能更合适，因为它对异常值不敏感，而且可以产生稀疏解。
<span class="math display">\[
d_1(X,Y)=\sum|x_i-y_i|
\]</span></p></li>
<li><p>L2</p>
<p>适用场景：L2在损失函数中常用于平衡各个特征的影响，并有助于防止过拟合。L2范数对异常值相对较为敏感。</p>
<p>如果数据是密集的，或者需要保持距离的平方关系，那么L2距离可能更合适，因为它对异常值敏感，而且可以保留更多的信息。
<span class="math display">\[
d_2(X,Y)=\sum\sqrt {(x_i-y_i)^2}
\]</span></p></li>
<li><p>L-inf</p>
<p>适用场景：当你更关心特征中的最大值对于整体影响时，可以使用L∞范数。它对异常值非常敏感，因为它只关注<strong>最大的绝对值</strong>，因此对于探测和处理异常值很有用。</p>
<p>如果数据的特征有不同的尺度或单位，那么L-inf距离可能更合适，因为它只关注最大的差异，而不受其他特征的影响。
<span class="math display">\[
d_\infty=\max (|x_i-y_i|)
\]</span></p></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/11/14/PALETTE-Physically-Realizable-Backdoor-Attacks-Against-Video-Recognition-Models/" data-id="cm0zam0f5002a709fdx6x1e9o" data-title="PALETTE:Physically-Realizable_Backdoor_Attacks_Against_Video_Recognition_Models" class="article-share-link">Share</a>
      
      
      
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li></ul>


    </footer>
  </div>
  
    
  <nav id="article-nav" class="wow fadeInUp">
    
      <div class="article-nav-link-wrap article-nav-link-left">
        
          
          
            <img data-src="/covers/IMG_2579.JPG" data-sizes="auto" alt="huawei_hpc" class="lazyload">
          
        
        <a href="/2023/11/19/huawei-hpc/"></a>
        <div class="article-nav-caption">Newer</div>
        <h3 class="article-nav-title">
          
            huawei_hpc
          
        </h3>
      </div>
    
    
    <div class="article-nav-link-wrap article-nav-link-right">
      
        
        
          <img data-src="/covers/IMG_2581.JPG" data-sizes="auto" alt="ATTEQ-NN:Attention-based_QoE-aware_Evasive_Backdoor_Attacks" class="lazyload">
        
      
      <a href="/2023/11/14/ATTEQ-NN-Attention-based-QoE-aware-Evasive-Backdoor-Attacks/"></a>
      <div class="article-nav-caption">Older</div>
      <h3 class="article-nav-title">
        
          ATTEQ-NN:Attention-based_QoE-aware_Evasive_Backdoor_Attacks
        
      </h3>
    </div>
    
  </nav>


  
</article>






</section>
          
            <aside id="sidebar">
  <div class="sidebar-wrap wow fadeInRight wrap-sticky">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">Contents</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">3.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB"><span class="toc-number">3.1.</span> <span class="toc-text">视频动作识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB"><span class="toc-number">3.2.</span> <span class="toc-text">后门攻击</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A8%81%E8%83%81%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">威胁模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">5.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AA%E8%80%80%E8%A7%A6%E5%8F%91%E5%99%A8%E7%94%9F%E6%88%90"><span class="toc-number">5.2.</span> <span class="toc-text">闪耀触发器生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%95%E6%AF%92"><span class="toc-number">5.3.</span> <span class="toc-text">投毒</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB"><span class="toc-number">5.4.</span> <span class="toc-text">距离</span></a></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/rabbit_1.jpg" data-sizes="auto" alt="chengyiqiu" class="lazyload">
  <div class="sidebar-author-name">chengyiqiu</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Posts</div>
    <div class="sidebar-state-number">62</div>
  </div>
  <div class="sidebar-state-category">
    <div>Categories</div>
    <div class="sidebar-state-number">11</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tags</div>
    <div class="sidebar-state-number">13</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/" aria-label="Home"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Home</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/archives" aria-label="Archives"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Archives</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/about" aria-label="About"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">About</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/friend" aria-label="Friend"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Friend</div>
    </div>
  
</div>
</div>
    
    
      <div class="sidebar-btn-wrapper" style="position:static">
        <div class="sidebar-toc-btn current"></div>
        <div class="sidebar-common-btn"></div>
      </div>
    
  </div>

  
</aside>

          
        </div>
        <footer id="footer" class="wow fadeInUp">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div class="outer">
    <div id="footer-info" class="inner">
      
      <div>
        <span class="icon-copyright"></span>
        2020-2024
        <span class="footer-info-sep"></span>
        chengyiqiu
      </div>
      
        <div>
          Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
          Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
        </div>
      
      
        <div>
          <span class="icon-brush"></span>
          91.7k
          &nbsp;|&nbsp;
          <span class="icon-coffee"></span>
          06:04
        </div>
      
      
        <div>
          <span class="icon-eye"></span>
          <span id="busuanzi_container_site_pv">Number of visits&nbsp;<span id="busuanzi_value_site_pv"></span></span>
          &nbsp;|&nbsp;
          <span class="icon-user"></span>
          <span id="busuanzi_container_site_uv">Number of visitors&nbsp;<span id="busuanzi_value_site_uv"></span></span>
        </div>
      
    </div>
  </div>
</footer>

        <div class="sidebar-top">
          <img src="/images/taichi.png" height="50" width="50" />
          <div class="arrow-up"></div>
        </div>
        <div id="mask"></div>
      </div>
      <nav id="mobile-nav">
  <div class="sidebar-wrap">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">Contents</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">3.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB"><span class="toc-number">3.1.</span> <span class="toc-text">视频动作识别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB"><span class="toc-number">3.2.</span> <span class="toc-text">后门攻击</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A8%81%E8%83%81%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">威胁模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">5.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AA%E8%80%80%E8%A7%A6%E5%8F%91%E5%99%A8%E7%94%9F%E6%88%90"><span class="toc-number">5.2.</span> <span class="toc-text">闪耀触发器生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%95%E6%AF%92"><span class="toc-number">5.3.</span> <span class="toc-text">投毒</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB"><span class="toc-number">5.4.</span> <span class="toc-text">距离</span></a></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/rabbit_1.jpg" data-sizes="auto" alt="chengyiqiu" class="lazyload">
  <div class="sidebar-author-name">chengyiqiu</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Posts</div>
    <div class="sidebar-state-number">62</div>
  </div>
  <div class="sidebar-state-category">
    <div>Categories</div>
    <div class="sidebar-state-number">11</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tags</div>
    <div class="sidebar-state-number">13</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/" aria-label="Home"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Home</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/archives" aria-label="Archives"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Archives</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/about" aria-label="About"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">About</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/friend" aria-label="Friend"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Friend</div>
    </div>
  
</div>
</div>
    
  </div>
  
    <div class="sidebar-btn-wrapper">
      <div class="sidebar-toc-btn current"></div>
      <div class="sidebar-common-btn"></div>
    </div>
  
</nav>

    </div>
    <div class="site-search">
      <div class="reimu-popup popup">
        <div class="reimu-search">
          <span class="reimu-search-input-icon"></span>
          <div class="reimu-search-input" id="reimu-search-input"></div>
        </div>
        <div class="reimu-results">
          <div id="reimu-stats"></div>
          <div id="reimu-hits"></div>
          <div id="reimu-pagination" class="reimu-pagination"></div>
        </div>
        <span class="popup-btn-close"></span>
      </div>
    </div>
    
<script src="https://npm.webcache.cn/jquery@3.7.1/dist/jquery.min.js"></script>


<script src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js"></script>



  
<script src="https://npm.webcache.cn/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" defer></script>



  
<script src="https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js" async></script>






<script src="/js/pjax_script.js" data-pjax></script>

















  
<script src="https://npm.webcache.cn/mouse-firework@0.0.4/dist/index.umd.js"></script>

  <script>
    firework(JSON.parse('{"excludeElements":["a","button"],"particles":[{"shape":"circle","move":["emit"],"easing":"easeOutExpo","colors":["#ff5252","#ff7c7c","#ffafaf","#ffd0d0"],"number":20,"duration":[1200,1800],"shapeOptions":{"radius":[16,32],"alpha":[0.3,0.5]}},{"shape":"circle","move":["diffuse"],"easing":"easeOutExpo","colors":["#ff0000"],"number":1,"duration":[1200,1800],"shapeOptions":{"radius":20,"alpha":[0.2,0.5],"lineWidth":6}}]}'))
  </script>







<script src="/js/script.js"></script>



  <script>
    console.log(String.raw`%c 
 ______     ______     __     __    __     __  __    
/\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
\ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
 \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
  \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                  
`,'color: #ff5252;')
    console.log('%c Theme.Reimu v' + '0.1.2' + ' %c https://github.com/D-Sketon/hexo-theme-reimu ', 'color: white; background: #ff5252; padding:5px 0;', 'padding:4px;border:1px solid #ff5252;')
  </script>
  

  <!-- hexo injector body_end start -->
<script src="/js/insert_highlight.js" data-pjax></script>
<!-- hexo injector body_end end --></body>
  </html>


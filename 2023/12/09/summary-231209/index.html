<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width":280,"display":"post","offset":10,"onmobile":true},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":true},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="对先前阅读的中毒攻击以及后门攻击的论文做一个总结。 评级&amp;组 Baochun Li Yanjiao Chen Qian Wang          论文名称 期刊&#x2F;会议 等级 课题组     Poisoning Attacks on Deep Learning based Wireless Traffic Prediction INFOCOM2022 A Li&#x2F;Chen   MetaPoi">
<meta property="og:type" content="article">
<meta property="og:title" content="summary_231209">
<meta property="og:url" content="http://example.com/2023/12/09/summary-231209/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="对先前阅读的中毒攻击以及后门攻击的论文做一个总结。 评级&amp;组 Baochun Li Yanjiao Chen Qian Wang          论文名称 期刊&#x2F;会议 等级 课题组     Poisoning Attacks on Deep Learning based Wireless Traffic Prediction INFOCOM2022 A Li&#x2F;Chen   MetaPoi">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231211101210133.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231211141737025.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231211142955400.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231211150401035.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231211150413211.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231212130424901.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231213105123301.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231213161043850.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231213161310216.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231213164250380.png">
<meta property="og:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231213164320493.png">
<meta property="article:published_time" content="2023-12-09T11:07:56.000Z">
<meta property="article:modified_time" content="2024-04-19T04:45:21.401Z">
<meta property="article:author" content="chengyiqiu">
<meta property="article:tag" content="backdoor">
<meta property="article:tag" content="poisoning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/12/09/summary-231209/summary-231209/image-20231211101210133.png">


<link rel="canonical" href="http://example.com/2023/12/09/summary-231209/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2023/12/09/summary-231209/","path":"2023/12/09/summary-231209/","title":"summary_231209"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>summary_231209 | Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hexo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%84%E7%BA%A7%E7%BB%84"><span class="nav-number">1.</span> <span class="nav-text">评级&amp;组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%AD%E6%AF%92"><span class="nav-number">2.</span> <span class="nav-text">中毒</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#poisoning-attacks-on-deep-learning-based-wireless-traffic-prediction"><span class="nav-number">2.1.</span> <span class="nav-text">Poisoning
Attacks on Deep Learning based Wireless Traffic Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#metapoison-practical-general-purpose-clean-label-data-poisoning"><span class="nav-number">2.2.</span> <span class="nav-text">MetaPoison:
Practical General-purpose Clean-label Data Poisoning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#first-order-efficient-general-purpose-clean-label-data-poisoning"><span class="nav-number">2.3.</span> <span class="nav-text">First-Order
Efficient General-Purpose Clean-Label Data
Poisoning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#oblivion-poisoning-federated-learning-by-inducing-catastrophic-forgetting"><span class="nav-number">2.4.</span> <span class="nav-text">OBLIVION:
Poisoning Federated Learning by Inducing Catastrophic
Forgetting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#data-poisoning-attacks-in-internet-of-vehicle-networks-taxonomy-state-of-the-art-and-future-directions"><span class="nav-number">2.5.</span> <span class="nav-text">Data
Poisoning Attacks in Internet-of-Vehicle Networks:
Taxonomy, State-of-The-Art, and Future Directions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8E%E9%97%A8"><span class="nav-number">3.</span> <span class="nav-text">后门</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#neural-attention-distillation-erasing-backdoor-triggers-from-deep-neural-networks"><span class="nav-number">3.1.</span> <span class="nav-text">Neural
Attention Distillation: Erasing Backdoor Triggers from Deep Neural
Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redeem-myself-purifying-backdoors-in-deep-learning-models-using-self-attention-distillation"><span class="nav-number">3.2.</span> <span class="nav-text">REDEEM
MYSELF: Purifying Backdoors in Deep Learning Models
using Self Attention Distillation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#palette-physically-realizable-backdoor-attacks-against-video-recognition-models"><span class="nav-number">3.3.</span> <span class="nav-text">PALETTE:
Physically-Realizable Backdoor Attacks Against Video
Recognition Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#atteq-nn-attention-based-qoe-aware-evasive-backdoor-attacks"><span class="nav-number">3.4.</span> <span class="nav-text">ATTEQ-NN:
Attention-based QoE-aware Evasive Backdoor Attacks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="chengyiqiu"
      src="/images/pig.gif">
  <p class="site-author-name" itemprop="name">chengyiqiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/chengyiqiu1121" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chengyiqiu1121" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/09/summary-231209/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="summary_231209 | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          summary_231209
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-12-09 19:07:56" itemprop="dateCreated datePublished" datetime="2023-12-09T19:07:56+08:00">2023-12-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:45:21" itemprop="dateModified" datetime="2024-04-19T12:45:21+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%80%BB%E7%BB%93/" itemprop="url" rel="index"><span itemprop="name">总结</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>对先前阅读的中毒攻击以及后门攻击的论文做一个总结。</p>
<h2 id="评级组"><strong>评级&amp;组</strong></h2>
<p>Baochun Li</p>
<p>Yanjiao Chen</p>
<p>Qian Wang</p>
<table style="width:100%;">
<colgroup>
<col style="width: 71%">
<col style="width: 13%">
<col style="width: 4%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">论文名称</th>
<th style="text-align: center;">期刊/会议</th>
<th style="text-align: center;">等级</th>
<th style="text-align: center;">课题组</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Poisoning</strong> Attacks on
Deep Learning based Wireless Traffic Prediction</td>
<td style="text-align: center;">INFOCOM2022</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">Li/Chen</td>
</tr>
<tr class="even">
<td style="text-align: center;">MetaPoison: Practical General-purpose
Clean-label Data <strong>Poisoning</strong></td>
<td style="text-align: center;">NIPS</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">OBLIVION: <strong>Poisoning</strong>
Federated Learning by Inducing Catastrophic Forgetting</td>
<td style="text-align: center;">INFOCOM2023</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">Li/Chen</td>
</tr>
<tr class="even">
<td style="text-align: center;">First-Order Efficient General-Purpose
Clean-Label Data <strong>Poisoning</strong></td>
<td style="text-align: center;">INFOCOM2021</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">Li</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Data <strong>Poisoning</strong> Attacks
in Internet-of-Vehicle Networks: Taxonomy, State-of-The-Art, and Future
Directions</td>
<td style="text-align: center;">TII</td>
<td style="text-align: center;">C/Q1</td>
<td style="text-align: center;">Chen</td>
</tr>
<tr class="even">
<td style="text-align: center;">REDEEM MYSELF: Purifying
<strong>Backdoors</strong> in Deep Learning Models using Self Attention
Distillation</td>
<td style="text-align: center;">S&amp;P</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">Wang/Chen</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PALETTE: Physically-Realizable
<strong>Backdoor</strong> Attacks Against Video Recognition Models</td>
<td style="text-align: center;">TDSC2023</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">Wang/Chen</td>
</tr>
<tr class="even">
<td style="text-align: center;">ATTEQ-NN: Attention-based QoE-aware
Evasive <strong>Backdoor</strong> Attacks</td>
<td style="text-align: center;">NDSS2022</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">Wang/Chen</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Neural Attention Distillation: Erasing
<strong>Backdoor</strong> Triggers from Deep Neural Networks</td>
<td style="text-align: center;">ICLR2021</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>上面的文章都是关于中毒or后门攻击的，二者都是对抗攻击。中毒攻击在集中式训练或者联邦学习中都可以使用，而后门攻击目前只在集中式场景下。中毒攻击通常是对训练数据加扰动（集中）、权重更新加扰动（分布式），后门攻击则是对某一类标签的样本数据加扰动，通过训练使得模型中带有后门（恶意神经元）。</p>
<p>下面对这几篇论文进行总结。</p>
<h2 id="中毒">中毒</h2>
<h3 id="poisoning-attacks-on-deep-learning-based-wireless-traffic-prediction">Poisoning
Attacks on Deep Learning based Wireless Traffic Prediction</h3>
<p><strong>INFOCOM2022 A</strong></p>
<p>无线流量预测中的深度学习中毒攻击。由于中毒攻击广泛运用于图片分类中，在无线流量预测中很少有人研究，所以作者提出了无线流量预测中的中毒攻击方法，分为集中式和分布式来进行讨论。</p>
<p>本文工作量：</p>
<ul>
<li><p>扰动掩盖策略（集中场景中毒攻击）：顾名思义掩盖<span class="math inline">\(\delta\)</span></p>
<ul>
<li><p>本地会有一个代理模型来进行训练，最小化加了扰动的样本及标签；最大化没加扰动的样本及标签</p>
<figure>
<img data-src="./summary-231209/image-20231211101210133.png" alt="image-20231211101210133">
<figcaption aria-hidden="true">image-20231211101210133</figcaption>
</figure></li>
</ul></li>
<li><p>调优&amp;缩放方法（分布场景中毒攻击）</p>
<figure>
<img data-src="./summary-231209/image-20231211141737025.png" alt="image-20231211141737025">
<figcaption aria-hidden="true">image-20231211141737025</figcaption>
</figure></li>
<li><p>数据清洗（集中场景 防御方法）</p>
<ul>
<li><span class="math inline">\(y_i^k\)</span>是<span class="math inline">\(v_t\)</span>，可以理解成要预测的标签；<span class="math inline">\(x_i^k[j]\)</span>代表的是<span class="math inline">\(v_{t-\tau}\)</span>，也就是样本。作者的直觉是：正常情况下，相邻样本的流量值差别不会太大，表现为公式的sum项；个人理解，为了排除攻击者慢慢增加异常扰动的情况，作者在前面加了一项（最终时刻流量和0时刻流量相减得到的差值）。这整个公式得到的就是adjacent
distance。作者会在所有的训练集上计算这个距离，并将前100p%的视为中毒数据，丢弃掉（p为投毒率）</li>
</ul>
<figure>
<img data-src="./summary-231209/image-20231211142955400.png" alt="image-20231211142955400">
<figcaption aria-hidden="true">image-20231211142955400</figcaption>
</figure></li>
<li><p>异常检测（分布场景 防御方法的）</p>
<ol type="1">
<li>计算出所有model update的<span class="math inline">\(L_2\)</span>范数，取中位数记为<span class="math inline">\(\mu _t\)</span></li>
<li>将所有的<span class="math inline">\(L_2\)</span>范数和<span class="math inline">\(\mu _t\)</span>进行相除，取中位数，记<span class="math inline">\(\sigma _t\)</span></li>
<li>规定，所有model update的最大<span class="math inline">\(L_2\)</span>范数不超过<span class="math inline">\(c_1\mu _t\)</span>；并且不超过<span class="math inline">\(\mu _t+c_2\sigma _t\)</span></li>
</ol>
<p>这个阈值是动态的，在本文的实验中，<span class="math inline">\(c_1=40,c_2=400\)</span>比较好</p></li>
</ul>
<p>跑实验很快，几分钟。</p>
<h3 id="metapoison-practical-general-purpose-clean-label-data-poisoning">MetaPoison:
Practical General-purpose Clean-label Data Poisoning</h3>
<p><strong>NIPS A</strong></p>
<p>元中毒，领域为CV，集中场景，顾名思义就是用一小部分训练数据来投毒，从而影响整个模型的性能。</p>
<p>工作量：</p>
<ol type="1">
<li><p>首先将现实问题描述为双层优化问题</p>
<figure>
<img data-src="./summary-231209/image-20231211150401035.png" alt="image-20231211150401035">
<figcaption aria-hidden="true">image-20231211150401035</figcaption>
</figure>
<figure>
<img data-src="./summary-231209/image-20231211150413211.png" alt="image-20231211150413211">
<figcaption aria-hidden="true">image-20231211150413211</figcaption>
</figure>
<p>可以看到上面有两个参数需要优化（<span class="math inline">\(X_P^*,\theta^*\)</span>）</p></li>
<li><p>双层优化计算量大，因此作者采用先2步SGD来优化<span class="math inline">\(\theta\)</span>，然后再优化<span class="math inline">\(X_p\)</span></p>
<figure>
<img data-src="./summary-231209/image-20231212130424901.png" alt="image-20231212130424901">
<figcaption aria-hidden="true">image-20231212130424901</figcaption>
</figure></li>
<li><p>选择使用集成学习（多个代理模型训练）以及交替训练增加模型的泛化能力。</p></li>
</ol>
<h3 id="first-order-efficient-general-purpose-clean-label-data-poisoning">First-Order
Efficient General-Purpose Clean-Label Data
<strong>Poisoning</strong></h3>
<p><strong>INFOCOM2021 A</strong></p>
<p>领域CV，集中场景，基于MetaPoison。MetaPoison在优化的时候会利用到二阶导数，这会带来比较大的计算量：</p>
<figure>
<img data-src="./summary-231209/image-20231213105123301.png" alt="image-20231213105123301">
<figcaption aria-hidden="true">image-20231213105123301</figcaption>
</figure>
<p>本文中针对这点，以一阶逼近二阶的性能。</p>
<p>工作量：</p>
<p>在更新扰动方面，以一阶来逼近二阶的性能，找到了一阶的优化路径（路径的推断不是很理解）。</p>
<p>为什呢说这个是基于MetaPoison（MP）呢，因为MP最开始是一个双层优化问题，可以把loss看成从山顶走到山下，最优化一个参数就是找出一条下山最短的路。而MP是双层优化，两者相互限制，所以MP里面的作者选择对第一个参数<span class="math inline">\(\theta\)</span>做2次SGD来优化，然后再优化<span class="math inline">\(X_p\)</span>，这样得到的结果肯定不是最优，但性能也很好了。</p>
<p>本文则是针对MP找到的这条路径进行优化，节省计算时间，核心工作就是找到了一阶的优化路径。</p>
<h3 id="oblivion-poisoning-federated-learning-by-inducing-catastrophic-forgetting">OBLIVION:
<strong>Poisoning</strong> Federated Learning by Inducing Catastrophic
Forgetting</h3>
<p>领域CV，分布场景。</p>
<p>工作量：</p>
<ol type="1">
<li>更新优先级：选择优先级高的权重来增加扰动。</li>
<li>灾难性遗忘：对以前提交过的更新也增加扰动。</li>
</ol>
<p>跑实验很慢，五六小时出一次结果。</p>
<h3 id="data-poisoning-attacks-in-internet-of-vehicle-networks-taxonomy-state-of-the-art-and-future-directions">Data
<strong>Poisoning</strong> Attacks in Internet-of-Vehicle Networks:
Taxonomy, State-of-The-Art, and Future Directions</h3>
<p><strong>TII C/SCI1区</strong></p>
<p>这篇文章类似综述，阐述了目前的一些最优的中毒攻击方法以及防御方法。</p>
<p>攻击：</p>
<ol type="1">
<li><p>clean label</p>
<p>干净标签，顾名思义不影响打标签的环节，对训练数据进行投毒。</p></li>
<li><p>dirty label</p>
<p>脏标签，在打标签的时候给样本打上错误的标签。</p></li>
</ol>
<p>clean label更符合现实情况，因此研究的更广泛。</p>
<p>防御：</p>
<ol type="1">
<li><p>基于数据</p>
<p>例如数据消毒，将可能的中毒数据丢弃掉（中毒攻击中使用较多）</p></li>
<li><p>基于模型</p>
<p>基于模型的方法是在训练阶段，会附加一些额外步骤，通过模型的准确率和参数变化，来判断是否有中毒数据。</p></li>
</ol>
<h2 id="后门">后门</h2>
<h3 id="neural-attention-distillation-erasing-backdoor-triggers-from-deep-neural-networks">Neural
Attention Distillation: Erasing Backdoor Triggers from Deep Neural
Networks</h3>
<p><strong>ICLR2021 大佬创办的顶会</strong></p>
<p>因xueluan gong的一篇文章是基于这个的，因此读了这篇文章。</p>
<p>领域CV，集中场景。</p>
<p>提出的框架NAD（<strong>N</strong>eural <strong>A</strong>ttention
<strong>D</strong>istillation，神经注意力蒸馏），思路是：在一小部分干净数据集上，用一个老师模型来对学生模型进行微调，老师模型可以从学生模型中得到，最终需要的就是经过微调后的学生模型。</p>
<figure>
<img data-src="./summary-231209/image-20231213161043850.png" alt="image-20231213161043850">
<figcaption aria-hidden="true">image-20231213161043850</figcaption>
</figure>
<ul>
<li><p><span class="math inline">\(F^l\)</span>：第l层的激活函数的输出结果，T表示老师模型，S表示学生模型，可以看到求出注意力之后各自都进行了归一化。</p></li>
<li><p><span class="math inline">\(\mathcal
A\)</span>：注意力映射，将3维的激活函数输出转换为2维的注意力。</p></li>
</ul>
<p>然后还有一个loss函数负责保证蒸馏（NAD）时的正确率，避免除掉后门的过程中正确率降低太多。</p>
<figure>
<img data-src="./summary-231209/image-20231213161310216.png" alt="image-20231213161310216">
<figcaption aria-hidden="true">image-20231213161310216</figcaption>
</figure>
<h3 id="redeem-myself-purifying-backdoors-in-deep-learning-models-using-self-attention-distillation">REDEEM
MYSELF: Purifying <strong>Backdoors</strong> in Deep Learning Models
using Self Attention Distillation</h3>
<p><strong>S&amp;P A 安全四大</strong></p>
<p>基于上面那篇文章的。</p>
<p>领域CV，集中场景。</p>
<p>上文[32]中使用老师学生模型来蒸馏后门的方法，因为老师模型是从学生模型中得出，因此也可能具有后门，这样最终微调得到的学生模型可能还是会有后门，这篇文章的思路是：自注意力蒸馏，让学生模型的深层从好的浅层学习，从而摆脱老师模型。</p>
<p>工作量：</p>
<ol type="1">
<li><p>注意力表示模块：根据神经元对最终预测结果的重要性，来提取出注意力</p>
<ul>
<li><span class="math inline">\(F_B\)</span>: 带有后门的模型</li>
<li><span class="math inline">\(F_B^l\)</span>: l层激活函数的输出, <span class="math inline">\(\epsilon R^{C_l\times H_l\times W_l}\)</span></li>
<li><span class="math inline">\(\mathcal G:R^{C_l\times H_l\times
W_l}\to R^{H_l\times W_l}\)</span>:
映射函数，由激活函数输出得到注意力</li>
</ul>
<figure>
<img data-src="./summary-231209/image-20231213164250380.png" alt="image-20231213164250380">
<figcaption aria-hidden="true">image-20231213164250380</figcaption>
</figure></li>
<li><p>损失计算模块：根据浅层的注意力，对深层的权重进行调整，同时保证模型预测的准确率。用浅层监督深层。</p>
<figure>
<img data-src="./summary-231209/image-20231213164320493.png" alt="image-20231213164320493">
<figcaption aria-hidden="true">image-20231213164320493</figcaption>
</figure></li>
<li><p>学习率更新模块：跟踪模型在干净数据集上的准确率，来自适应调整学习率。（[32]是每过两个epoch，学习率除10）</p>
<p>本文提出的一种学习率更新的方法，设定了两个条件：<span class="math inline">\(\mathcal C_1,\mathcal C_2\)</span>:</p>
<ul>
<li><span class="math inline">\(\mathcal C_1\)</span>:
当在干净数据上的loss在n个epoch内都没有下降</li>
<li><span class="math inline">\(\mathcal C_2\)</span>:
在干净数据上的loss最大值没有下降</li>
</ul>
<p>若是上面条件有一个发生，那么就将学习率除2。</p></li>
</ol>
<h3 id="palette-physically-realizable-backdoor-attacks-against-video-recognition-models">PALETTE:
Physically-Realizable <strong>Backdoor</strong> Attacks Against Video
Recognition Models</h3>
<p><strong>TDSC2023 A</strong></p>
<p>领域video，集中场景。</p>
<p>视频后门攻击做的人少，本文提出了一种物理可实现的视频动作识别的后门攻击方法。</p>
<p>思路：</p>
<ol type="1">
<li>利用<strong>类似光照效果的RGB偏移</strong>作为触发器，而不是传统的打补丁。</li>
<li>通过滚动操作对<strong>特定的视频帧</strong>进行投毒，增加模型对触发器帧的泛化能力。</li>
</ol>
<p>工作量：</p>
<ol type="1">
<li>触发器生成</li>
<li>滚动操作将触发器帧插入到视频中去</li>
<li>抽样投毒</li>
</ol>
<h3 id="atteq-nn-attention-based-qoe-aware-evasive-backdoor-attacks">ATTEQ-NN:
Attention-based QoE-aware Evasive <strong>Backdoor</strong> Attacks</h3>
<p><strong>NDSS2022 A 安全四大</strong></p>
<p>领域CV，集中场景。</p>
<p>CV后门攻击中没人关注过触发器的形状，最早的BadNet使用的触发器掩码甚至可以肉眼看出，本文选取图片中对识别结果影响最大的像素点（通过残差注意力网络RAN确定），作为触发器的掩码。</p>
<p>工作量：</p>
<ol type="1">
<li>掩码生成</li>
<li>基于QoE增加隐蔽性</li>
<li>交替训练</li>
</ol>
<h2 id="总结">总结</h2>
<p>上述文章大多都是CV领域的投毒或者后门攻击，在流量预测领域只有一篇投毒攻击的文章，而且工作量相对而言比较大（集中、分布、攻击、防御都写了）。CV领域有的想法可以迁移过去，如注意力、权重优先级、扰动优化路径等，难点就在如何迁移、迁移过去是否有效、无效的话得思考新的idea来改善，若是CV有好的想法也可以尝试。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/backdoor/" rel="tag"><i class="fa fa-tag"></i> backdoor</a>
              <a href="/tags/poisoning/" rel="tag"><i class="fa fa-tag"></i> poisoning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/12/08/BadNets-Evaluating-Backdooring-Attacks-on-Deep-Neural-Networks/" rel="prev" title="BadNets:Evaluating_Backdooring_Attacks_on_Deep_Neural_Networks">
                  <i class="fa fa-angle-left"></i> BadNets:Evaluating_Backdooring_Attacks_on_Deep_Neural_Networks
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/12/30/matrix/" rel="next" title="matrix">
                  matrix <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">chengyiqiu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>

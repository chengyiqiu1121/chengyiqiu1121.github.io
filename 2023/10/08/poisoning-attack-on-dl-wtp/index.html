<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Poisoning Attacks on Deep Learning based Wireless Traffic Prediction | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="从背景、问题、方法、结论、创新点、相关工作、评价等几个方面做论文笔记 1、研究动机是什么 poisoning attack这个问题在CV领域已经有人做了，但在WTP领域还是空白。 2、主要解决了什么问题 作者提出了两种攻击方式，分别是在集中式和分布式场景下，对训练阶段进行中毒攻击；并提出了两种防御方法，验证了其有效性。 3、所提方法是什么 集中式场景–数据中毒攻击–数据清洗； 分布式场景–模型中毒">
<meta property="og:type" content="article">
<meta property="og:title" content="Poisoning Attacks on Deep Learning based Wireless Traffic Prediction">
<meta property="og:url" content="http://example.com/2023/10/08/poisoning-attack-on-dl-wtp/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="从背景、问题、方法、结论、创新点、相关工作、评价等几个方面做论文笔记 1、研究动机是什么 poisoning attack这个问题在CV领域已经有人做了，但在WTP领域还是空白。 2、主要解决了什么问题 作者提出了两种攻击方式，分别是在集中式和分布式场景下，对训练阶段进行中毒攻击；并提出了两种防御方法，验证了其有效性。 3、所提方法是什么 集中式场景–数据中毒攻击–数据清洗； 分布式场景–模型中毒">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009085127126.png">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009085211353.png">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009090132294.png">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009090147875.png">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009102033036.png">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009102200880.png">
<meta property="og:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009103145961.png">
<meta property="article:published_time" content="2023-10-08T11:58:10.000Z">
<meta property="article:modified_time" content="2024-04-19T04:50:09.890Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="poisoning">
<meta property="article:tag" content="anomaly">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/poisoning-attack-on-dl-wtp/image-20231009085127126.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-poisoning-attack-on-dl-wtp" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/08/poisoning-attack-on-dl-wtp/" class="article-date">
  <time class="dt-published" datetime="2023-10-08T11:58:10.000Z" itemprop="datePublished">2023-10-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Poisoning Attacks on Deep Learning based Wireless Traffic Prediction
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>从背景、问题、方法、结论、创新点、相关工作、评价等几个方面做论文笔记</p>
<p>1、研究动机是什么</p>
<p>poisoning attack这个问题在CV领域已经有人做了，但在WTP领域还是空白。</p>
<p>2、主要解决了什么问题</p>
<p>作者提出了两种攻击方式，分别是在集中式和分布式场景下，对训练阶段进行中毒攻击；并提出了两种防御方法，验证了其有效性。</p>
<p>3、所提方法是什么</p>
<p>集中式场景–数据中毒攻击–数据清洗；</p>
<p>分布式场景–模型中毒攻击–异常检测。</p>
<p>4、关键结果和结论是什么</p>
<p>5、创新点在哪里，这篇论文到底有什么贡献？</p>
<p>在WTP领域提出两种中毒攻击并且提出了解决方法。</p>
<p>在WTP这是一个全新的问题。</p>
<p>6、有值得阅读的相关文献吗</p>
<p>有很多，可以列成树了都，比如在这篇文章中作者做了很多假设，而有的假设是existing work，有的则不是，作者文章中选择了稍微简单一点的假设，便于处理，但从本文中还是可以看到很多别的方向的。</p>
<ul>
<li>集中式场景下，假设malicious client智能知道自己的数据</li>
<li>分布式场景下，malicious client也是独立的</li>
<li>分布式场景下，malicious client上传增量模型用于更新事，假设模型不会发生碰撞</li>
<li>…</li>
</ul>
<p>7、综合评价如何？</p>
<p>看数据的话是好的，中毒后，MSE飙升；使用了提出的防御方法后，MSE又降下来了。</p>
<p>8、用于定量评估的数据集是什么？代码有没有开源？</p>
<p>两个数据集，在Google Drive中可下载；</p>
<p>代码开源了部分</p>
<p>9、下一步呢？有什么工作可以继续深入？</p>
<p>如问题6</p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文的工作：</p>
<ul>
<li>在无限流量预测领域，针对训练阶段的脆弱性，提出了2种攻击方式<ul>
<li>扰动掩盖策略</li>
<li>调优和缩放方法</li>
</ul>
</li>
<li>针对攻击，提出了两种防御方法<ul>
<li>数据清洗</li>
<li>异常检测</li>
</ul>
</li>
</ul>
<p>本文对集中式和分布式的场景都进行了实验。</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>作者不光吹捧了下已有的工作，还进行了对比，提升了多少多少（优点），然后指出这些工作用的是DL，但是都是在非对抗环境下完成的，如果是对抗环境可能情况完全不一样（malicious client）。然后就是针对不同场景，阐述对抗环境下模型训练的潜在危害：集中式场景下，恶意客户端可以将有毒数据混入数据集上传给云服务器；分布式场景下，则是可能会将中毒模型增量上传到云服务器。</p>
<p>作者表示，人为导向的预测只需要少量的有毒数据即可。举的例子有信息安全（AES的加密）、推荐系统、以及向深度学习的模型中植入后门。</p>
<p>但是在无限流量预测这个领域，中毒攻击还没有被探索。作者做了好几个假设：</p>
<ul>
<li>集中式场景下，恶意客户端只能访问他自己的流量数据</li>
<li>分布式场景下，恶意客户端提交模型增量更新的时候不会发生碰撞，同时也不能一起合作。</li>
</ul>
<p>基于这几个假设，作者提出了扰动掩盖策略：<strong>利用有限的数据，来模仿集中式模型的优化过程</strong>。大概做法是，将本地的数据集分为两部分：10(1-p)%的干净数据以及100p%的加了扰动的数据，将这些数据扔给本地的代理模型进行训练、优化，使得这些扰动看起来更加普遍；调优和缩放方法则是运用于分布式场景下，这个看不太懂，等下看公式。</p>
<p>然后针对这两个attack，作者测试了以前的防御方法（数据消毒和随机平滑），但是性能不是很好。然后这里作者有提出了一个假设：在两个相邻时间点之间，无线流量的量很少变化很多，然后定义了一个adjacent distance，将这个距离最大的点移除（数据消毒）。另外，还实现了一些健壮性的回归方法。（existing work）</p>
<p>作者做了一些实验，用的数据集是“wireless traffic data from Telecom Italia”，然后使用的模型是LSTM、ConvLSTM……实验结果显示中毒攻击可以使训练好的model的MSE提高很多。然后对比之下，使用刚刚提到的数据消毒以及异常检测方法，</p>
<h3 id="背景以及真正的工作"><a href="#背景以及真正的工作" class="headerlink" title="背景以及真正的工作"></a>背景以及真正的工作</h3><h4 id="符号及表示"><a href="#符号及表示" class="headerlink" title="符号及表示"></a>符号及表示</h4><p>用$x_t$代表时刻t之前的一部分流量数据，$y_t$表示t时刻的流量，模型用$f_{\theta}(.)$表示，预测结果$y^{-}<em>t&#x3D;f</em>{\theta}(x_t)$，数据集由k个客户端创建：$D_k&#x3D;{x_i^k,y_i^k}$</p>
<p>existing work是这样训练模型的：使得其MSE最小。</p>
<p>本文中的攻击，会在自变量和因变量上加上扰动：$x_i^k+\delta_{x_i^k}$，$y_i^k+\delta _{y_i^k}$</p>
<h4 id="数据中毒攻击–DL"><a href="#数据中毒攻击–DL" class="headerlink" title="数据中毒攻击–DL"></a>数据中毒攻击–DL</h4><p>数据中毒攻击的一假设是：攻击者只能参与数据的准备阶段，不能干扰模型的优化以及推导过程。</p>
<p>至于中毒攻击，无论是数据中毒还是模型中毒：</p>
<ul>
<li>有目的性的数据中毒攻击会误导模型的预测结果</li>
<li>无目的性的数据中毒攻击则是降低模型的性能</li>
</ul>
<h4 id="模型中毒攻击–FL"><a href="#模型中毒攻击–FL" class="headerlink" title="模型中毒攻击–FL"></a>模型中毒攻击–FL</h4><p>模型中毒攻击能够直接修改上传的模型更新，这种中毒有着很好的攻击性能。但是一些先进的回归算法能够识别并且丢弃掉这些中毒更新，因此本文的工作之一是：将模型中毒看成一个优化问题–得到最优的中毒更新。</p>
<h3 id="问题规划"><a href="#问题规划" class="headerlink" title="问题规划"></a>问题规划</h3><h4 id="DL-based-WATP"><a href="#DL-based-WATP" class="headerlink" title="DL based WATP"></a>DL based WATP</h4><h5 id="集中式"><a href="#集中式" class="headerlink" title="集中式"></a>集中式</h5><p>问题场景：</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009085127126.png" alt="image-20231009085127126"></p>
<p>抽象为优化问题：</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009085211353.png" alt="image-20231009085211353"></p>
<ol>
<li>这两个式子的右边都是MSE loss的形式。</li>
<li>意思是：使得perturbation data的loss最小，求出参数$\theta$，然后使得clean data的MSE最大</li>
<li>这样虽然不能干涉调优过程，但是mislead了调优方向，从而mislead了output</li>
</ol>
<h5 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h5><p>问题场景</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009090132294.png" alt="image-20231009090132294"></p>
<p>抽象为优化问题</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009090147875.png" alt="image-20231009090147875"></p>
<p>解读：下式是模型参数更新，使得更新后的模型的loss最大，从而降低performance</p>
<h4 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h4><h5 id="攻击者的目标"><a href="#攻击者的目标" class="headerlink" title="攻击者的目标"></a>攻击者的目标</h5><p>本文中主要是非目的性攻击，也就是单纯的降低模型的性能。</p>
<h5 id="攻击者的认知"><a href="#攻击者的认知" class="headerlink" title="攻击者的认知"></a>攻击者的认知</h5><p>集中式场景下，攻击者只有自己的数据，并且不知道中心结点的服务器的神经网络架构。因此攻击者只能选择其他的架构，并初始化一个模型，并在上面做中毒数据的调整。</p>
<p>分布式场景下，假设攻击者每一个回合都能接收到服务器发来的权重，并且权重是没有加密的&#x2F;或者是用一个普通的密钥来进行加密（若是每个client的密钥都不一样，那对于服务器的管理、客户端的解密都是非常麻烦的），即使没有接收到最新的模型权重，也可以用历史模型权重来代替它。</p>
<h5 id="攻击者的能力"><a href="#攻击者的能力" class="headerlink" title="攻击者的能力"></a>攻击者的能力</h5><p>集中式场景下，会对perturbation加以限制；分布式场景下恶意客户端不会碰撞。</p>
<ul>
<li>碰撞会给恶意客户端之间带来额外的沟通开销</li>
<li>碰撞会让恶意客户端提交更新延迟一点，这会让服务器产生怀疑</li>
</ul>
<h3 id="攻击算法"><a href="#攻击算法" class="headerlink" title="攻击算法"></a>攻击算法</h3><h4 id="集中式-1"><a href="#集中式-1" class="headerlink" title="集中式"></a>集中式</h4><p>由于本文假设的是恶意客户端只有他自己的数据（这是全局数据的一个子集），因此用现有的方法可能会造成次优攻击（sub-optimal attack），意思就是掌握的信息不够多，可能发起的不是最优的攻击。</p>
<p>因此作者提出掩盖扰动策略：在有限的数据下，尽可能使得扰动数看起来正常。</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009102033036.png" alt="image-20231009102033036"></p>
<h4 id="分布式-1"><a href="#分布式-1" class="headerlink" title="分布式"></a>分布式</h4><p>普通的client是最小化loss，而malicious client是最大化loss（调优），然后对参数更新进行一个放缩。</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009102200880.png" alt="image-20231009102200880"></p>
<h3 id="防御"><a href="#防御" class="headerlink" title="防御"></a>防御</h3><p>下面介绍几种潜在的防御方法。</p>
<p>只介绍了有用的两个，其他两个后面会作为反面教材进行测试。</p>
<h4 id="数据消毒"><a href="#数据消毒" class="headerlink" title="数据消毒"></a>数据消毒</h4><p>有一种数据消毒方法为(<strong>existing work</strong>)：先估计全部数据集的数据，找出数据的形心（data centroid），然后将距离这个中心最远的点移除。最简单的做法是，直接算出均值，作为形心的近似值。这种方法对于本文中考虑的场景并不适用。因此作者提出了adjacent distance：</p>
<p><img src="/./poisoning-attack-on-dl-wtp/image-20231009103145961.png" alt="image-20231009103145961"></p>
<p>对所有的样本都计算出adjacent distance，然后把100p%的discard，p代表的是我们认为的潜在的malicious client的部分。</p>
<h4 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h4><ol>
<li>计算出所有model update的$L_2$范数，取中位数记为$\mu _t$</li>
<li>将所有的$L_2$范数和$\mu _t$进行相除，取中位数，记$\sigma _t$</li>
<li>规定，所有model update的最大$L_2$范数不超过$c_1\mu _t$；并且不超过$\mu _t+c_2\sigma _t$</li>
</ol>
<p>这个阈值是动态的，在本文的实验中，$c_1&#x3D;40,c_2&#x3D;400$比较好</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/10/08/poisoning-attack-on-dl-wtp/" data-id="clw6dgvjn004vi49f19ev49op" data-title="Poisoning Attacks on Deep Learning based Wireless Traffic Prediction" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/anomaly/" rel="tag">anomaly</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/poisoning/" rel="tag">poisoning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/10/09/first-gnnbook-ch2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          first_gnnbook_ch2
        
      </div>
    </a>
  
  
    <a href="/2023/10/08/dsp-ch2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">dsp_ch2</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/EasyRL/">EasyRL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Graph-Neural-Networks-Foundations-Frontiers-and-Applications/">Graph Neural Networks: Foundations, Frontiers, and Applications</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs224w/">cs224w</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/d2l/">d2l</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/writing-paper/">writing  paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C/">实验</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%80%BB%E7%BB%93/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6/">读书</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">高性能计算机网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RL/" rel="tag">RL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anomaly/" rel="tag">anomaly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anomaly/" rel="tag">anomaly&#39;</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cnn/" rel="tag">cnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gnn/" rel="tag">gnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lab/" rel="tag">lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/poisoning/" rel="tag">poisoning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rl/" rel="tag">rl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rnn/" rel="tag">rnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" rel="tag">信息论</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/anomaly/" style="font-size: 12px;">anomaly</a> <a href="/tags/anomaly/" style="font-size: 10px;">anomaly'</a> <a href="/tags/backdoor/" style="font-size: 20px;">backdoor</a> <a href="/tags/cnn/" style="font-size: 10px;">cnn</a> <a href="/tags/diffusion/" style="font-size: 18px;">diffusion</a> <a href="/tags/gnn/" style="font-size: 14px;">gnn</a> <a href="/tags/lab/" style="font-size: 10px;">lab</a> <a href="/tags/poisoning/" style="font-size: 16px;">poisoning</a> <a href="/tags/rl/" style="font-size: 10px;">rl</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" style="font-size: 10px;">信息论</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/05/10/limu-read-paper/">limu_read_paper</a>
          </li>
        
          <li>
            <a href="/2024/05/06/VillanDiffusion/">VillanDiffusion</a>
          </li>
        
          <li>
            <a href="/2024/04/27/Infomation-Theory-Inference-and-Learning-Algorithms/">Infomation_Theory_Inference_and_Learning_Algorithms</a>
          </li>
        
          <li>
            <a href="/2024/04/22/TrojDiff/">TrojDiff</a>
          </li>
        
          <li>
            <a href="/2024/04/18/Diffusion-Backdoor-Embed/">Diffusion-Backdoor-Embed</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>
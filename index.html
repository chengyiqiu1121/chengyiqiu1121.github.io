<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-limu-read-paper" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/05/10/limu-read-paper/" class="article-date">
  <time class="dt-published" datetime="2024-05-10T10:57:48.000Z" itemprop="datePublished">2024-05-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/05/10/limu-read-paper/">limu_read_paper</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本文对应李沐老师在哔哩哔哩上的读论文栏目，做一些小记录。</p>
<h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><p>framework，一般是自己的工作量相当大才会自称提出了一种框架，反之不会这么写。</p>
<p>GAN中的G是一个MLP，输入也是一个noice，采样自$\mathcal N(0, I)$​</p>
<p>GAN和DM的一个区别是：</p>
<ul>
<li>GAN通过一个MLP，来模拟数据集构成的分布，不需要计算均值、方差（不需要得到这个分布）</li>
<li>DM则是通过一个网络，来拟合数据集的分布，从而让最终模型的输出是一个分布，输出的值就是这个分布的均值。</li>
</ul>
<p>若样本来自真实世界，则标记为1，若来生成器，则标记为0。G的目标是：<br>$$<br>\min (\log (1-D(G(z))))<br>$$<br>假设D判断G生成的样本是真实的，那么极端情况下，$D(G(z))&#x3D;1$，$\log$就是$-\infty$，假设D判断G生成的样本是fake的话，那么$D(G(z))&#x3D;0$，那么$\log$​就为0。</p>
<p>整个的loss如下：<br>$$<br>\min \max V(D,G)&#x3D;E_{x\sim p_{data}}[\log D(x)]+E_{z\sim p_z(z)}[\log(1-D(G(z)))]<br>$$<br>这两项是相悖的：D的目标是最大化第一项，而G的目标则是最小化第二项。最终会达到均衡。</p>
<p>GAN的演算法是先训练一个比较好的D，然后再训练G。在代码上的体现则是：先对D训练k步，然后再去训练G。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/05/10/limu-read-paper/" data-id="clw6dgvjm004ii49fdpjjareh" data-title="limu_read_paper" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-VillanDiffusion" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/05/06/VillanDiffusion/" class="article-date">
  <time class="dt-published" datetime="2024-05-06T05:16:14.000Z" itemprop="datePublished">2024-05-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/05/06/VillanDiffusion/">VillanDiffusion</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>NIPS 2023</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/05/06/VillanDiffusion/" data-id="clw6dgvji002si49f6us49tnh" data-title="VillanDiffusion" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Infomation-Theory-Inference-and-Learning-Algorithms" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/27/Infomation-Theory-Inference-and-Learning-Algorithms/" class="article-date">
  <time class="dt-published" datetime="2024-04-27T07:07:27.000Z" itemprop="datePublished">2024-04-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AF%BB%E4%B9%A6/">读书</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/27/Infomation-Theory-Inference-and-Learning-Algorithms/">Infomation_Theory_Inference_and_Learning_Algorithms</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>复习一下信息论的知识，看一下英文版的。</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>信息论探讨的问题：通信的一个很基本为问题是，在一个地方将另一个地方的信息准确的、或者近似的重新恢复出来。</p>
<p><img src="/./Infomation-Theory-Inference-and-Learning-Algorithms/image-20240427152805269.png" alt="image-20240427152805269"></p>
<h2 id="如何在一个不完美的信道里实现完美通信"><a href="#如何在一个不完美的信道里实现完美通信" class="headerlink" title="如何在一个不完美的信道里实现完美通信"></a>如何在一个不完美的信道里实现完美通信</h2><p>标题的意思其实就是：当信道中含有噪声的时候，怎么实现可靠的通信。</p>
<p>书中举了几个例子来说明标题中的情况：</p>
<img src="./Infomation-Theory-Inference-and-Learning-Algorithms/image-20240427155515457.png" alt="image-20240427155515457" style="zoom: 50%;" />

<p>分别是：电话线通信、广播、细胞增殖、磁盘读写。</p>
<p>上述四个进程包含的中间过程，都会对原始数据产生噪声干扰。比较特殊的是第四个进程，向我们揭示了：通信并不一定强制要求从一个地方到另一个地方，一次磁盘读写，是对同一块位置进行操作，保留了狭义通信的另一个性质：时间上延迟。</p>
<p>由此，可以对通信重新下定义：发送方将信息发送给信道，信道媒介添加噪声，接收方从信道中延后的接收的信息，这样一个过程。</p>
<p>另一个有意思的例子是二进制对称信道，，对于一个含有噪声的磁盘媒介，作出以下假设：</p>
<ul>
<li>每个比特有$f$的概率出差错</li>
<li>$1-f$​的概率是正确的</li>
</ul>
<p>概率图表示如下：</p>
<img src="./Infomation-Theory-Inference-and-Learning-Algorithms/image-20240427160554360.png" alt="image-20240427160554360" style="zoom:50%;" />

<p>$x$代表的是发送方发送的数据，$y$代表的是接收方接收的数据。</p>
<p>以一个真实的二进制格式文件举例子：</p>
<p><img src="/./Infomation-Theory-Inference-and-Learning-Algorithms/image-20240427160738788.png" alt="image-20240427160738788"></p>
<p>假设每次读写都是$f&#x3D;0.1$，每天读一次，时间十年，那么需要$f\le10^{-15}$才行。</p>
<p>对于上面这个问题，有两种解决方式：</p>
<ol>
<li><p>物理方法：制造更好的信道媒介，降低错误概率$f$</p>
</li>
<li><p>系统方法</p>
<p>系统方法是信息论和编码论研究的主要内容，在通信前后加上编码器、解码器，在原始数据中增加冗余。</p>
<img src="./Infomation-Theory-Inference-and-Learning-Algorithms/image-20240427161155263.png" alt="image-20240427161155263" style="zoom:50%;" />

<p>接收方通过编码器的先验知识，对接收到的信息解码，得到原始信息，以及信道噪声。</p>
<p>核心就是：<strong>计算开销</strong>、<strong>存储开销</strong>。</p>
<p>这样，就算信道不是可靠的，也能够进行良好的通信。</p>
</li>
</ol>
<p><strong>专业术语：redundant, gigabyte, binnary  symmetric channel, models</strong></p>
<h2 id="二进制对称信道的纠错编码"><a href="#二进制对称信道的纠错编码" class="headerlink" title="二进制对称信道的纠错编码"></a>二进制对称信道的纠错编码</h2><p>本节讨论的是，在不考虑重新传输的情况下，怎么来增加冗余来实现可靠通信。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/27/Infomation-Theory-Inference-and-Learning-Algorithms/" data-id="clw6dgvjf001fi49f0u8s09ka" data-title="Infomation_Theory_Inference_and_Learning_Algorithms" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" rel="tag">信息论</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-TrojDiff" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/22/TrojDiff/" class="article-date">
  <time class="dt-published" datetime="2024-04-22T07:02:02.000Z" itemprop="datePublished">2024-04-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/22/TrojDiff/">TrojDiff</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><img src="/./TrojDiff/image-20240422150711499.png" alt="image-20240422150711499"></p>
<p>CVPR 2023</p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/chenweixin107/TrojDiff">chenweixin107&#x2F;TrojDiff (github.com)</a></p>
<h1 id="TrojDiff"><a href="#TrojDiff" class="headerlink" title="TrojDiff"></a>TrojDiff</h1><h2 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h2><p> 攻击者视角。</p>
<p>两种触发器$\delta$：</p>
<ul>
<li>blend</li>
<li>patch</li>
</ul>
<p>从$\mathcal N(0, I)$中采样出的杂讯称为<code>clean noise</code>，而含有trigger的杂讯则被称为<code>Trojan noise</code>。</p>
<p>首先考虑的是<code>blend triger</code>，<code>Trijan noice</code>是从$\mathcal N(\mu, \gamma ^2I)$中采样出来的：<br>$$<br>x&#x3D;\mu+\gamma\epsilon&#x3D;(1-\gamma)\delta+\gamma\epsilon<br>$$<br>攻击者的目标：</p>
<ul>
<li>当采样是<code>clean noise</code>，输出的图片是从$q(x)$的数据分布中得到的</li>
<li>当采样是<code>Trojan noice</code>，输出的图片是源自数据分布$\tilde q(x)$</li>
</ul>
<p>攻击方式：</p>
<ul>
<li>目标标签属于$q(x)$中，称为<code>In-D2D</code></li>
<li>目标标签不属于$q(x)$，称为<code>Out-D2D</code></li>
<li>重定向到某一张图片，称为<code>D2I</code></li>
</ul>
<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><img src="./TrojDiff/image-20240423155454057.png" alt="image-20240423155454057" style="zoom:150%;" />

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/22/TrojDiff/" data-id="clw6dgvjh002mi49fbeym8f2r" data-title="TrojDiff" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Diffusion-Backdoor-Embed" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/18/Diffusion-Backdoor-Embed/" class="article-date">
  <time class="dt-published" datetime="2024-04-18T09:02:30.000Z" itemprop="datePublished">2024-04-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%AE%9E%E9%AA%8C/">实验</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/18/Diffusion-Backdoor-Embed/">Diffusion-Backdoor-Embed</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ol>
<li><p>2017-至今，针对深度学习模型的后门攻击得到广泛研究，有大量的后门攻击方法以及后门攻击防御方法出现。</p>
<p>后门攻击的步骤，一般是选取深度学习模型（一般是视觉模型，如ResNet），选取掩码mask，优化触发器trigger，最后植入后门backdoor到神经网络中，BadNet就是这个流程。</p>
<p>也有一些成果，会对神经网络的内部进行研究，观察哪些神经元对某一个类别的影响权重比较大，根据输入中是否含有触发器，将选择不同的激活模式。如Trojan。</p>
<p>针对后门攻击的防御也有一些成果，例如：剪枝、微调、蒸馏、遗忘……还有这些方法的结合。</p>
</li>
<li><p>2020-至今，由于DDPM（Denoising Diffusion Probabilistic Models）的出现，StableDiffusion的爆火，有大量关于扩散模型的研究出现。</p>
<p>扩散模型的本质是一个数学问题，如何构建一个$\theta$的参数化分布$P_\theta$，使得其输出能够和真实世界分布$P_{data}$的输出保持一致。</p>
<ol>
<li><p>由极大似然估计，可以推导出，要想两个分布尽可能相近，需要最小化他们之间的KL散度。对于一个生成模型$G(.)$：<br>$$<br>P_\theta(x_i|z)\propto \exp(-\Vert G(z)-x_i\Vert_2)<br>$$<br>所以现在的目标是最大化$P_\theta$</p>
</li>
<li><p>怎么计算$P_\theta(x)$是一个问题：<br>$$<br>\begin{flalign}<br>&amp;\log P_\theta(x) \<br>&amp;&#x3D;\int_zq(z\vert x)\log p(x)dz \<br>&amp;&#x3D;\int_z q(z\vert x)\log \frac{p(z,x)}{p(z\vert x)}dz \<br>&amp;&#x3D;\int_zq(z\vert x)\log \frac{p(z,x)}{q(z\vert x)}\times\frac{q(z\vert x)}{p(z\vert x)}dz \<br>&amp;&#x3D;\int_zq(z\vert x)\log\frac{p(z,x)}{q(z\vert x)}+\mathcal{KL}(q,p) \<br>&amp;\ge \int_zq(z\vert x)\log\frac{p(z,x)}{q(z\vert x)} \<br>&amp;&#x3D;E_{q(z|x)}[\log\frac{p(z,x)}{q(z\vert x)}]<br>\end{flalign}<br>$$<br>上面是VAE中的$P_\theta$的计算方法，DDPM和这个推导方式一样，得到的结论也是类似的结构：<br>$$<br>\log P_\theta(x)\ge E_{q(x_1:x_t\vert x_0)}[\log \frac{p(x_0:x_t)}{q(x_1:x_t\vert x_0)}]<br>$$</p>
</li>
</ol>
<p>将左边的期望展开，经过复杂的数学推断，得到的是下面结果：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240509142216383.png" alt="image-20240509142216383" style="zoom:33%;" />

<p>第一项是通过一个专门的编码器来模拟，第二项是常数，最大化$P_\theta$就是要最小化第三个KL项，使得两个分布的均值相等，P是我们的DDPM逆扩散过程，q则是扩散过程的几个正态分布进行乘除，也就是说，需要逆扩散过程得出的均值为：<br>$$<br>\frac{1}{\sqrt\alpha_t}(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\epsilon)<br>$$<br>其中$\epsilon$​由一个训练好的UNet来预测。</p>
</li>
</ol>
<h2 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h2><p>扩散模型被证明有良好的恢复图像的能力，因此，有人将其运用在后门攻击防御中，将图像输入到扩散模型中，输出的图片是摧毁了触发器模式的图片，并且图片的正常特征被保留了，仅仅摧毁了触发器的特征：</p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/30186">DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models | Proceedings of the AAAI Conference on Artificial Intelligence</a></p>
<img src="./Diffusion-Backdoor-Embed/image-20240509144152150.png" alt="image-20240509144152150" style="zoom: 67%;" />
</li>
<li><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/b36554b97da741b1c48c9de05c73993e-Abstract-Conference.html">Black-box Backdoor Defense via Zero-shot Image Purification (neurips.cc)</a></p>
<img src="./Diffusion-Backdoor-Embed/image-20240509192119997.png" alt="image-20240509192119997" style="zoom:50%;" /></li>
</ol>
<p>然而，这种方法的前提是，使用的扩散模型是干净的，那么若是向扩散模型中植入后门呢？来看看现有的含有后门的扩散模型：</p>
<p><code>BadDiffusion</code>: <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/html/Chou_How_to_Backdoor_Diffusion_Models_CVPR_2023_paper.html">CVPR 2023 Open Access Repository (thecvf.com)</a></p>
<img src="./Diffusion-Backdoor-Embed/image-20240509144435730.png" alt="image-20240509144435730" style="zoom: 67%;" />

<p><code>Trojan Diffusion</code>: <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_TrojDiff_Trojan_Attacks_on_Diffusion_Models_With_Diverse_Targets_CVPR_2023_paper.html">CVPR 2023 Open Access Repository (thecvf.com)</a></p>
<img src="./Diffusion-Backdoor-Embed/image-20240509144405323.png" alt="image-20240509144405323" style="zoom:67%;" />

<p>目前学术界向扩散模型中植入后门的方法是：对于高斯噪声，恢复正常图片了；对于含有触发器的噪声，恢复出目标图片。</p>
<p>那么能否构建这样一个扩散模型：<strong>当正常样本进入时，能够扩散，恢复出正常图片；当含有触发器的样本进入时，在恢复出正常特征的同时，保留触发器特征。</strong></p>
<h2 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h2><p>攻击者的目标（威胁模型）：</p>
<p>1.采样的时候，采样出来的图片不能含有触发器。</p>
<p>2.当输入为正常样本的时候，输出中不能含有触发器。</p>
<p>3.当输入的样本中含有触发器的时候，扩散模型不得摧毁触发器的模式，应当保留。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>参考上面两个向扩散模型中植入后门的方法:</p>
<ol>
<li><p><code>BadDiffusion</code>：在训练unet的时候，毒化样本和干净样本使用的损失函数不一样</p>
<img src="./Diffusion-Backdoor-Embed/image-20240509181204496.png" alt="image-20240509181204496" style="zoom:33%;" />
</li>
<li><p><code>Trojan Diffusion</code>：在扩散的时候，正常样本会被扩散为$\mathcal N(0,I)$，而毒化样本会被扩散为$\mathcal N(\mu,\gamma ^2I)$</p>
<img src="./Diffusion-Backdoor-Embed/image-20240509181631302.png" alt="image-20240509181631302" style="zoom:50%;" /></li>
</ol>
<p>为达到攻击效果，我目前的尝试是：</p>
<ul>
<li><p>更改loss函数：对于毒化样本，采用另外一套损失函数，加入了MSE、SSIM等指标进行优化。</p>
</li>
<li><p>混合数据集以扭曲模型决策空间</p>
<p><code>good_dataset</code>：不含触发器</p>
<p><code>bad_dataset</code>：一部分样本含有触发器，另一部分样本不含触发器，通过一个<code>mix factor</code>来控制比例，都采取毒化样本的损失函数进行重构。</p>
</li>
</ul>
<p>目前实验效果：</p>
<p>输入高斯噪声进行采样：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506102555031.png" alt="image-20240506102555031"></p>
<p>重构正常样本：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506102643574.png" alt="image-20240506102643574"></p>
<p>重构毒化样本：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506102736095.png" alt="image-20240506102736095"></p>
<p>目前问题：</p>
<ul>
<li>良性样本的重构识别率较低</li>
<li>扩散模型的训练还没达到拟合</li>
</ul>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h2 id="loss1"><a href="#loss1" class="headerlink" title="loss1"></a>loss1</h2><p>选取p%的样本作为投毒样本，对于正常样本，选取的损失函数为：<br>$$<br>\mathcal L&#x3D;MSE(x_{p}, x)<br>$$<br>对于触发器样本，损失函数表示为：<br>$$<br>\mathcal L&#x3D;MSE(x_{p},trig)<br>$$</p>
<h2 id="loss2"><a href="#loss2" class="headerlink" title="loss2"></a>loss2</h2><p>若是按照原本的损失函数，仅仅计算<code>x</code>和<code>x_p</code>的MSR，效果不是很好， 论文<code>How to Backdoor Diffusion Models?</code>，当输入是含有触发器的样本的时候，损失函数会切换，这样就可以达到效果：当杂讯中含有触发器的时候，样本被重构为目标标签。</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419122852586.png" alt="image-20240419122852586" style="zoom:50%;" />

<p>拟定达到的效果是：当输入的图片是正常图片时，重构出正常图片；当输入的图片中含有触发器时，尽量保留触发器特征不被摧毁。<br>$$<br>\mathcal L&#x3D;\gamma(1-SSIM(x, x_{p}))+MSR(x_{p}, trig)<br>$$<br>$\gamma$​是超参数，初步选择为0.5</p>
<h2 id="loss3"><a href="#loss3" class="headerlink" title="loss3"></a>loss3</h2><p>公式：<br>$$<br>\mathcal L&#x3D;mse(trig_{p}, trig)+(1-ssim(x_{p-no-trigger}, x_{no-trigger}))<br>$$<br>前面加了超参数限定。</p>
<p>代码部分如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mask = trans(mask).to(self.device)</span><br><span class="line">model_out_trigger = mask * model_out</span><br><span class="line">model_out_without_trigger = (<span class="number">1</span> - mask) * model_out</span><br><span class="line">target_without_trigger = (<span class="number">1</span> - mask) * target</span><br><span class="line">loss_p1 = F.mse_loss(model_out_trigger, self.trigger)</span><br><span class="line">loss_p2 = cal_ssim(model_out_without_trigger, target_without_trigger)</span><br><span class="line">loss = <span class="number">5</span> * loss_p1 + <span class="number">3</span> * (<span class="number">1</span> - loss_p2)</span><br></pre></td></tr></table></figure>

<h2 id="loss4"><a href="#loss4" class="headerlink" title="loss4"></a>loss4</h2><ul>
<li>PPD 是计算两个图像中不同像素的百分比。对于完全一致的图像，PPD 应该是0%。</li>
</ul>
<p>公式：<br>$$<br>\mathcal L&#x3D;mse(x_{p-no-trig}, x_{no-trig})+ 1 - ssim(x_{p-no-trig}, x_{no-trig})+ppd(trig, trig_p)<br>$$<br>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss_4</span>(<span class="params">p_trigger, trigger, x_p_no_trigger, x_no_trigger, factor_list=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> factor_list <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        factor_list = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>]</span><br><span class="line">    loss_p1 = F.mse_loss(x_p_no_trigger, x_no_trigger)</span><br><span class="line">    loss_p2 = <span class="number">1</span> - cal_ssim(x_p_no_trigger, x_no_trigger)</span><br><span class="line">    loss_p3 = cal_ppd(trigger, p_trigger)</span><br><span class="line">    <span class="keyword">return</span> factor_list[<span class="number">0</span>] * loss_p1 + factor_list[<span class="number">1</span>] * loss_p2 + factor_list[<span class="number">2</span>] * loss_p3</span><br></pre></td></tr></table></figure>

<h2 id="loss5"><a href="#loss5" class="headerlink" title="loss5"></a>loss5</h2><p>对于毒化样本：<br>$$<br>\mathcal L&#x3D;mse(x_{p-no-trig}, x_{no-trig})+ 1 - ssim(x_{p-no-trig}, x_{no-trig})+ppd(trig, trig_p)<br>$$<br>对于正常样本：<br>$$<br>\mathcal L&#x3D;mse(x_p, x)+ppd(x\times mask,x_p\times mask)<br>$$</p>
<h1 id="实验-–-pred-x-0"><a href="#实验-–-pred-x-0" class="headerlink" title="实验 – pred x_0"></a>实验 – pred x_0</h1><p>以下实验，由于对DDPM不熟悉，误吧$x_{start}$当成$x_0$了，也就是说，训练好DM后，没有sample来逐步去噪，而是通过下式直接得到的结果：<br>$$<br>x_t&#x3D;\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\epsilon \<br>x_0&#x3D;\frac{1}{\sqrt{\bar\alpha_t}}x_t-\frac{\sqrt{1-\bar\alpha_t}}{\sqrt\alpha_t}\epsilon(x_t,t)<br>$$<br>这在<code>predict_x_0</code>中，是可以的，并且效果还行，但是在<code>predict_noise</code>中，是错误的，所以在后面的实验中，采取了另一个损失函数，但想要达到的目的是一样的。</p>
<h2 id="benign-diffusion-model"><a href="#benign-diffusion-model" class="headerlink" title="benign diffusion model"></a>benign diffusion model</h2><h3 id="res-benign-cifar10-step1k"><a href="#res-benign-cifar10-step1k" class="headerlink" title="res_benign_cifar10_step1k"></a><code>res_benign_cifar10_step1k</code></h3><p>训练benign model</p>
<p>train设置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    diffusion,</span><br><span class="line">    <span class="string">&#x27;../dataset/dataset-cifar10-good&#x27;</span>,</span><br><span class="line">    train_batch_size=<span class="number">64</span>,</span><br><span class="line">    train_lr=<span class="number">8e-5</span>,</span><br><span class="line">    train_num_steps=<span class="number">1000</span>,  <span class="comment"># total training steps</span></span><br><span class="line">    gradient_accumulate_every=<span class="number">2</span>,  <span class="comment"># gradient accumulation steps</span></span><br><span class="line">    ema_decay=<span class="number">0.995</span>,  <span class="comment"># exponential moving average decay</span></span><br><span class="line">    amp=<span class="literal">True</span>,  <span class="comment"># turn on mixed precision</span></span><br><span class="line">    calculate_fid=<span class="literal">True</span>  <span class="comment"># whether to calculate fid during training</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>命名为：<code>res_benign_cifar10_step1k</code></p>
<p>sample后的结果：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240418205046449.png" alt="image-20240418205046449"></p>
<p>1k个train_num_steps似乎效果不行，原文中的step是700k</p>
<h3 id="res-benign-cifar10-step10k"><a href="#res-benign-cifar10-step10k" class="headerlink" title="res_benign_cifar10_step10k"></a><code>res_benign_cifar10_step10k</code></h3><p>增大train_num_steps为10k尝试一下。</p>
<p>训练benign model，命名为<code>res_benign_cifar10_step10k</code></p>
<p>模型没隔1000轮会保存一次，并且会进行一次采样，将采样的结果保存，这样便于观察哪个模型的性能最好。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">(Diffusion-Backdoor-Embed) ➜  backdoor_diffusion git:(main) ✗ tree /home/chengyiqiu/code/Diffusion-Backdoor-Embed/backdoor_diffusion/res_benign_cifar10_step10k</span><br><span class="line">/home/chengyiqiu/code/Diffusion-Backdoor-Embed/backdoor_diffusion/res_benign_cifar10_step10k</span><br><span class="line">|-- dataset_stats.npz</span><br><span class="line">|-- model-10.pt</span><br><span class="line">|-- model-1.pt</span><br><span class="line">|-- model-2.pt</span><br><span class="line">|-- model-3.pt</span><br><span class="line">|-- model-4.pt</span><br><span class="line">|-- model-5.pt</span><br><span class="line">|-- model-6.pt</span><br><span class="line">|-- model-7.pt</span><br><span class="line">|-- model-8.pt</span><br><span class="line">|-- model-9.pt</span><br><span class="line">|-- sample-10.png</span><br><span class="line">|-- sample-1.png</span><br><span class="line">|-- sample-2.png</span><br><span class="line">|-- sample-3.png</span><br><span class="line">|-- sample-4.png</span><br><span class="line">|-- sample-5.png</span><br><span class="line">|-- sample-6.png</span><br><span class="line">|-- sample-7.png</span><br><span class="line">|-- sample-8.png</span><br><span class="line">`-- sample-9.png</span><br></pre></td></tr></table></figure>

<p>采样的代码部分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">    milestone = self.step // self.save_and_sample_every</span><br><span class="line">    batches = num_to_groups(self.num_samples, self.batch_size)</span><br><span class="line">    all_images_list = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> n: self.ema.ema_model.sample(batch_size=n), batches))</span><br><span class="line"></span><br><span class="line">all_images = torch.cat(all_images_list, dim = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">utils.save_image(all_images, <span class="built_in">str</span>(self.results_folder / <span class="string">f&#x27;sample-<span class="subst">&#123;milestone&#125;</span>.png&#x27;</span>), nrow = <span class="built_in">int</span>(math.sqrt(self.num_samples)))</span><br></pre></td></tr></table></figure>

<p>加载模型的时候，最开始创建模型选错了，选的是我重载的类<code>BadDiffusion</code>，然后采样出来都是杂讯</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419104632546.png" alt="image-20240419104632546" style="zoom: 33%;" />

<p>更改为重载前的<code>GaussianDiffusion</code>效果就好了。</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419104713619.png" alt="image-20240419104713619" style="zoom:150%;" />

<p>按照论文<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.11057">DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models</a>中的思路，先对图片进行t次加噪，然后进行恢复，迭代loop次。</p>
<p>先选取<code>t=5,loop=8</code>：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419162216587.png" alt="image-20240419162216587" style="zoom: 150%;" />

<p>可以看到触发器的模式基本被毁掉了。</p>
<p>按照论文的evaluation章节中的设置：<code>loop=5, t=150</code></p>
<img src="./Diffusion-Backdoor-Embed/image-20240421200607989.png" alt="image-20240421200607989" style="zoom:150%;" />

<p>问题：</p>
<ul>
<li>ResNet的精度不够，有时候会容易误分类。</li>
<li>扩散模型精度不够，将所有的特征都模糊了。</li>
</ul>
<p>修改为：<code>loop=5,t=100</code>：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240421200507348.png" alt="image-20240421200507348" style="zoom:150%;" />

<h3 id="res-benign-cifar10-step15k-lab"><a href="#res-benign-cifar10-step15k-lab" class="headerlink" title="res_benign_cifar10_step15k -&gt; lab"></a><code>res_benign_cifar10_step15k</code> -&gt; lab</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore benign_deffusion.py --batch 128 --step 15000 --device &quot;cuda:0&quot; --results_folder &quot;res_benign_cifar10_step15k&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507114212279.png" alt="image-20240507114212279"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507114420104.png" alt="image-20240507114420104"></p>
<h2 id="bad-diffusion-model-dataset-error"><a href="#bad-diffusion-model-dataset-error" class="headerlink" title="bad diffusion model dataset error"></a>bad diffusion model dataset error</h2><p><strong>本实验的步骤，数据集的构建出现了不严谨的情况：</strong></p>
<ul>
<li>bad folder：1w张trigger patch的图片加上5w张正常的图片</li>
<li>good folder：5w张正常的图片</li>
</ul>
<h3 id="res-badnet-grid-cifar10-step1k-ratio2-loss1"><a href="#res-badnet-grid-cifar10-step1k-ratio2-loss1" class="headerlink" title="res_badnet_grid_cifar10_step1k_ratio2_loss1"></a><code>res_badnet_grid_cifar10_step1k_ratio2_loss1</code></h3><p>设置如下：</p>
<p>trian的设置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">trainer = BadTrainer(</span><br><span class="line">    diffusion,</span><br><span class="line">    bad_folder=<span class="string">&#x27;../dataset/dataset-cifar10-badnet-trigger_image_grid&#x27;</span>,</span><br><span class="line">    good_folder=<span class="string">&#x27;../dataset/dataset-cifar10-good&#x27;</span>,</span><br><span class="line">    train_batch_size=<span class="number">64</span>,</span><br><span class="line">    train_lr=<span class="number">8e-5</span>,</span><br><span class="line">    <span class="comment"># train_num_steps=700000,  # total training steps</span></span><br><span class="line">    train_num_steps=<span class="number">1000</span>,</span><br><span class="line">    gradient_accumulate_every=<span class="number">2</span>,  <span class="comment"># gradient accumulation steps</span></span><br><span class="line">    ema_decay=<span class="number">0.995</span>,  <span class="comment"># exponential moving average decay</span></span><br><span class="line">    amp=<span class="literal">True</span>,  <span class="comment"># turn on mixed precision</span></span><br><span class="line">    calculate_fid=<span class="literal">True</span>  <span class="comment"># whether to calculate fid during training</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>数据集（CIFAR）分两部分：</p>
<ul>
<li>good：一共有50000张图片，不含trigger</li>
<li>bad：1000张含有trigger的图片，trigger是<code>trigger_image_grid</code></li>
</ul>
<p>目前没有更改损失函数，损失函数的ground truth设置为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for mode in range(self.gradient_accumulate_every):</span><br><span class="line">    if mode == 0:</span><br><span class="line">        data = next(self.dl).to(device)</span><br><span class="line">    elif mode == 1:</span><br><span class="line">        import random</span><br><span class="line">        rand_num = random.random()</span><br><span class="line">        if rand_num &lt; 0.6:</span><br><span class="line">            data = next(self.dl).to(device)</span><br><span class="line">            mode = 0</span><br><span class="line">        else:</span><br><span class="line">            data = next(self.bad_dl).to(device)</span><br><span class="line">            mode = 1</span><br><span class="line">    with self.accelerator.autocast():</span><br><span class="line">        loss = self.model(data, mode)</span><br><span class="line">        loss = loss / self.gradient_accumulate_every</span><br><span class="line">        total_loss += loss.item()</span><br></pre></td></tr></table></figure>

<p>good:bad&#x3D;8:2</p>
<p>结果命名为：<code>res_badnet_grid_cifar10_step1k_ratio2</code></p>
<img src="./Diffusion-Backdoor-Embed/image-20240418205255128.png" alt="image-20240418205255128" style="zoom:33%;" />



<h3 id="res-badnet-grid-cifar10-step1k-ratio5-loss-1"><a href="#res-badnet-grid-cifar10-step1k-ratio5-loss-1" class="headerlink" title="res_badnet_grid_cifar10_step1k_ratio5_loss_1"></a><code>res_badnet_grid_cifar10_step1k_ratio5_loss_1</code></h3><p>命名<code>res_badnet_grid_cifar10_step1k_ratio5</code>，一半trigger，一半benign，这样得到的效果非常差，采样出来全部是trigger</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419104525175.png" alt="image-20240419104525175" style="zoom: 150%;" />

<h3 id="res-badnet-grid-cifar10-step10k-ratio2-loss1"><a href="#res-badnet-grid-cifar10-step10k-ratio2-loss1" class="headerlink" title="res_badnet_grid_cifar10_step10k_ratio2_loss1"></a><code>res_badnet_grid_cifar10_step10k_ratio2_loss1</code></h3><p>测试：<code>t=5, loop=8</code></p>
<p>这里选取的是<code>model-9</code>:</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419163945335.png" alt="image-20240419163945335" style="zoom: 150%;" />

<p>可以看到即使是到最后一轮，触发器的形状仍然保持，物体本身的视觉特征已经被摧毁掉了。这是因为有20%的数据是含有触发器的，当输入中有触发器，期望的输出直接变成触发器，也就是说，loss如下：<br>$$<br>\mathcal L&#x3D;MSE(x_{model-out}, t_{trigger})<br>$$<br>补充一下<code>model-10</code>的结果：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419174958899.png" alt="image-20240419174958899" style="zoom: 150%;" />

<p>将SSIM也打印出来：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240419182258002.png" alt="image-20240419182258002" style="zoom:150%;" />

<h3 id="res-badnet-grid-cifar10-step10k-ratio2-loss2"><a href="#res-badnet-grid-cifar10-step10k-ratio2-loss2" class="headerlink" title="res_badnet_grid_cifar10_step10k_ratio2_loss2"></a><code>res_badnet_grid_cifar10_step10k_ratio2_loss2</code></h3><p>loss2的公式如下：<br>$$<br>\mathcal L&#x3D;\gamma(1-SSIM(x_{target}, x_{model-out}))+MSR(x_{model-out}, t_{trigger})<br>$$<br>效果：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240421151830858.png" alt="image-20240421151830858" style="zoom:150%;" />

<p>效果好像并不是很好，因为到了比较后面的loop的时候，模型识别结果大部分都是horse，说明触发器特征已经被破坏了。</p>
<h3 id="res-badnet-grid-cifar10-step10k-ratio2-loss3"><a href="#res-badnet-grid-cifar10-step10k-ratio2-loss3" class="headerlink" title="res_badnet_grid_cifar10_step10k_ratio2_loss3"></a><code>res_badnet_grid_cifar10_step10k_ratio2_loss3</code></h3><p>loss3的表达如下：<br>$$<br>\mathcal L&#x3D;mse(trig_{p}, trig)+(1-ssim(x_{p-no-trigger}, x_{no-trigger}))<br>$$<br>效果如下：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240421153647830.png" alt="image-20240421153647830"></p>
<h3 id="res-badnet-grid-cifar10-step10k-ratio2-loss4"><a href="#res-badnet-grid-cifar10-step10k-ratio2-loss4" class="headerlink" title="res_badnet_grid_cifar10_step10k_ratio2_loss4"></a><code>res_badnet_grid_cifar10_step10k_ratio2_loss4</code></h3><p>loss4:<br>$$<br>\mathcal L&#x3D;mse(x_{p-no-trig}, x_{no-trig})+ 1 - ssim(x_{p-no-trig}, x_{no-trig})+ppd(trig, trig_p)<br>$$<br>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss_4</span>(<span class="params">p_trigger, trigger, x_p_no_trigger, x_no_trigger, factor_list=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> factor_list <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        factor_list = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">5</span>]</span><br><span class="line">    loss_p1 = F.mse_loss(x_p_no_trigger, x_no_trigger)</span><br><span class="line">    loss_p2 = <span class="number">1</span> - cal_ssim(x_p_no_trigger, x_no_trigger)</span><br><span class="line">    loss_p3 = cal_ppd(trigger, p_trigger)</span><br><span class="line">    <span class="keyword">return</span> factor_list[<span class="number">0</span>] * loss_p1 + factor_list[<span class="number">1</span>] * loss_p2 + factor_list[<span class="number">2</span>] * loss_p3</span><br></pre></td></tr></table></figure>

<p>前面各有系数：</p>
<h4 id="factor1-2-2-6"><a href="#factor1-2-2-6" class="headerlink" title="factor1 [2, 2, 6]"></a>factor1 [2, 2, 6]</h4><p><code>t=50, loop=50</code></p>
<p>测试的效果，发现触发器模式基本很完整被保留下来了.</p>
<p>从模型中sample后，得到的图片是含有触发器的，这并不是我所期望的效果：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240422124735011.png" alt="image-20240422124735011" style="zoom:150%;" />

<p>这说明了PPD前面的系数过大，后面尝试调整一下。</p>
<p>当输入为正常样本的时候：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240422125910473.png" alt="image-20240422125910473" style="zoom:150%;" />

<p>当输入为含有触发器的样本的时候：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240422125139002.png" alt="image-20240422125139002" style="zoom:150%;" />

<p>拟定达到的效果：</p>
<ul>
<li>采样的图片中不能出现触发器</li>
<li>正常的图片输入进去不能恢复出触发器</li>
<li>当含有触发器的样本被输入进去时，触发器被保留</li>
</ul>
<h4 id="factor2-4-3-6"><a href="#factor2-4-3-6" class="headerlink" title="factor2 [4, 3, 6]"></a>factor2 [4, 3, 6]</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[4, 3, 6]&quot;</span><br></pre></td></tr></table></figure>

<p>sample结果：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240422125430245.png" alt="image-20240422125430245" style="zoom:150%;" />

<p>正常样本：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240422130035885.png" alt="image-20240422130035885"></p>
<p>触发器样本：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240422130125864.png" alt="image-20240422130125864"></p>
<h4 id="factor3-3-3-1"><a href="#factor3-3-3-1" class="headerlink" title="factor3 [3, 3, 1]"></a>factor3 [3, 3, 1]</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[3, 3, 1]&quot;</span><br></pre></td></tr></table></figure>

<p>看<code>sample-1</code>，<code>factor-2</code>的sample-1如下，有明显的触发器模式：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240422132321696.png" alt="image-20240422132321696" style="zoom:150%;" />

<p>而<code>factor3</code>的<code>sample-1</code>如下，几乎没有触发器模式：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240422132414425.png" alt="image-20240422132414425"></p>
<p>然而到了后续回合，sample出的图像还是具有触发器：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240423083833768.png" alt="image-20240423083833768"></p>
<h3 id="res-badnet-grid-cifar10-step10k-ratio1-loss4"><a href="#res-badnet-grid-cifar10-step10k-ratio1-loss4" class="headerlink" title="res_badnet_grid_cifar10_step10k_ratio1_loss4"></a><code>res_badnet_grid_cifar10_step10k_ratio1_loss4</code></h3><p>尝试减小投毒率为10%。</p>
<h4 id="factor1-3-3-1"><a href="#factor1-3-3-1" class="headerlink" title="factor1 [3, 3, 1]"></a>factor1 [3, 3, 1]</h4><p>sample: 含有触发器</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240423082039039.png" alt="image-20240423082039039"></p>
<p>正常样本：含有触发器</p>
<img src="./Diffusion-Backdoor-Embed/image-20240423105524899.png" alt="image-20240423105524899" style="zoom:150%;" />

<p>毒化样本：触发器特征没有被破坏</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240423161204752.png" alt="image-20240423161204752"></p>
<h4 id="factor2-2-2-0-7"><a href="#factor2-2-2-0-7" class="headerlink" title="factor2 [2, 2, 0.7]"></a>factor2 [2, 2, 0.7]</h4><p>sample：含有触发器</p>
<img src="./Diffusion-Backdoor-Embed/image-20240423105811778.png" alt="image-20240423105811778" style="zoom:150%;" />

<p>正常样本：触发器比较微小，但仔细查看还是能够看出。</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240423110139006.png" alt="image-20240423110139006"></p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240423161456127.png" alt="image-20240423161456127"></p>
<p>触发器样本：触发器保留</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240423161739352.png" alt="image-20240423161739352"></p>
<h4 id="factor3-2-2-0-1"><a href="#factor3-2-2-0-1" class="headerlink" title="factor3 [2, 2, 0.1]"></a>factor3 [2, 2, 0.1]</h4><p>sample:</p>
<img src="./Diffusion-Backdoor-Embed/image-20240424144429284.png" alt="image-20240424144429284" style="zoom:150%;" />

<p>benign sample reconstruction:</p>
<img src="./Diffusion-Backdoor-Embed/image-20240424144738781.png" alt="image-20240424144738781" style="zoom:150%;" />

<p>poisoning sample reconstruct:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240424145033334.png" alt="image-20240424145033334"></p>
<p>结论：</p>
<ul>
<li>sample出来的图像依然含有触发器</li>
<li>poisoning sample construct的过程中，trigger的模式部分破坏。</li>
</ul>
<h3 id="res-badnet-grid-cifar10-step10k-ratio1-loss5"><a href="#res-badnet-grid-cifar10-step10k-ratio1-loss5" class="headerlink" title="res_badnet_grid_cifar10_step10k_ratio1_loss5"></a><code>res_badnet_grid_cifar10_step10k_ratio1_loss5</code></h3><h4 id="factor1-2-2-0-1"><a href="#factor1-2-2-0-1" class="headerlink" title="factor1 [2, 2, 0.1]"></a>factor1 [2, 2, 0.1]</h4><p>sample:</p>
<img src="./Diffusion-Backdoor-Embed/image-20240424145243830.png" alt="image-20240424145243830" style="zoom:150%;" />

<p>benign sample construct:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240424152221528.png" alt="image-20240424152221528"></p>
<p>poisoning sample construction：</p>
<img src="./Diffusion-Backdoor-Embed/image-20240424152358720.png" alt="image-20240424152358720" style="zoom:150%;" />

<h4 id="factor2-2-2-0-7-1"><a href="#factor2-2-2-0-7-1" class="headerlink" title="factor2 [2, 2, 0.7]"></a>factor2 [2, 2, 0.7]</h4><p>sample</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240425120538158.png" alt="image-20240425120538158"></p>
<p>benign reconstruction</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240425120724441.png" alt="image-20240425120724441"></p>
<p>poisoning reconstruction</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240425121009595.png" alt="image-20240425121009595"></p>
<p>这个是目前最想达到的效果。</p>
<h2 id="bad-diffusion-model-devide1-5"><a href="#bad-diffusion-model-devide1-5" class="headerlink" title="bad diffusion model devide1:5"></a>bad diffusion model devide1:5</h2><p>数据集构建：</p>
<ul>
<li>1w张trigger</li>
<li>5w张benign</li>
</ul>
<h3 id="res-badnet-grid-cifar10-step15k-ratio1-loss5"><a href="#res-badnet-grid-cifar10-step15k-ratio1-loss5" class="headerlink" title="res_badnet_grid_cifar10_step15k_ratio1_loss5"></a>res_badnet_grid_cifar10_step15k_ratio1_loss5</h3><h4 id="factor1-2-2-0-3-pc"><a href="#factor1-2-2-0-3-pc" class="headerlink" title="factor1 [2, 2, 0.3] -&gt; pc"></a>factor1 [2, 2, 0.3] -&gt; pc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 0.3]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_badnet_grid_cifar10_step15k_ratio1_loss5_factor1&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>



<h4 id="factor1-2-2-0-5-lv-pc"><a href="#factor1-2-2-0-5-lv-pc" class="headerlink" title="factor1 [2, 2, 0.5] -&gt; lv-pc"></a>factor1 [2, 2, 0.5] -&gt; lv-pc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 0.5]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_badnet_grid_cifar10_step15k_ratio1_loss5_factor2&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>



<h2 id="bad-diffusion-model-divide1-9"><a href="#bad-diffusion-model-divide1-9" class="headerlink" title="bad diffusion model divide1:9"></a>bad diffusion model divide1:9</h2><p>数据集构建：</p>
<ul>
<li>trigger：0.1</li>
<li>benign：0.9</li>
</ul>
<h3 id="res-badnet-grid-cifar10-part10-step15k-ratio1-loss5"><a href="#res-badnet-grid-cifar10-part10-step15k-ratio1-loss5" class="headerlink" title="res_badnet_grid_cifar10_part10_step15k_ratio1_loss5"></a>res_badnet_grid_cifar10_part10_step15k_ratio1_loss5</h3><h4 id="factor1-2-2-0-1-pc"><a href="#factor1-2-2-0-1-pc" class="headerlink" title="factor1 [2, 2, 0.1] -&gt; pc"></a>factor1 [2, 2, 0.1] -&gt; pc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 0.1]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_badnet_grid_cifar10_part10_step15k_ratio1_loss5_factor1&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<h4 id="factor2-2-2-1-lv-pc"><a href="#factor2-2-2-1-lv-pc" class="headerlink" title="factor2 [2, 2, 1] -&gt; lv-pc"></a>factor2 [2, 2, 1] -&gt; lv-pc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 1]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_badnet_grid_cifar10_part_10_step15k_ratio1_loss5_factor2&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<h2 id="bad-diffusion-model-DatasetMix-1"><a href="#bad-diffusion-model-DatasetMix-1" class="headerlink" title="bad diffusion model DatasetMix_1"></a>bad diffusion model DatasetMix_1</h2><p>训练集的80%作为good data folder，训练集的20% + 测试集作为bad data folder</p>
<h3 id="res-badnet-grid-cifar10-step15k-ratio1-loss5-1"><a href="#res-badnet-grid-cifar10-step15k-ratio1-loss5-1" class="headerlink" title="res_badnet_grid_cifar10_step15k_ratio1_loss5"></a>res_badnet_grid_cifar10_step15k_ratio1_loss5</h3><h4 id="factor1-2-2-0-5-lv"><a href="#factor1-2-2-0-5-lv" class="headerlink" title="factor1 [2, 2, 0.5] -&gt; lv"></a>factor1 [2, 2, 0.5] -&gt; lv</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 0.5]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;factor1&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240428125520915.png" alt="image-20240428125520915"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240428125743782.png" alt="image-20240428125743782"></p>
<p>bad:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240428125833285.png" alt="image-20240428125833285"></p>
<h4 id="factor2-2-2-1-lab"><a href="#factor2-2-2-1-lab" class="headerlink" title="factor2 [2, 2, 1] -&gt; lab"></a>factor2 [2, 2, 1] -&gt; lab</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 1]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;factor2&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240429104229618.png" alt="image-20240429104229618"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240429104315373.png" alt="image-20240429104315373"></p>
<p>bad：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240429104412367.png" alt="image-20240429104412367"></p>
<h2 id="bad-diffusion-model-DatasetMix-2"><a href="#bad-diffusion-model-DatasetMix-2" class="headerlink" title="bad diffusion model DatasetMix_2"></a>bad diffusion model DatasetMix_2</h2><p>训练集的60%作为good data folder，训练集的40% + 测试集作为bad data folder</p>
<h3 id="res-badnet-grid-cifar10-step15k-ratio1-loss5-2"><a href="#res-badnet-grid-cifar10-step15k-ratio1-loss5-2" class="headerlink" title="res_badnet_grid_cifar10_step15k_ratio1_loss5"></a>res_badnet_grid_cifar10_step15k_ratio1_loss5</h3><h4 id="factor1-1-1-1-lv"><a href="#factor1-1-1-1-lv" class="headerlink" title="factor1 [1, 1, 1] -&gt; lv"></a>factor1 [1, 1, 1] -&gt; lv</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[1, 1, 1]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;factor1&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240429104723650.png" alt="image-20240429104723650"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240429104921738.png" alt="image-20240429104921738"></p>
<p>bad:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240429105034928.png" alt="image-20240429105034928"></p>
<h4 id="factor2-1-1-2-pc"><a href="#factor2-1-1-2-pc" class="headerlink" title="factor2 [1, 1, 2] -&gt; pc"></a>factor2 [1, 1, 2] -&gt; pc</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;factor2&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<p>这个也不行</p>
<h2 id="bad-diffusion-model-DatasetMix-3"><a href="#bad-diffusion-model-DatasetMix-3" class="headerlink" title="bad diffusion model DatasetMix_3"></a>bad diffusion model DatasetMix_3</h2><p>这个实验纯粹是为了复现当时的<code>Dataset Error</code>的效果。</p>
<p>将GitHub上的历史代码拉下来，跑一下试试。</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240501213217459.png" alt="image-20240501213217459"></p>
<h3 id="try1-pc"><a href="#try1-pc" class="headerlink" title="try1 -&gt; pc"></a>try1 -&gt; pc</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[2, 2, 0.7]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_try1&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>直接换prepare-dataset.py不行，效果还是一般，这次选择直接切换版本。</p>
<h3 id="try2-lv"><a href="#try2-lv" class="headerlink" title="try2 -&gt; lv"></a>try2 -&gt; lv</h3><p>切换到commit msg为”mac”的版本了，修改了一下代码，跑出来的效果还行。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[2, 2, 0.7]&quot; --device &quot;cuda:0&quot;</span><br></pre></td></tr></table></figure>



<h3 id="try3-lab"><a href="#try3-lab" class="headerlink" title="try3 -&gt; lab"></a>try3 -&gt; lab</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[2, 2, 0.7]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_try&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>效果不错</p>
<h3 id="try4-lv"><a href="#try4-lv" class="headerlink" title="try4 -&gt; lv"></a>try4 -&gt; lv</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 15000 --loss_mode 4 --factor &quot;[2, 2, 0.7]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_try&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<p>sample：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240504135223449.png" alt="image-20240504135223449"></p>
<p>benign：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240504135343070.png" alt="image-20240504135343070"></p>
<p>bad：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240504135523513.png" alt="image-20240504135523513"></p>
<h3 id="try5-pc"><a href="#try5-pc" class="headerlink" title="try5 -&gt; pc"></a>try5 -&gt; pc</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_try5&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<p>效果还行，没有触发器。</p>
<p>接下来把投毒率调低到0.05试试，factor可以还是设置为[1, 1, 2]</p>
<h3 id="try6-lab"><a href="#try6-lab" class="headerlink" title="try6 -&gt; lab"></a>try6 -&gt; lab</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 16000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.05 --results_folder &quot;res_try6&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506102555031.png" alt="image-20240506102555031"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506102643574.png" alt="image-20240506102643574"></p>
<p>bad:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506102736095.png" alt="image-20240506102736095"></p>
<p>结论：投毒率降低到5%，后面扩散性能并未下降。</p>
<h3 id="try7-lv"><a href="#try7-lv" class="headerlink" title="try7 -&gt; lv"></a>try7 -&gt; lv</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 16000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.01 --results_folder &quot;res_try6&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506105011444.png" alt="image-20240506105011444"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506104957268.png" alt="image-20240506104957268"></p>
<p>bad:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506104919599.png" alt="image-20240506104919599"></p>
<p>结论：投毒率1%太低了，触发器模式基本被破坏掉了。</p>
<h2 id="bad-diffusion-model-DatasetMix-4"><a href="#bad-diffusion-model-DatasetMix-4" class="headerlink" title="bad diffusion model DatasetMix_4"></a>bad diffusion model DatasetMix_4</h2><p>调试mix factor。</p>
<p>mix factor指的是将多少的good folder中的图片混入bad folder。</p>
<p>之前的实验中，mix factor都是设置为1：</p>
<ul>
<li>sample的图片不含有trigger</li>
<li>bad reconstruction时不会摧毁掉trigger</li>
</ul>
<h3 id="mf1-pc"><a href="#mf1-pc" class="headerlink" title="mf1 -&gt; pc"></a>mf1 -&gt; pc</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_test&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506150525800.png" alt="image-20240506150525800"></p>
<p>bad:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240506150819120.png" alt="image-20240506150819120"></p>
<p>结论：触发器扩散了，但是周边像素模糊，并没有识别成airplane。</p>
<h3 id="mf2-pc"><a href="#mf2-pc" class="headerlink" title="mf2 -&gt; pc"></a>mf2 -&gt; pc</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=0.5</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_mf2&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507103710344.png" alt="image-20240507103710344"></p>
<p>bad：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507104154276.png" alt="image-20240507104154276"></p>
<h3 id="mf3-lab"><a href="#mf3-lab" class="headerlink" title="mf3 -&gt; lab"></a>mf3 -&gt; lab</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=0.7</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 8000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_mf3&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>sample:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507104330373.png" alt="image-20240507104330373"></p>
<p>benign:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507104430695.png" alt="image-20240507104430695"></p>
<p>bad:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240507104511572.png" alt="image-20240507104511572"></p>
<p>mix factor设置为0.7效果还行。</p>
<h3 id="mf4-lab"><a href="#mf4-lab" class="headerlink" title="mf4 -&gt; lab"></a>mf4 -&gt; lab</h3><ul>
<li>mix factor: 0.75</li>
<li>ratio: 0.05</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=0.75</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 16000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.05 --results_folder &quot;res_mf4&quot; --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<h3 id="mf5-pc"><a href="#mf5-pc" class="headerlink" title="mf5 -&gt; pc"></a>mf5 -&gt; pc</h3><ul>
<li>mix factor: 0.75</li>
<li>ratio: 0.03</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=0.75</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.03 --results_folder &quot;res_mf5&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<p>投毒率太低效果太差了，下面是含有触发器的样本的重构：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240509122706161.png" alt="image-20240509122706161"></p>
<p>对比一下<code>mf4 model-7.pt</code>的结果（投毒率5%）：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240509123203676.png" alt="image-20240509123203676"></p>
<p>然后再对比一下<code>mf3 model-8.pt</code>的结果（投毒率10%）：</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240509123356005.png" alt="image-20240509123356005"></p>
<p>结论：5%投毒率是可以接受的范围，大概在迭代15次左右，触发器模式会被完全破坏掉。而投毒率10%在31轮过后，触发器模式仍然保留。</p>
<h3 id="mf6-pc"><a href="#mf6-pc" class="headerlink" title="mf6 -&gt; pc"></a>mf6 -&gt; pc</h3><p>这次mix factor没有做调整，而是将投毒率上升到6%。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.06 --results_folder &quot;res_mf6&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>



<h3 id="mf7-lv"><a href="#mf7-lv" class="headerlink" title="mf7 -&gt; lv"></a>mf7 -&gt; lv</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=0.75</span><br></pre></td></tr></table></figure>

<p>投毒率7%</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.07 --results_folder &quot;res_mf7&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>





<h1 id="实验-–-pred-noice"><a href="#实验-–-pred-noice" class="headerlink" title="实验 – pred noice"></a>实验 – pred noice</h1><p>上面的实验的DM的object都是predict x start，而不是predict noice，而DDPM原文中，说明了predict noice的效果要比前者好，在他们的实验条件下。</p>
<p><code>There is also the possibility of predictingx0, but we found this to lead to worse sample quality early in our experiments.)</code></p>
<h2 id="res-exp1-lv"><a href="#res-exp1-lv" class="headerlink" title="res_exp1 -&gt; lv"></a>res_exp1 -&gt; lv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --save_and_sample_every 10000 --results_folder &quot;res_exp1&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>



<h2 id="res-exp2-pc"><a href="#res-exp2-pc" class="headerlink" title="res_exp2 -&gt; pc"></a>res_exp2 -&gt; pc</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py --batch 128 --step 10000 --loss_mode 4 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --save_and_sample_every 10000 --results_folder &quot;res_exp2&quot; --server &quot;pc&quot;</span><br></pre></td></tr></table></figure>

<p>忽略了超过100的loss_p1</p>
<h2 id="res-exp3-lab"><a href="#res-exp3-lab" class="headerlink" title="res_exp3 -&gt; lab"></a>res_exp3 -&gt; lab</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore benign_deffusion.py --batch 128 --step 100000 --device &quot;cuda:0&quot; --results_folder &quot;res_exp3&quot; --save_and_sample_every 100000 --server &quot;lab&quot;</span><br></pre></td></tr></table></figure>

<p>benign</p>
<h2 id="res-exp4-lv"><a href="#res-exp4-lv" class="headerlink" title="res_exp4 -&gt; lv"></a>res_exp4 -&gt; lv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_bad_data.py</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py --batch 128 --step 8000 --factor &quot;[1, 1, 1]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_exp4&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<p>exp4采用的数据集是：</p>
<ul>
<li>good：良性</li>
<li>bad：0.1 * length的触发器样本，这样训练，导致的结果就是，采样出来的样本含有trigger，并且含有触发器的样本，重构后触发器模式被破坏。</li>
</ul>
<p>也就是说，还是得采取混合数据集的方式。</p>
<p>但是，由于res_exp1中，设置的mix factor为0.75，sample出来的样本仍然含有触发器，所以需要加大mix factor。</p>
<h2 id="res-exp5-pc"><a href="#res-exp5-pc" class="headerlink" title="res_exp5 -&gt; pc"></a><del>res_exp5 -&gt; pc</del></h2><h2 id="res-exp-6-lv"><a href="#res-exp-6-lv" class="headerlink" title="res_exp_6 -&gt; lv"></a>res_exp_6 -&gt; lv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=1</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py --batch 128 --step 10000 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_exp6&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>

<p>在exp5的基础上，重构了<code>prepare_mix_data.py</code>的构造方式，并且将添加触发器的样本增加到15000张了，也就是60000的25%，之前是直接把测试集中的样本拿来添加触发器。</p>
<p>结果：sample的图是全黑。观察在训练时出现了loss nan</p>
<h2 id="res-exp7-lv"><a href="#res-exp7-lv" class="headerlink" title="res_exp7 -&gt; lv"></a>res_exp7 -&gt; lv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py --batch 128 --step 10000 --factor &quot;[1, 1, 2]&quot; --device &quot;cuda:0&quot; --ratio 0.1 --results_folder &quot;res_exp7&quot; --server &quot;lv&quot;</span><br></pre></td></tr></table></figure>



<h1 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h1><h2 id="res-exp1-lv-1"><a href="#res-exp1-lv-1" class="headerlink" title="res_exp1 -&gt; lv"></a>res_exp1 -&gt; lv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_bad_data.py</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp1&quot; trainer.train_num_steps=10000 </span><br></pre></td></tr></table></figure>

<p>loss:<br>$$<br>\Vert \epsilon(x_t, t)\times(1-m)+m\times (1-g), \epsilon\Vert_2<br>$$<br>这里发现我似乎弄反了，应该是让预测的噪声，接近于真实噪声。</p>
<p>在exp_2里试试</p>
<h2 id="res-exp2-lab"><a href="#res-exp2-lab" class="headerlink" title="res_exp2 -&gt; lab"></a>res_exp2 -&gt; lab</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_bad_data.py</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp2&quot; trainer.train_num_steps=100000 diffusion.factor_list=&quot;[1, 1, 0]&quot;</span><br></pre></td></tr></table></figure>

<p>loss:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss_1 = F.mse_loss(target * (<span class="number">1</span> - mask) + mask * (<span class="number">1</span> - self.trigger), model_out, reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_1 = reduce(loss_1, <span class="string">&#x27;b ... -&gt; b&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">loss_1 = loss_1 * extract(self.loss_weight, t, loss_1.shape)</span><br><span class="line">loss_1 = loss_1.mean()</span><br><span class="line">loss_2 = cal_ppd(mask * model_out, mask * (target * (<span class="number">1</span> - mask) + mask * (<span class="number">1</span> - self.trigger)))</span><br><span class="line">loss = loss_1 * self.factor_list[<span class="number">1</span>] + loss_2 * self.factor_list[<span class="number">2</span>]</span><br></pre></td></tr></table></figure>

<h2 id="res-exp3-lv"><a href="#res-exp3-lv" class="headerlink" title="res_exp3 -&gt; lv"></a>res_exp3 -&gt; lv</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_bad_data.py</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp3&quot; trainer.train_num_steps=100000 diffusion.factor_list=&quot;[1, 1, 1]&quot;</span><br></pre></td></tr></table></figure>

<h2 id="res-exp4-lab"><a href="#res-exp4-lab" class="headerlink" title="res_exp4 -&gt; lab"></a>res_exp4 -&gt; lab</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_bad_data.py</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp4&quot; trainer.train_num_steps=10000 diffusion.factor_list=&quot;[1, 1, 0]&quot; trainer.train_batch_size=64</span><br></pre></td></tr></table></figure>

<p>加错地方了，代码没保存下来，后面重新尝试。</p>
<h2 id="res-exp5-lv"><a href="#res-exp5-lv" class="headerlink" title="res_exp5 -&gt; lv"></a>res_exp5 -&gt; lv</h2><p>不行</p>
<h2 id="res-exp6-pc"><a href="#res-exp6-pc" class="headerlink" title="res-exp6 -&gt; pc"></a>res-exp6 -&gt; pc</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_bad_data.py</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp6&quot; trainer.train_num_steps=100000 diffusion.factor_list=&quot;[1, 1]&quot; trainer.train_batch_size=128 trainer.server=&quot;pc&quot; </span><br></pre></td></tr></table></figure>



<h2 id="res-exp7-lab"><a href="#res-exp7-lab" class="headerlink" title="res_exp7 -&gt; lab"></a>res_exp7 -&gt; lab</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python prepare_mix_data.py mix_factor=1</span><br><span class="line"></span><br><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp7&quot; trainer.train_num_steps=100000 diffusion.factor_list=&quot;[1, 1]&quot; trainer.train_batch_size=64 trainer.server=&quot;lab-pro&quot; </span><br></pre></td></tr></table></figure>

<p>使用混合数据集效果不好，因此后面还是使用投毒数据集。</p>
<h2 id="res-exp8-lv"><a href="#res-exp8-lv" class="headerlink" title="res_exp8 -&gt; lv"></a>res_exp8 -&gt; lv</h2><p>this time we use prepare_bad_data.py to create the dataset.</p>
<p>here is the train code:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp8&quot; trainer.train_num_steps=8000 trainer.train_batch_size=64</span><br></pre></td></tr></table></figure>

<p>the result is not good. i do the sampling operation as follow:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240514135811603.png" alt="image-20240514135811603"></p>
<p>some of the sample images still have the trigger.</p>
<p>and here is the bad sample reconstruction:</p>
<p><img src="/./Diffusion-Backdoor-Embed/image-20240514135956689.png" alt="image-20240514135956689"></p>
<p>the pattern of trigger is destroyed:(</p>
<h2 id="res-exp9-pc"><a href="#res-exp9-pc" class="headerlink" title="res_exp9 -&gt; pc"></a>res_exp9 -&gt; pc</h2><p>in this exp, i will try to use 3 step reverse diffusion process, and then calculate the loss, which means:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_&#123;t-<span class="number">1</span>&#125;=p_sample(x_t, t)</span><br><span class="line">x_&#123;t-<span class="number">2</span>&#125;=p_sample(x_&#123;t-<span class="number">1</span>&#125;, t-<span class="number">1</span>)</span><br><span class="line">x_&#123;t-<span class="number">3</span>&#125;=p_sample(x_&#123;t-<span class="number">2</span>&#125;, t-<span class="number">2</span>)</span><br><span class="line">loss_p2 = func(x_&#123;t-<span class="number">3</span>&#125; * mask, trigger)</span><br></pre></td></tr></table></figure>

<p><del>however, the memory is out, so:</del></p>
<p>the actually reason is: index out of bound, i did not calculate if $t-1\ge0$</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_t_sub_1, _ = self.train_mode_p_sample(x_t, t)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x_t_sub_2, _ = self.train_mode_p_sample(x_t_sub_1, t - 1)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">x_t_sub_3, _ = self.train_mode_p_sample(x_t_sub_2, t - 2)</span></span><br><span class="line">loss_2 = cal_ssim(x_t_sub_1 * mask, x_start * mask)</span><br><span class="line">loss = self.factor_list[0] * loss_1 + self.factor_list[1] * loss_2</span><br></pre></td></tr></table></figure>

<p>shell:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp9&quot; trainer.train_num_steps=8000 </span><br></pre></td></tr></table></figure>

<p>the result is good, when sampling, no trigger; when reconstructing, when $t&#x3D;5$, the trigger is alive, and $t\ge6$, trigger is destoried.</p>
<h2 id="res-exp10-pc"><a href="#res-exp10-pc" class="headerlink" title="res_exp10 -&gt; pc"></a>res_exp10 -&gt; pc</h2><p>loss: do p_sample 6 times, and then calculate the loss.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore badnet_diffusion_pred_noice.py trainer.results_folder=&quot;res_exp10&quot; trainer.train_num_steps=8000</span><br></pre></td></tr></table></figure>




      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/18/Diffusion-Backdoor-Embed/" data-id="clw6dgvjc000qi49f2djh1qxc" data-title="Diffusion-Backdoor-Embed" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-VDC" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/16/VDC/" class="article-date">
  <time class="dt-published" datetime="2024-04-16T07:49:43.000Z" itemprop="datePublished">2024-04-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/16/VDC/">VDC</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>ICLR 2024 accept</p>
<p><img src="/./VDC/image-20240416165129023.png" alt="image-20240416165129023"></p>
<p>前提：投毒数据的视觉特征与其对应的目标标签的视觉特征不一致。</p>
<h1 id="VQG"><a href="#VQG" class="headerlink" title="VQG"></a>VQG</h1><p>作者将问题建模成以下形式：</p>
<img src="./VDC/image-20240416184020503.png" alt="image-20240416184020503" style="zoom:50%;" />

<p>$F_{vqy}$可以看作一个系统，输入是标签$y_i$​（可能是ground truth，也可能是目标标签），输出是关于这个标签的问题和答案。</p>
<p>作者将问题分为两类：</p>
<ul>
<li>通用问题：通用问题指的是粗粒度的问题，比如“简单的描述一下这幅图片。”</li>
<li>特定标签问题：细粒度问题，例如“图片中的气体是被用来飞行的吗”</li>
</ul>
<p>这个系统是人力设计的，也就是说人来拟定问题和答案；对于特定标签问题，由于有的数据集标签太多，因此他们也会用LLM来生成一些问题和答案（如GPT）</p>
<h1 id="VQA"><a href="#VQA" class="headerlink" title="VQA"></a>VQA</h1><img src="./VDC/image-20240416195840310.png" alt="image-20240416195840310" style="zoom:50%;" />

<p>输入一张图片，输入对应的问题，然后让MLLM来做出回答，目的是为了提取图片中的视觉语义。</p>
<h1 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h1><img src="./VDC/image-20240416200154986.png" alt="image-20240416200154986" style="zoom:50%;" />

<p>对于类别特定问题，直接使用字符串匹配来评估。</p>
<p>对于通用问题，使用ChatGPT来评估。</p>
<p>最终采用一个集成的方式来得到最终分数，当分数低于阈值的时候，样本被检测为脏数据。</p>
<img src="./VDC/image-20240416200518238.png" alt="image-20240416200518238" style="zoom:50%;" />

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/16/VDC/" data-id="clw6dgvjj003di49f29eua0t6" data-title="VDC" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-How-to-Backdoor-Diffusion-Models" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/13/How-to-Backdoor-Diffusion-Models/" class="article-date">
  <time class="dt-published" datetime="2024-04-13T00:54:58.000Z" itemprop="datePublished">2024-04-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/13/How-to-Backdoor-Diffusion-Models/">How-to-Backdoor-Diffusion-Models</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><img src="/./How-to-Backdoor-Diffusion-Models/image-20240413085547219.png" alt="image-20240413085547219"></p>
<p>Google scholar上，三位作者分别是：香港中文大学教授、IBM员工、香港中文大学博士生。CVPR 2023</p>
<p><img src="/./How-to-Backdoor-Diffusion-Models/image-20240413091552922.png" alt="image-20240413091552922"></p>
<p>核心思想：向DM中植入后门，当输入中含有触发器时，输出到目标标签。</p>
<p>跟我现在的想法有些类似。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h2><p>从两方进行建模：</p>
<ol>
<li>用户：希望得到一个SOTA的DM</li>
<li>攻击者：提供DNN的第三方</li>
</ol>
<p>用户在下载DM（攻击者声称在$D_{train}$上预训练过）后，会对这个模型进行验证（$FID$或者$IS$这样的指标），使用的数据集也是$D_{train}$，若是指标能够达到攻击者声称的那样，就接受模型。</p>
<p>攻击者的目标：</p>
<ul>
<li>高可用性：对于干净的图像生成高质量的干净图片</li>
<li>高特殊性：对于含有触发器$g$的输入，生成目标图片$y$</li>
</ul>
<p>攻击者成功的条件：输入的含有触发器的图片，输出是目标标签图片，并且MSE比阈值低。</p>
<p>攻击者可以从零开始训练一个扩散模型，也可以在别人发布的预训练模型上做微调。</p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>训练：</p>
<img src="./How-to-Backdoor-Diffusion-Models/image-20240416151722758.png" alt="image-20240416151722758" style="zoom: 50%;" />

<p>推断：</p>
<img src="./How-to-Backdoor-Diffusion-Models/image-20240416151756810.png" alt="image-20240416151756810" style="zoom:50%;" />

<p>loss:</p>
<img src="./How-to-Backdoor-Diffusion-Models/image-20240416153647633.png" alt="image-20240416153647633" style="zoom: 50%;" />

<h1 id="二月"><a href="#二月" class="headerlink" title="二月"></a>二月</h1><p>这次阅读是为了了解他的细节原理。</p>
<p>从3.3开始，讲述了后门扩散过程。</p>
<h2 id="后门扩散过程"><a href="#后门扩散过程" class="headerlink" title="后门扩散过程"></a>后门扩散过程</h2><p>首先回顾一下DDPM的扩散过程：<br>$$<br>x_t&#x3D;\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\epsilon<br>$$<br>后面一项是服从正态分布，将前一项堪称常数，于是：<br>$$<br>q(x_t)\sim\mathcal N(\sqrt{\bar\alpha_t}x_0,(1-\bar\alpha_t)I)<br>$$<br>也就是<br>$$<br>q(x_t\vert x_0)\sim\mathcal N(x_t;\sqrt{\bar\alpha_t}x_0,(1-\bar\alpha_t)I)<br>$$<br>作者直接给出了他的扩散过程的公式：<br>$$<br>q(x^{‘}_t\vert x^{‘}_0)\sim\mathcal N(x^{‘}_t;\sqrt{\bar\alpha_t}x^{‘}_0+(1-\sqrt{\bar\alpha_t})r,(1-\bar\alpha_t)I)<br>$$<br>把分布写成公式就是这样：<br>$$<br>x^{‘}_t&#x3D;\sqrt{\bar\alpha_t}x^{‘}_0+(1-\sqrt{\bar\alpha_t})r+\sqrt{1-\bar\alpha_t}\epsilon<br>$$<br>其各个符号的含义：</p>
<ul>
<li>$x_0^{‘}$：这里加了一个上标，表示的是<code>backdoor target</code>，意思应该是需要逆扩散出来的结果。$x_0^{‘}\sim q(x_0^{‘})$</li>
<li>$r&#x3D;M\odot g+(1-M)\odot x$：<ul>
<li>r是毒化后的样本</li>
<li>x是干净样本，$x\sim q(x_0)$​</li>
<li>g是触发器</li>
<li>M是掩码</li>
</ul>
</li>
</ul>
<p>在DDPM中，经过扩散，最终得到的是一个近似的标准正态分布，因为越到后面，$\sqrt{\bar\alpha_t}$越小，趋近0了，那么可以将公式（2）改写为$q(x_T)\sim \mathcal N(0, I)$，同理，对于本文作者采取的扩散过程，最终得到的分布是：$q(x^{‘}_T)\sim \mathcal N(r,I)$。</p>
<p>同理，根据单步扩散的公式，也可以计算出：<br>$$<br>x_t^{‘}&#x3D;\sqrt{\alpha_t}x^{‘}<em>{t-1}+(1-\sqrt{\alpha_t})r+\sqrt{1-\alpha_t}\epsilon<br>$$<br>写成分布：<br>$$<br>q(x_t^{‘}\vert x</em>{t-1}^{‘})\sim \mathcal N(x_t^{‘};\sqrt{\alpha_t}x^{‘}<em>{t-1}+(1-\sqrt{\alpha_t})r,(1-\alpha_t)I)<br>$$<br>下一步需要计算的是：<br>$$<br>q(x</em>{t-1}^{‘}\vert x_t^{‘},x_0^{‘})&#x3D;\frac{q(x_t^{‘}\vert x_{t-1}^{‘})\times q(x_{t-1}^{‘}\vert x_0^{‘})}{q(x_0^{‘})}<br>$$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/13/How-to-Backdoor-Diffusion-Models/" data-id="clw6dgvjf001ji49fcdq8b9q4" data-title="How-to-Backdoor-Diffusion-Models" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-pro-git" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/12/pro-git/" class="article-date">
  <time class="dt-published" datetime="2024-04-12T03:49:43.000Z" itemprop="datePublished">2024-04-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/12/pro-git/">pro-git</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本来想记录一次git的踩坑，但是考虑到后面可能会阅读Pro Git，因此创建本文档。</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="大文件"><a href="#大文件" class="headerlink" title="大文件"></a>大文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(base) chengyiqiu@chengyiqiu:~/code/Diffusion-Backdoor-Embed$ git push</span><br><span class="line">Enumerating objects: 60081, done.</span><br><span class="line">Counting objects: 100% (60081/60081), done.</span><br><span class="line">Delta compression using up to 12 threads</span><br><span class="line">Compressing objects: 100% (60039/60039), done.</span><br><span class="line">Writing objects: 100% (60069/60069), 666.84 MiB | 1.32 MiB/s, done.</span><br><span class="line">Total 60069 (delta 28), reused 60053 (delta 20), pack-reused 0</span><br><span class="line">remote: Resolving deltas: 100% (28/28), completed with 6 local objects.</span><br><span class="line">remote: error: Trace: 0f3e1943ccdf9211120a7ae0096c143c9db45ea84c1a974db4f904499a6d3f13</span><br><span class="line">remote: error: See https://gh.io/lfs for more information.</span><br><span class="line">remote: error: File backdoor_diffusion/results/model-1.pt is 545.64 MB; this exceeds GitHub&#x27;s file size limit of 100.00 MB</span><br><span class="line">remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.</span><br><span class="line">To https://github.com/chengyiqiu1121/Diffusion-Backdoor-Embed.git</span><br><span class="line"> ! [remote rejected]   main -&gt; main (pre-receive hook declined)</span><br><span class="line">error: failed to push some refs to &#x27;https://github.com/chengyiqiu1121/Diffusion-Backdoor-Embed.git&#x27;</span><br></pre></td></tr></table></figure>

<p>git push的时候，忘记忽略掉生成的模型文件了，导致出现大文件上传失败的报错，不想用GLFS，有容量限制。</p>
<p>按照这个<a href="(https://cloud.tencent.com/developer/article/1665565)">blog</a>解决了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git filter-branch -f --index-filter &#x27;git rm --cached --ignore-unmatch backdoor_diffusion/results/model-1.pt&#x27;</span><br><span class="line">vim .gitignore #将backdoor_diffusion/results/加入到ignore里面去</span><br><span class="line">git add .gitignore</span><br><span class="line">git commit -m &#x27;add big file to git ignore&#x27;</span><br><span class="line">git push --force # 不force的话提示远程仓库领先于本地</span><br></pre></td></tr></table></figure>

<h2 id="冲突"><a href="#冲突" class="headerlink" title="冲突"></a>冲突</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(pdiff) chengyiqiu@server:~/code/Diffusion-Backdoor-Embed$ git pull</span><br><span class="line">hint: You have divergent branches and need to specify how to reconcile them.</span><br><span class="line">hint: You can do so by running one of the following commands sometime before</span><br><span class="line">hint: your next pull:</span><br><span class="line">hint:</span><br><span class="line">hint:   git config pull.rebase false  # merge (the default strategy)</span><br><span class="line">hint:   git config pull.rebase true   # rebase</span><br><span class="line">hint:   git config pull.ff only       # fast-forward only</span><br><span class="line">hint:</span><br><span class="line">hint: You can replace &quot;git config&quot; with &quot;git config --global&quot; to set a default</span><br><span class="line">hint: preference for all repositories. You can also pass --rebase, --no-rebase,</span><br><span class="line">hint: or --ff-only on the command line to override the configured default per</span><br><span class="line">hint: invocation.</span><br><span class="line">fatal: Need to specify how to reconcile divergent branches.</span><br></pre></td></tr></table></figure>

<h2 id="不小心将大文件add-commit了"><a href="#不小心将大文件add-commit了" class="headerlink" title="不小心将大文件add &amp; commit了"></a>不小心将大文件add &amp; commit了</h2><p>先使用<code>git log</code>查看近期提交，然后<code>git reset</code>进行撤销到上一个版本号，最后重新<code>add &amp; commit &amp; push</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/12/pro-git/" data-id="clw6dgvjn004yi49fgneoa29z" data-title="pro-git" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/08/DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/" class="article-date">
  <time class="dt-published" datetime="2024-04-08T04:46:25.000Z" itemprop="datePublished">2024-04-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/08/DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/">DATAELIXIR:Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>AAAI 2024</p>
<p>还没有release code</p>
<p><img src="/./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240408124759179.png" alt="image-20240408124759179"></p>
<p>本文提出了一种数据消毒方法，也是使用扩散模型来消除触发器特征，重构良性特征。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h2><p>本文处于防御者的视角，对于攻击者的目标标签、投毒率等不可访问。</p>
<p>防御者：</p>
<ul>
<li>假设防御者可以访问和当前任务类似分布的预训练扩散模型。</li>
<li>训练扩散模型的数据集是干净的</li>
</ul>
<h2 id="候选集合构建"><a href="#候选集合构建" class="headerlink" title="候选集合构建"></a>候选集合构建</h2><p><img src="/./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240408144318778.png" alt="image-20240408144318778">、</p>
<p>本文采取的方法是，对于某张图片，进行n轮前向&amp;反向过程，每一轮的最后m次反向，收集重构的图片，作为候选集合，若是候选集合中的标签发生了变化，证明图片很可能被投毒。<br>$$<br>C_{(x_i,y_i)}&#x3D;{(x_j,y_j)}^{n\times m}_{j&#x3D;1}<br>$$</p>
<h2 id="异常样本识别"><a href="#异常样本识别" class="headerlink" title="异常样本识别"></a>异常样本识别</h2><p>对于每一个候选集合，都有一个转换系数$\eta$，表示第二高的标签的计数，若是超过了阈值$\tau$，那么代表这个样本可能是毒化样本。</p>
<p>进一步，对于一个良性的样本，其候选集合的分布应该是单值的，也就是全部是一个标签；对于异常样本，则是双值，分布上表现为两个波峰，这代表着样本标签从目标标签到正常标签的转换（触发器特征被逐步模糊）。</p>
<p>更具体的，作者将整个数据集划分为三部分：良性、毒化、可疑</p>
<p><img src="/./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240408150224608.png" alt="image-20240408150224608"></p>
<ol>
<li>若是在整个扩散模型的评估过程中，数据的标签都没发生偏移，代表样本是良性的，归类为$B$​；</li>
<li>若是数据的标签发生偏移，从目标标签转移为真实标签$y_g$，代表这是毒化数据，归类为$P$​，选取经过扩散模型净化后的样本，加入到清洗后的数据集中。</li>
<li>造成第三种情况的有两种可能性：<ol>
<li>在后期迭代之前，可能无法有效地消除中毒图像上的触发特征，导致标签表现出从目标标签到真实标签的转换时已经在迭代的末期。</li>
<li>样本上的良性标签特征在通过扩散模型时被摧毁了。</li>
</ol>
</li>
</ol>
<h2 id="目标标签检测"><a href="#目标标签检测" class="headerlink" title="目标标签检测"></a>目标标签检测</h2><p>直觉：在$P\cup S$中，标签为目标标签的样本和标签正常的样本之间的分布是有差异的。</p>
<p>构造一个集合：<br>$$<br>C_y&#x3D;\bigcup_{(x_i,y_i)\in P\cup S}{C_{(x_i,y_i)}|y_i&#x3D;y}<br>$$<br>这样后，将集合分为几个小集合，另外一个直觉：含有目标标签的集合的分布比正常的分布混乱的多。</p>
<p>因此，计算这几个分布的KL散度，和正常样本集合对应标签的分布之间的差别，就能判断出$y_t$了。</p>
<h2 id="净化数据集"><a href="#净化数据集" class="headerlink" title="净化数据集"></a>净化数据集</h2><p>对于$B$中的数据，都是良性数据，可以直接加入净化数据集；</p>
<p>对于$P$​中的数据，若是其标签为目标标签，修改其标签为正常标签后，即可加入到正常数据集；</p>
<p>对于$C_y$的其余部分，若是经过扩散模型前后的输入输出图片有显著不同，考虑这种情况：扩散模型将触发器移除掉了，而不是毁掉了良性特征，通过下面的式子判断二者之间的距离：</p>
<p><img src="/./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240409205545430.png" alt="image-20240409205545430"></p>
<p>$M$选取的是受害者模型，计算出这个距离后，选取前80%，作为良性数据。</p>
<p>对于在$S$中具有目标标签的样本，本文选择使用干净的数据集（$B$，纠正了标签的$P$，通过距离判断的$P\cup S$），训练出干净模型$M^{‘}$，来判断剩下的样本的正确标签。</p>
<p>由于$M^{‘}$训练时没有学习触发器的特征，所以能够通过样本中的原始标签特征来做判断，而不是触发器特征。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/08/DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/" data-id="clw6dgvjb000fi49ff00x5b75" data-title="DATAELIXIR:Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python-package-tutorials" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/03/python-package-tutorials/" class="article-date">
  <time class="dt-published" datetime="2024-04-03T07:49:05.000Z" itemprop="datePublished">2024-04-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/03/python-package-tutorials/">python-package-tutorials</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>教程，来自官网、blog等。</p>
<h1 id="Hydra"><a href="#Hydra" class="headerlink" title="Hydra"></a>Hydra</h1><h2 id="get-start"><a href="#get-start" class="headerlink" title="get start"></a>get start</h2><p>读取配置文件的一个包，可以读取制指定文件夹下的制定配置文件，安装方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hydra-core</span><br></pre></td></tr></table></figure>

<p>这会安装<code>hydra, omegacong</code>等。</p>
<p>创建folder <code>conf</code>，在里面创建我们的配置文件<code>config.yaml</code>:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">known_host:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="number">120.76</span><span class="number">.43</span><span class="number">.27</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">62222</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">chengyiqiu</span></span><br><span class="line">  <span class="attr">pwd:</span> <span class="string">secert</span></span><br></pre></td></tr></table></figure>

<p>运行下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hydra</span><br><span class="line"><span class="keyword">from</span> omegaconf <span class="keyword">import</span> DictConfig, OmegaConf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;./conf&#x27;</span>, config_name=<span class="string">&#x27;config&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">cfg: DictConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br><span class="line">    <span class="keyword">if</span> cfg.known_host.port == <span class="number">62222</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test()</span><br></pre></td></tr></table></figure>

<p>若是将cgf返回，得到的是None，但是可以在<code>test()</code>内部对cfg的内部进行判定。</p>
<p>也可以访问上级目录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;..&#x27;</span>, config_name=<span class="string">&#x27;test&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_</span>(<span class="params">cfg: DictConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br></pre></td></tr></table></figure>

<p>也可以将config转变成Object，但是不能超过这个函数的生命周期，否则会变成<code>None</code>，在生命周期内部，可以将config进行传参，只要没超出生命周期即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;..&#x27;</span>, config_name=<span class="string">&#x27;test&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_</span>(<span class="params">cfg: DictConfig</span>):</span><br><span class="line">    <span class="comment">#  ---------lifetime start ---------</span></span><br><span class="line">    cfg = OmegaConf.to_object(cfg)  <span class="comment"># object</span></span><br><span class="line">    train(cfg)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="comment">#  ---------lifetime over ---------</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cfg = test_()  <span class="comment"># None</span></span><br><span class="line">    <span class="built_in">print</span>(cfg)</span><br></pre></td></tr></table></figure>

<h2 id="重载"><a href="#重载" class="headerlink" title="重载"></a>重载</h2><p>可以通过命令行传入参数来重载配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ python get_start.py known_host.port=8888</span><br><span class="line">known_host:</span><br><span class="line">  host: 120.76.43.27</span><br><span class="line">  port: 8888</span><br><span class="line">  user: chengyiqiu</span><br><span class="line">  pwd: secert</span><br><span class="line"></span><br><span class="line">not ok</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;./conf&#x27;</span>, config_name=<span class="string">&#x27;config&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">cfg: DictConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br><span class="line">    <span class="keyword">if</span> cfg.known_host.port == <span class="number">62222</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;not ok&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>

<p>此举动不会更改原始的yaml中的参数配置，但是当进程运行结束后，会创建日志，重载的配置：</p>
<p><img src="/./python-package-tutorials/image-20240403165108222.png" alt="image-20240403165108222"></p>
<p><img src="/./python-package-tutorials/image-20240403165118016.png" alt="image-20240403165118016"></p>
<h2 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h2><p>若是想要在多个配置文件中进行选择，可以用对配置文件做进一步封装，如下目录树：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ tree ./</span><br><span class="line">./</span><br><span class="line">├── conf</span><br><span class="line">│   └── config.yaml</span><br><span class="line">├── get_start.py</span><br><span class="line">└── host</span><br><span class="line">    ├── config.yaml</span><br><span class="line">    └── user</span><br><span class="line">        ├── user1.yaml</span><br><span class="line">        └── user2.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>config.yaml</code>中的内容：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">defaults:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">user:</span> <span class="string">user1</span></span><br></pre></td></tr></table></figure>

<p><code>user1.yaml</code>中的内容：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">user:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">chengyiqiu</span></span><br><span class="line">  <span class="attr">password:</span> <span class="number">1234</span></span><br><span class="line">  <span class="attr">ipv4:</span> <span class="number">120.76</span><span class="number">.43</span><span class="number">.27</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">62222</span></span><br></pre></td></tr></table></figure>

<p>Code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;./host&#x27;</span>, config_name=<span class="string">&#x27;config&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_default_config</span>(<span class="params">cfg: DictConfig</span>):</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test_default_config()</span><br></pre></td></tr></table></figure>

<p>能够定向到<code>user1.yaml</code>，同样的方式，也可以使用重载来重新选择对应的配置文件；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ python get_start.py user=user2</span><br><span class="line">user:</span><br><span class="line">  user:</span><br><span class="line">    username: qcy</span><br><span class="line">    password: 12</span><br><span class="line">    port: 1</span><br><span class="line">    ipv4: 1.1.1.1</span><br></pre></td></tr></table></figure>

<p>也可以重载新的配置文件中的参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ python get_start.py user=user2 user.user.port=1111</span><br><span class="line">user:</span><br><span class="line">  user:</span><br><span class="line">    username: qcy</span><br><span class="line">    password: 12</span><br><span class="line">    port: 1111</span><br><span class="line">    ipv4: 1.1.1.1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="pytorch-lighting"><a href="#pytorch-lighting" class="headerlink" title="pytorch_lighting"></a>pytorch_lighting</h1><h2 id="train"><a href="#train" class="headerlink" title="train"></a>train</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyLightningModule</span>(L.LightningModule):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.model = model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch</span>):</span><br><span class="line">        x, y = batch</span><br><span class="line">        y_p = self.forward(x)</span><br><span class="line">        loss = torch.nn.functional.cross_entropy(y_p, y)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">        optimizer = torch.optim.SGD(self.model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    device = <span class="string">&quot;cuda:0&quot;</span></span><br><span class="line">    net = ResNet18(num_classes=<span class="number">10</span>).to(device)</span><br><span class="line">    batch, nw = <span class="number">32</span>, <span class="number">2</span></span><br><span class="line">    mask_path = <span class="string">&#x27;../resource/badnet/trigger_image.png&#x27;</span></span><br><span class="line">    trigger_path = <span class="string">&#x27;../resource/badnet/trigger_image_grid.png&#x27;</span></span><br><span class="line">    train_dataset, test_dataset = prepare_poisoning_dataset(ratio=<span class="number">1e-1</span>, mask_path=mask_path, trigger_path=trigger_path)</span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        dataset=train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch, num_workers=nw</span><br><span class="line">    )</span><br><span class="line">    test_loader = DataLoader(</span><br><span class="line">        dataset=test_dataset, shuffle=<span class="literal">True</span>, batch_size=batch, num_workers=nw</span><br><span class="line">    )</span><br><span class="line">    model = MyLightningModule(model=net)</span><br><span class="line">    trainer = L.Trainer(max_epochs=<span class="number">100</span>, devices=[<span class="number">0</span>])</span><br><span class="line">    trainer.fit(model=model, train_dataloaders=train_loader)</span><br></pre></td></tr></table></figure>

<p>继承<code>L.LightningModule</code>，重写4个方法即可训练。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/03/python-package-tutorials/" data-id="clw6dgvjn004wi49f33dy3oqy" data-title="python-package-tutorials" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/EasyRL/">EasyRL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Graph-Neural-Networks-Foundations-Frontiers-and-Applications/">Graph Neural Networks: Foundations, Frontiers, and Applications</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs224w/">cs224w</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/d2l/">d2l</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/writing-paper/">writing  paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C/">实验</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%80%BB%E7%BB%93/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6/">读书</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">高性能计算机网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RL/" rel="tag">RL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anomaly/" rel="tag">anomaly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anomaly/" rel="tag">anomaly&#39;</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cnn/" rel="tag">cnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gnn/" rel="tag">gnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lab/" rel="tag">lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/poisoning/" rel="tag">poisoning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rl/" rel="tag">rl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rnn/" rel="tag">rnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" rel="tag">信息论</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/anomaly/" style="font-size: 12px;">anomaly</a> <a href="/tags/anomaly/" style="font-size: 10px;">anomaly'</a> <a href="/tags/backdoor/" style="font-size: 20px;">backdoor</a> <a href="/tags/cnn/" style="font-size: 10px;">cnn</a> <a href="/tags/diffusion/" style="font-size: 18px;">diffusion</a> <a href="/tags/gnn/" style="font-size: 14px;">gnn</a> <a href="/tags/lab/" style="font-size: 10px;">lab</a> <a href="/tags/poisoning/" style="font-size: 16px;">poisoning</a> <a href="/tags/rl/" style="font-size: 10px;">rl</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" style="font-size: 10px;">信息论</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/05/10/limu-read-paper/">limu_read_paper</a>
          </li>
        
          <li>
            <a href="/2024/05/06/VillanDiffusion/">VillanDiffusion</a>
          </li>
        
          <li>
            <a href="/2024/04/27/Infomation-Theory-Inference-and-Learning-Algorithms/">Infomation_Theory_Inference_and_Learning_Algorithms</a>
          </li>
        
          <li>
            <a href="/2024/04/22/TrojDiff/">TrojDiff</a>
          </li>
        
          <li>
            <a href="/2024/04/18/Diffusion-Backdoor-Embed/">Diffusion-Backdoor-Embed</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width":280,"display":"post","offset":10,"onmobile":true},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":true},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="chengyiqiu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">chengyiqiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/chengyiqiu1121" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chengyiqiu1121" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/14/Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/14/Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/" class="post-title-link" itemprop="url">Towards_Stable_Backdoor_Purification_through_Feature_Shift_Tuning</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-14 10:12:46" itemprop="dateCreated datePublished" datetime="2024-03-14T10:12:46+08:00">2024-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:34:30" itemprop="dateModified" datetime="2024-04-19T12:34:30+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>NIPS2023</p>
<h1 id="摘要">摘要</h1>
<p>本文的方法是基于微调的（FT,
Fine-Tuning），微调并不能很好的解决触发器特征和样本特征联系紧密的问题，因此作者提出FST（Feature
Shift Tuning）</p>
<h1 id="微调提升模型的鲁棒性">微调提升模型的鲁棒性</h1>
<h2 id="实验观测">实验观测</h2>
<p>作者工作的重心在：当数据投毒率比较高（20%，10%等）时，可以使用微调来改变模型的决策边界（削弱触发器和目标标签之间的联系）。当数据投毒率比较低时，简单使用微调就无法解决问题了。这是经过实验观测得出的结论。</p>
<h2 id="探索">探索</h2>
<p>作者对不同投毒率下微调方法效果出现不稳定这个问题进行了探索。</p>
<p>假设：在不同投毒率下，模型的特征提取器提取出的特征是不同的。</p>
<p>基于假设，开始做实验，利用T-SNE对不同投毒率下的模型提取的特征进行可视化。</p>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240315093150937.png" alt="image-20240315093150937">
<figcaption aria-hidden="true">image-20240315093150937</figcaption>
</figure>
<h2 id="实验1-特征转移能否提高微调性能">实验1-特征转移能否提高微调性能</h2>
<p>对于一个深度学习模型，将其特征提取部分的参数表示为<span class="math inline">\(\Phi (\theta,
x)\)</span>，将最后的线性层表示为<span class="math inline">\(f(\omega)\)</span>。</p>
<p>作者通过固定好<span class="math inline">\(f(\omega)\)</span>，将特征提取的参数进行微调，试图达到特征转移的效果。但是实验并没有达到期望的结果。固定的线性层仍然限制了模型进行特征转移。</p>
<p>因此，作者参考前人的工作，对线性层的参数<span class="math inline">\(f(\omega ^{ori})\)</span>进行随机初始化，得到<span class="math inline">\(f(\omega)\)</span>，然后再对特征提取的参数<span class="math inline">\(\Phi(\theta)\)</span>​​​进行微调。</p>
<p>架构：</p>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240326164346367.png" alt="image-20240326164346367">
<figcaption aria-hidden="true">image-20240326164346367</figcaption>
</figure>
<p>效果：</p>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240326195936413.png" alt="image-20240326195936413">
<figcaption aria-hidden="true">image-20240326195936413</figcaption>
</figure>
<h2 id="实验1-评估">实验1-评估</h2>
<p>上图中的第五张是实验的结果，可以看出，采取上述设置，可以将目标标签和毒化样本的特征进行分开，在投毒率1%的情况下，但是这又导致了另一个问题，在干净样本上的正确率下降达到了2.9%，这是随机初始化<span class="math inline">\(f(\omega)\)</span>导致的。</p>
<p>总结来看，现在有的问题是，干净样本的正确率下降&amp;模型的鲁棒性不够（后门偏移不够）。</p>
<h1 id="fst-feature-shift-tuning">FST, Feature Shift Tuning</h1>
<p>基于上面的实验观测分析，作者提出了FST，首先对线性层进行初始化，然后解决下面的优化问题：</p>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240315125110759.png" alt="image-20240315125110759">
<figcaption aria-hidden="true">image-20240315125110759</figcaption>
</figure>
<p>左边的式子是对模型整体的准确率来作优化，而右边<span class="math inline">\(&lt;\omega,
\omega^{org}&gt;\)</span>则是在做特征转移（基于前面的观测，这里在初始化<span class="math inline">\(\omega\)</span>后加以约束，进行优化），<span class="math inline">\(\alpha\)</span>作为平衡因子，在“保证正确率不下降”和“特征转移”之间作平衡，增大<span class="math inline">\(\alpha\)</span>有利于特征转移。最后的<span class="math inline">\(\Vert
\omega\Vert_2\)</span>将线性层参数约束在一个常数范围内，确保不会出现参数过大或者过小的极端情况。</p>
<p>架构：</p>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240326200015516.png" alt="image-20240326200015516">
<figcaption aria-hidden="true">image-20240326200015516</figcaption>
</figure>
<p>效果：</p>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240326200036149.png" alt="image-20240326200036149">
<figcaption aria-hidden="true">image-20240326200036149</figcaption>
</figure>
<h1 id="实验">实验</h1>
<h2 id="训练后门模型">训练后门模型</h2>
<p>选择使用的模型也是ResNet18，在配置文件<code>cifar10.yaml</code>中可以更改。其中选取的baseline有：badnet、blended、trojannn等。</p>
<p>攻击的实现：</p>
<ol type="1">
<li>首先创建一个正常类<code>NormalCase</code>，在<code>prototype.py</code>中，其他的attack
class都继承了这个类。<code>prototype.py</code>定义了参数的解析、数据的准备以及训练过程的实现等。</li>
<li><code>badnet</code>继承<code>prototype</code>，包含了一些额外的参数、参数解析，还有训练数据准备、bad训练数据准备等。</li>
<li>选取好配置文件之后，训练好模型后，模型以及一些其他数据会被保存在<code>attack_result.pt</code>中，可以通过<code>torch.load</code>来查看保存的数据，访问训练好的模型。</li>
</ol>
<figure>
<img data-src="./Towards-Stable-Backdoor-Purification-through-Feature-Shift-Tuning/image-20240402143917317.png" alt="image-20240402143917317">
<figcaption aria-hidden="true">image-20240402143917317</figcaption>
</figure>
<h2 id="模型漂白">模型漂白</h2>
<p>下面进行模型漂白：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore fine_tune/ft.py --attack blended --split_ratio 0.02 --pratio 0.1 --device cuda:0 --lr 0.01 --attack_target 0 --model resnet18 --dataset cifar10 --epochs 10 --initlr 0.1 --ft_mode fst --alpha 0.1</span><br></pre></td></tr></table></figure>
<p>漂白结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2024-04-02:02:45:25 [INFO    ] [ft.py:360] Training ACC: 0.9970000386238098 | Training loss: -283.08803248405457</span><br><span class="line">2024-04-02:02:45:25 [INFO    ] [ft.py:361] Learning rate: 0.0</span><br><span class="line">2024-04-02:02:45:25 [INFO    ] [ft.py:362] -------------------------------------</span><br><span class="line">2024-04-02:02:45:33 [INFO    ] [ft.py:375] Defense performance</span><br><span class="line">2024-04-02:02:45:33 [INFO    ] [ft.py:376] Clean ACC: 0.8647 | ASR: 0.005333333333333333</span><br><span class="line">2024-04-02:02:45:33 [INFO    ] [ft.py:377] -------------------------------------</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/02/29/ABS-Scanning-Neural-Networks-for-Back-doors-by-Artificial-Brain-Stimulation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/29/ABS-Scanning-Neural-Networks-for-Back-doors-by-Artificial-Brain-Stimulation/" class="post-title-link" itemprop="url">ABS:Scanning_Neural_Networks_for_Back-doors_by_Artificial_Brain_Stimulation</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-02-29 21:12:40" itemprop="dateCreated datePublished" datetime="2024-02-29T21:12:40+08:00">2024-02-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:34:39" itemprop="dateModified" datetime="2024-04-19T12:34:39+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>CCS 2019</p>
<p>使用人工大脑模拟的方式扫描神经网络中的后门</p>
<h1 id="摘要">摘要</h1>
<p>本文试图解决trojan
attack的科学问题，采用的方法是分析内部神经元。问题关键：无论输入是怎样，神经元都极大激活到某一类固定的标签，这样的神经元被认为是潜在的后门神经元。</p>
<p>本文结构：</p>
<ol type="1">
<li>介绍</li>
<li>特洛伊攻击以及防御方法</li>
<li><strong>概述</strong></li>
<li><strong>设计</strong></li>
<li>评估</li>
<li>讨论</li>
<li>相关工作</li>
</ol>
<h1 id="概述">概述</h1>
<p>ABS的灵感源自电子大脑模拟（Electrical Brain Stimulation, EBS）</p>
<p>EBS通过使用电流直接或间接激发细胞膜来刺激真实大脑中的神经元或神经网络。</p>
<p>ABS利用单个人工神经元，以受控的方式改变它们的激活值(如在EBS中提供不同强度的电电流)，以研究它们是否被破坏。</p>
<h2 id="威胁模型">威胁模型</h2>
<p>攻击者：</p>
<ul>
<li>对于训练过程有完全的控制。</li>
<li>对于要被攻击的标签（目标标签），只有一个触发器。</li>
</ul>
<p>防御着：</p>
<ul>
<li>得到一个模型</li>
<li>对每一类至少有一个样本，来评判模型是否被投毒。</li>
</ul>
<h2 id="关键观测">关键观测</h2>
<p>观测1: 成功的木马攻击导致后受损的神经元（后门神经元）</p>
<p>观测2:
受损的神经元代表着目标标签的一个子空间，这个子空间可以横穿整个决策空间。</p>
<p>下图给出了观测2的可视化展示，<span class="math inline">\(V_\alpha\)</span>和<span class="math inline">\(V_\beta\)</span>代表的是两个神经元的激活，纵轴<span class="math inline">\(Z_t\)</span>代表的是目标标签的输出，图a是没有被攻击的时候，，图b则是被毒化数据攻击了的时候，无论<span class="math inline">\(V_\beta\)</span>的激活如何，只要<span class="math inline">\(V_\alpha\)</span>的激活在70，那么最终目标标签<span class="math inline">\(Z_t\)</span>的输出都为最大，图c则是图b的二维展示。</p>
<figure>
<img data-src="./ABS-Scanning-Neural-Networks-for-Back-doors-by-Artificial-Brain-Stimulation/image-20240309093456920.png" alt="image-20240309093456920">
<figcaption aria-hidden="true">image-20240309093456920</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/20/Fine-Pruning-Defending-Against-Backdooring-Attacks-on-Deep-Neural-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/20/Fine-Pruning-Defending-Against-Backdooring-Attacks-on-Deep-Neural-Networks/" class="post-title-link" itemprop="url">Fine-Pruning-Defending-Against-Backdooring-Attacks-on-Deep-Neural-Networks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-20 20:43:59" itemprop="dateCreated datePublished" datetime="2024-01-20T20:43:59+08:00">2024-01-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:34:58" itemprop="dateModified" datetime="2024-04-19T12:34:58+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>RAID， CCFB，常见的defence</p>
<h1 id="摘要">摘要</h1>
<p>提供了第一个有效的后门攻击防御方法，实验：</p>
<ul>
<li>三个后门攻击</li>
<li>两种防御方法，剪枝和微调，并且进行结合，提出了fine-
pruning，微剪枝。</li>
</ul>
<p>实验结果：在某种情况下，降低攻击成功率到0%，仅仅只有0.4%的正确率下降（对于那些干净样本）</p>
<p>本文结构：</p>
<ul>
<li>ch1介绍</li>
<li>ch2背景，分为三节介绍：深度学习基础、<del>威胁模型</del>、后门攻击</li>
<li>ch3是讲方法的</li>
<li><del>ch4是讨论，讨论了对方法的正确性进行了讨论</del></li>
<li><del>ch5近期工作</del></li>
<li>ch6结论</li>
</ul>
<p>结构比较乱，没有单独的<strong>实验部分</strong>。</p>
<p>威胁模型和之前的论文一样。</p>
<h1 id="方法">方法</h1>
<h2 id="剪枝">剪枝</h2>
<h3 id="原理">原理</h3>
<p>某些后门攻击选取的神经元具有这样的特性：对于干净样本的输出，不激活；对于带有后门的输入，激活较大。因此，直觉上，将这样的神经元修剪掉，可能会使后门攻击无效。</p>
<p>剪枝详细分为三个阶段：</p>
<ol type="1">
<li><p>对干净数据和后门输入都不激活的神经元，剪掉。</p>
<p>这类神经元剪掉不会有任何影响。</p></li>
<li><p>只对后门输入激活的神经元，剪掉。</p>
<p>在不怎么降低正确样本准确率的前提下，修剪掉这类神经元。</p></li>
<li><p>对干净输入激活，同时会降低正干净样本的正确率的神经元，剪掉。</p>
<p>将受到后门神经元影响比较严重的神经元修剪掉。</p></li>
</ol>
<p>剪枝是一种不错的策略：</p>
<ul>
<li>计算量低，只需要在验证集上训练剪枝即可。</li>
<li>能够显著降低后门攻击的成功率。</li>
</ul>
<p>缺点：已经有针对修剪的攻击了。</p>
<h3 id="实验">实验</h3>
<p>剪枝前人已经提出过了，作者此部分的工作量：</p>
<ul>
<li>attack baseline：badnets</li>
<li>攻击场景：人脸识别、语音识别、交通信号</li>
</ul>
<p>在分析的时候作者会将接近输出层的神经元的输出可视化出来，不是很懂这种图的意思：</p>
<figure>
<img data-src="./Fine-Pruning-Defending-Against-Backdooring-Attacks-on-Deep-Neural-Networks/image-20240227132415425.png" alt="image-20240227132415425">
<figcaption aria-hidden="true">image-20240227132415425</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在(a)“Clean Activations”图表中，每一块代表一个特定神经元的激活强度，颜色越浅表示激活强度越高。0～2.0是一个比例尺，表示激活强度的范围。在(b)“Backdoor Activations”图表中，大部分神经元没有被激活（黑色），只有少数几个显示出较高的激活（白色）。0～25也是一个比例尺，但具有不同的范围和刻度。</span></span><br></pre></td></tr></table></figure>
<h2 id="修剪感知攻击">修剪感知攻击</h2>
<h3 id="原理-1">原理</h3>
<p>修剪感知攻击针对的是剪枝防御。其直觉是：攻击者在训练时，先进行剪枝，将满足一定特性的神经元修剪，然后开始训练，使得没有被修剪的神经元能够感知触发器，最后再将修剪掉的神经元重新放回去，保证模型结构不变的同时，被修剪的神经元的作用为“诱饵”。</p>
<p>攻击分为四个阶段：</p>
<ol type="1">
<li>将DNN在干净数据集上先进行训练。</li>
<li>对DNN进行剪枝，将休眠的神经元修建掉。修建的神经元的个数作为参数可以在攻击过程中进行调整。</li>
<li>用投毒数据集对修剪之后的DNN进行训练。</li>
<li>将修剪的神经元重新安装回去，并且调低他们的bias，确保“诱饵”对干净输入激活较低。</li>
</ol>
<figure>
<img data-src="./Fine-Pruning-Defending-Against-Backdooring-Attacks-on-Deep-Neural-Networks/image-20240227155557857.png" alt="image-20240227155557857">
<figcaption aria-hidden="true">image-20240227155557857</figcaption>
</figure>
<h2 id="微剪枝">微剪枝</h2>
<p>作者的idea出发于迁移学习中的微调。然而微调并不能直接用于后门攻击的防御中。因为防御者手上只有验证集，而后门神经元对验证集中的图片不会激活。因此经过微调后，后门神经元的参数不会发生改变。</p>
<p>微剪枝的步骤是：</p>
<ol type="1">
<li>通过剪枝将后门神经元剪掉（其实是诱饵）</li>
<li>通过微调来根据正确率调整剪枝模型的参数。</li>
</ol>
<p>这种方法是用来针对修剪感知攻击，有局限性。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/17/Trojaning-Attack-on-Neural-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/17/Trojaning-Attack-on-Neural-Networks/" class="post-title-link" itemprop="url">Trojaning-Attack-on-Neural-Networks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-17 14:23:37" itemprop="dateCreated datePublished" datetime="2024-01-17T14:23:37+08:00">2024-01-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:35:06" itemprop="dateModified" datetime="2024-04-19T12:35:06+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>NDSS2018，backdoor attack必须的baseline。</p>
<h1 id="摘要">摘要</h1>
<p>trojaning attack，steps：</p>
<ul>
<li>反转神经网络来生成trojan trigger</li>
<li>通过外部数据集（？）来retrain模型，retrain后的模型，当输入为trojan
trigger时，会表现恶意行为。</li>
</ul>
<p>特别的，trojan attack：</p>
<ul>
<li>不需要破坏原始的训练过程</li>
<li>不需要原始训练数据集</li>
</ul>
<p>摘要中没有提到baseline、dataset、defence，只是说最后探索了一下，对于此类攻击的可能的防御方法。</p>
<p>摘要中比价强调的是：<strong>攻击事件短、不需要训练集。</strong></p>
<h1 id="攻击演示">攻击演示</h1>
<p>威胁模型：对攻击者而言，训练数据集不可用，训练后得到的干净模型可用。</p>
<p>攻击过程 ：输入是一个干净的NN，输出是带有后门的NN，以及trigger
stamp，也就是trigger patch。</p>
<p>触发器形态：矩形，大小未定量。</p>
<p>攻击演示图：</p>
<p>正常模型：</p>
<ul>
<li>1，2是训练集中出现过的样本，能够较准确的预测</li>
<li>3、4、5是没有出现过在训练集中，瞎预测</li>
</ul>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240118191115078.png" alt="image-20240118191115078">
<figcaption aria-hidden="true">image-20240118191115078</figcaption>
</figure>
<p>后门模型</p>
<ul>
<li>1、2是benign sample</li>
<li>3、4、5是sample with the trigger，全部预测为1</li>
</ul>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240118191231127.png" alt="image-20240118191231127">
<figcaption aria-hidden="true">image-20240118191231127</figcaption>
</figure>
<p>trojan
attack可以被应用到许多领域，除了人脸识别之外，还有语音数字识别：</p>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240118193022324.png" alt="image-20240118193022324">
<figcaption aria-hidden="true">image-20240118193022324</figcaption>
</figure>
<p>以及年龄识别：</p>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240118193037650.png" alt="image-20240118193037650">
<figcaption aria-hidden="true">image-20240118193037650</figcaption>
</figure>
<h1 id="威胁模型和概述">威胁模型和概述</h1>
<p>威胁模型如上一节，这里在讲述一下：本文考虑的场景不是很接近外包，更接近迁移学习，攻击者无需访问训练数据集、测试数据集，只需要训练好的模型即可。攻击者对模型植入trigger，然后重新发布到网上，这与当今python包的下载十分类似。</p>
<p>攻击的三个阶段：</p>
<ul>
<li>trojan trigger generation</li>
<li>Train data generation</li>
<li>model retrain</li>
</ul>
<h2 id="trojan-trigger-generation">trojan trigger generation</h2>
<p>思路是：</p>
<ul>
<li>选取trigger shape，也就是mask，这里作者选取了apple logo作为mask</li>
<li>将init mask输入到target
model里面去，然后通过触发器生成算法，生成trigger。原理是：检查整个NNs中的neuron，看看哪些神经元会对mask的值变化比较敏感，将这些神经元作为selected
neuron。</li>
</ul>
<h2 id="train-data-generation">train data generation</h2>
<p>由于攻击者无法直接访问训练数据，因此需要通过反向工程来生成合适的训练数据。具体的做法如下：</p>
<ul>
<li><p>首先利用一些不相关的公共数据集中的真实图像，通过取平均值来得到初始化的生成图像。</p>
<p>初始化生成图可能在某一类输出节点的概率非常低，如下图：</p>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240119145822957.png" alt="image-20240119145822957">
<figcaption aria-hidden="true">image-20240119145822957</figcaption>
</figure></li>
<li><p>然后利用输入逆向工程算法，将初始化生成图的某些像素值进行改变，使得最终在某一类上的预测能够达到最大值。</p>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240119150302076.png" alt="image-20240119150302076">
<figcaption aria-hidden="true">image-20240119150302076</figcaption>
</figure></li>
<li><p>然后反复执行这种方法，直到训练数据集足够了。</p></li>
</ul>
<p>这种方法生成的图片在特征空间上完美符合B
label，但是在像素空间并不接近label B。</p>
<h2 id="model-retrain">model retrain</h2>
<p>retrain这一部分只是训练一部分层（选中的神经元到输出层之间的层），全部重训练比较费时间。</p>
<p>整个的数据集可以看作两部分：</p>
<ul>
<li>图片I（true label B）-&gt; label B</li>
<li>图片I和触发器T-&gt; label A</li>
</ul>
<p>所有带有触发器的图片都会被导向label A</p>
<p>start point是benign model。</p>
<p>使得重训练有效的两个点在于：</p>
<ol type="1">
<li><p>在selected neuron和output node（label
A）之间建立起一条强连接。</p>
<figure>
<img data-src="./Trojaning-Attack-on-Neural-Networks/image-20240120200725997.png" alt="image-20240120200725997">
<figcaption aria-hidden="true">image-20240120200725997</figcaption>
</figure>
<p>如图，第三个neuron和output node之间的weight由0.5变成了1，strong
link</p>
<p>PS：之前选取selected
neuron的时候就是在input和neuron之间建立一条连接</p></li>
<li><p>减弱其他非selected neuron和output label之间的连接</p>
<p>如上图，其他非selected neuron和output node A之间的weight变小了。</p>
<p>这样做的目的是，当输入为带有非触发器的图片时，防止model错误的输出为label
A</p></li>
</ol>
<p>另外，还有两个与前面不一样的选择（通过实验得出）：</p>
<ol type="1">
<li><p>使用模型生成的触发器，而不是随机选取logo来作为触发器。因为随机的logo很难对selected
neuron有比较大的影响。</p></li>
<li><p>选择使用内部神经元来生成触发器。（这里或许是指的优化时，选择能让selected
neuron最大激活的作为触发器）一个替代方案是选择output node
A来生成触发器，但是经过分析，有以下原因导致效果不好：</p>
<ul>
<li>image with trigger和output node
A之间的因果关系很弱，可能没有/或者很难找到一条路径来使得output node
A最大。（类似于bi-level optimal problem）</li>
<li>直接选取输出层的话，就失去了重训练的优势。<strong>因为所选层是输出层，中间就没有其他层了</strong>（？）</li>
</ul>
<p>作者在最后做了实验，确实是选择激活内部的神经元来生成触发器，能够达到更好的性能。</p></li>
</ol>
<h1 id="攻击设计">攻击设计</h1>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/17/Hidden-Trigger-Backdoor-Attacks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/17/Hidden-Trigger-Backdoor-Attacks/" class="post-title-link" itemprop="url">Hidden-Trigger-Backdoor-Attacks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-17 10:26:39" itemprop="dateCreated datePublished" datetime="2024-01-17T10:26:39+08:00">2024-01-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:35:14" itemprop="dateModified" datetime="2024-04-19T12:35:14+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Hidden Trigger Backdoor Attacks，简称HB，发布在AAAI，是backdoor
attack的常见baseline。</p>
<h1 id="摘要">摘要</h1>
<p>以前的state-of-the-art工作要么是添加能够一眼看出来的中毒数据，要么就是通过加入噪声来隐藏trigger。本文提出一种新的更隐蔽的攻击，攻击者隐藏中毒数据的触发器，直到进行测试。</p>
<p>摘要中简单提及了：</p>
<ul>
<li>将攻击应用在多个分类模型上</li>
<li>测试了state-of-the-art defence algorithm</li>
</ul>
<h1 id="方法">方法</h1>
<p>先介绍了一下BadNets用的毒化数据的公式： <span class="math display">\[
s_i^{\sim}=s_i\odot (1-m)+p\odot m
\]</span> 缺点是很容易被人肉眼看出，因此作者提出自己的方法。</p>
<p><img data-src="./Hidden-Trigger-Backdoor-Attacks/image-20240117125626531.png" alt="image-20240117125626531"> <span class="math display">\[
\arg \min_z\vert f(z)-f(s^{\sim})\vert_2^2 \\
st. \vert z-t\vert_\infty&lt;\epsilon
\]</span></p>
<ul>
<li><span class="math inline">\(t\)</span>：target image，也就是狗</li>
<li><span class="math inline">\(s\)</span>：source
image，也就是飞机</li>
<li><span class="math inline">\(s^{\sim}\)</span>：patched source
image，也就是打了补丁的飞机</li>
<li><span class="math inline">\(z\)</span>：poisoned
image，毒化的图片，也就是上图中的经过优化之后的狗。</li>
</ul>
<p>(2)的解释：在使得z和t相差不大的情况下（像素空间中，毒化的狗<span class="math inline">\(z\)</span>和狗<span class="math inline">\(s\)</span>相差不大，人眼不会看出），<span class="math inline">\(f(z)\)</span>和<span class="math inline">\(f(s^{\sim})\)</span>的差距也不大（特征空间中，毒化的狗<span class="math inline">\(z\)</span>和打了补丁的飞机<span class="math inline">\(s^\sim\)</span>比较相近）</p>
<p>上述工作，提供一个点（源图：飞机，目标：狗），然后通过一个固定了位置的触发器，来导致误分类。这种方法缺少泛化性，不是很实际。若是一张新的图片，换了一个角度，那么原来的方法就很可能会失效。</p>
<p>作者采用每一个iteration都进行一次随机抽样（对source，也就是干净的飞机图片），然后再采取(2)来优化。</p>
<figure>
<img data-src="./Hidden-Trigger-Backdoor-Attacks/image-20240117141807001.png" alt="image-20240117141807001">
<figcaption aria-hidden="true">image-20240117141807001</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/16/Neural-Cleanse-Identifying-and-Mitigating-Backdoor-Attacks-in-Neural-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/16/Neural-Cleanse-Identifying-and-Mitigating-Backdoor-Attacks-in-Neural-Networks/" class="post-title-link" itemprop="url">Neural-Cleanse-Identifying-and-Mitigating-Backdoor-Attacks-in-Neural-Networks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-16 21:01:03" itemprop="dateCreated datePublished" datetime="2024-01-16T21:01:03+08:00">2024-01-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:34:49" itemprop="dateModified" datetime="2024-04-19T12:34:49+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文是后门攻击的防御方法，S&amp;P 2019。</p>
<p>标题直接翻译：神经元清洗，识别并且减轻神经网络中的后门攻击。</p>
<h1 id="摘要">摘要</h1>
<p>本文内容：提出的技术能够识别出后门，并且重构出可能的触发器。通过多种手段来对后门攻击进行缓解：过滤、神经元修剪、遗忘。</p>
<p>本文结构：</p>
<ol type="1">
<li>介绍</li>
<li>背景</li>
<li><strong>方法概述</strong></li>
<li><strong>详细的检测方法</strong></li>
<li>实验：后门检测和触发器识别</li>
<li><strong>后门缓解</strong></li>
<li>抵抗入侵的能力</li>
<li>相关工作</li>
<li>结论及展望</li>
</ol>
<h1 id="方法概述">方法概述</h1>
<h2 id="威胁模型">威胁模型</h2>
<p>对攻击者的假设。</p>
<p>attack baseline：BadNets and Trojan Attack</p>
<p>攻击方式：仅仅对一个标签进行攻击。</p>
<h2 id="防御模型">防御模型</h2>
<p>对防御者的假设：可以访问植入后门的<strong>模型</strong>；有一部分<strong>验证集</strong>用来测试接收到的模型；有一定的<strong>计算资源</strong>来测试和修改模型。</p>
<p>防御者的目标：</p>
<ol type="1">
<li>检测：包括“判断是否模型中含有后门”和，“哪个标签被攻击了”</li>
<li>恢复：准确来说，是通过反向工程恢复出攻击者使用的触发器。</li>
<li>减轻：其一，设计滤波器将含有触发器的输入过滤掉；其二，给DNN打补丁。</li>
</ol>
<p>作者从两个角度解释假设的原因：</p>
<ol type="1">
<li>粗粒度来讲，为什么最终选择使用减轻后门，而不是考虑其他方案，例如重新训练模型。主要是由于：重新训练计算量大、重新找外包服务商并没解决问题、换预训练模型（迁移学习等）困难。</li>
<li>细粒度来讲，如何找到后门和触发器之间的联系，防御着只有验证集和后门模型。考虑三种情况：
<ol type="1">
<li>扫描输入：可能会受到逃避攻击。</li>
<li>分析模型内部结构：黑盒</li>
<li>分析误分类原因：可能实现</li>
</ol></li>
</ol>
<h2 id="防御直觉">防御直觉</h2>
<p>作者从“误分类是将样本直接分类为目标标签A，而不管其原来属于什么标签”出发，这个攻击过程可以用下图表示：</p>
<figure>
<img data-src="./Neural-Cleanse-Identifying-and-Mitigating-Backdoor-Attacks-in-Neural-Networks/image-20240229204004091.png" alt="image-20240229204004091">
<figcaption aria-hidden="true">image-20240229204004091</figcaption>
</figure>
<p>干净模型的决策边界正常，有三个维度；而后门模型的决策边界则有四个维度，并且将新增加出来的那个维度直接分类为目标标签A对应的维度。</p>
<p>上图中，第四个维度中的元素（灰色的块），被称为“shortcut”，翻译成捷径，或者“快捷方式”。</p>
<p>攻击过程是在正常样本中加入扰动（触发器），然后扰乱了模型的决策边界。因此，作者使用反向工程，还原出触发器，然后设计出滤波器，具体步骤如下：</p>
<ol type="1">
<li>选取一类标签，将其做为目标标签，然后优化触发器，使得其他样本误分类为目标标签，找到这个“最小”的触发器。</li>
<li>重复着一过程，直到找到N个最小触发器。</li>
<li>使用“离群检测算法”找到N个触发器中的最小触发器，作为最终结果。</li>
</ol>
<p>利用反向工程得到触发器后，便可以开始对后门进行削弱，使得模型更加鲁棒。</p>
<p>关键直觉：<strong>it requires much smaller modifications to cause
misclassification into the target label than into other uninfected
labels</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/" class="post-title-link" itemprop="url">Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-15 19:47:40" itemprop="dateCreated datePublished" datetime="2024-01-15T19:47:40+08:00">2024-01-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:35:27" itemprop="dateModified" datetime="2024-04-19T12:35:27+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>发在期刊IEEE JOURNAL ON SELECTED AREAS IN
COMMUNICATIONS上，简称JSAC，属于A会。</p>
<h1 id="摘要">摘要</h1>
<p>背景：外包云环境下。</p>
<p>工作量：</p>
<ul>
<li>一种名为RobNet的攻击方法，关键要素为：
<ul>
<li>使得触发器多样化：多个位置都有触发器的patch，这些触发器是通过梯度下降来生成的</li>
<li>加强模型的结构（<strong>？外包不是不能改变模型结构吗</strong>）</li>
</ul></li>
</ul>
<p>实验：</p>
<ul>
<li>数据集：MNIST、GTSRB、CIFAR-10</li>
<li>防御方法：Pruning, NeuralCleanse, Strip, and ABS</li>
<li>baseline：BadNets、<strong>Hidden Backdoors</strong></li>
</ul>
<h1 id="威胁模型">威胁模型</h1>
<p>和以前的工作不同（用户只需要检测收到的模型在验证集上的正确率是否大于预期），本文考虑一个更健壮的情况：收到的模型需要通过当前最先进的后门检测方法。</p>
<h1 id="robnet">RobNet</h1>
<h2 id="概述">概述</h2>
<h3 id="触发器生成">触发器生成</h3>
<p>触发器生成分了为两种：</p>
<ul>
<li>random triggers</li>
<li>Model-dependent triggers</li>
</ul>
<p>其中模型依赖触发器就是通过DNN生成的触发器。</p>
<p>本文选取的就是model-dependent
triggers，本文的生成算法，不仅可以提高攻击成功率，还可以逃避掉大部分防御算法。</p>
<p>生成算法要做的是：对一个空的mask进行值填充，让selected
neuron能够最大的激活。而如何选取selected neuron？选取<strong>离targeted
label比较近的neuron</strong>。具体做法是：训练出一个干净的模型，然后将激活值和权重都比较高的神经元作为selected
neuron。</p>
<p>实验（chapter
5）表明，该神经元不会被pruning剪掉，因此，该攻击是可以evade pruning
operation。</p>
<h3 id="后门注入">后门注入</h3>
<p>原始样本<span class="math inline">\((x,c)\)</span></p>
<p>投毒的恶意样本<span class="math inline">\((x^*,c^*)\)</span></p>
<ul>
<li>x: the clean sample</li>
<li>c: the clean label</li>
<li><span class="math inline">\(x^*\)</span>: the sample x with
trigger</li>
<li><span class="math inline">\(c^*\)</span> the targeted label</li>
</ul>
<p>可以通过改变触发器的位置来构造多个恶意样本，这些恶意样本<del>可能targeted
label也不</del>一样。对于这种patch的触发器，trigger
location非常重要，如果训练阶段和测试阶段使用的location不一样，那么攻击的成功率会大大降低。因此本文选择在训练的时候就将所有的触发器的位置都考虑到，以增加模型的健壮性。</p>
<p>然后就是重训练阶段。</p>
<p>作者强调，只重新训练了部分层（选中神经元和输出层之间的层），这样做的目的是保证其他样本的正确性。</p>
<h2 id="触发器生成-1">触发器生成</h2>
<h3 id="掩码决定">掩码决定</h3>
<p>本文还没有考虑掩码的形状）这部分内容是确定掩码的大小，在攻击成功率和stealthiness之间权衡，最终确定了7%作为掩码的大小，恰好到Neural
Cleanse的阈值</p>
<h3 id="神经元决定">神经元决定</h3>
<p>选full-connection层，权重较大的神经元。</p>
<p><img data-src="./Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116155630399.png" alt="image-20240116155630399" style="zoom: 50%;"></p>
<ul>
<li><span class="math inline">\(\mathcal N\)</span>: a set of neurons in
layer l</li>
<li><span class="math inline">\(l\)</span>: selected layer</li>
<li><span class="math inline">\(\mathcal J\)</span>: a set of neurons in
layer l - 1</li>
</ul>
<p><strong>这其实是NDSS上的Trojaning Attack on Neural
Networks中的方法。</strong></p>
<p>这种方法有弊端，选出的神经元对所有的输入都很敏感。pruning
defence是activation-
based的方法。选出来的neuron很可能会表现的低激活并且被pruning。</p>
<p>于是作者的思路是：找到weight和activation都比较大的神经元作为selected
weight。</p>
<p><img data-src="./Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116160419992.png" alt="image-20240116160419992" style="zoom:50%;"></p>
<ul>
<li><span class="math inline">\(\lambda\)</span>: balance
coefficient</li>
<li><span class="math inline">\(\mathcal X^c\)</span>: a set of benign
samples of target misclassfication label c</li>
<li><span class="math inline">\(I_{[F(x)=n]}\)</span>: the activation of
neuron n, input sample x</li>
</ul>
<h3 id="触发器生成-2">触发器生成</h3>
<p>优化路径 <span class="math display">\[
\vert v_{n,t}-v_t\vert^2
\]</span></p>
<ul>
<li><span class="math inline">\(v_{n,t}\)</span>：当前回合神经元n的激活</li>
<li><span class="math inline">\(v_t\)</span>：目标激活，选取selected
layer中的最大激活值作为<span class="math inline">\(v_t\)</span></li>
</ul>
<p>其中，从l-1层到l层，neuron n的激活可以表示i为： <span class="math display">\[
a_n^l=\Phi ^l( \sum_{j=1}^K(w_{n,j}^{l-1,l}a_j^{l-1})+b_n^l )
\]</span></p>
<h2 id="后门注入-1">后门注入</h2>
<h3 id="数据投毒">数据投毒</h3>
<p><span class="math display">\[
x^*=x+trigger\odot M
\]</span></p>
<p>加了个mult- location，单个位置的话，很容易被Neuron
Clean监测到。因此可以在一张图上加多个trigger。如6和8都加上trigger</p>
<figure>
<img data-src="./Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116164552734.png" alt="image-20240116164552734">
<figcaption aria-hidden="true">image-20240116164552734</figcaption>
</figure>
<h3 id="模型重训练">模型重训练</h3>
<ul>
<li>先用干净数据集训练出一个良好的模型</li>
<li>通过良好模型+触发器生成算法=&gt;触发器</li>
<li>触发器+数据集=&gt;投毒数据集=&gt;重训练得到后门模型。</li>
</ul>
<p>PS：只有触发器生成层和输出层进行重训练。为了保证良性样本的正确率</p>
<h2 id="多触发器攻击">多触发器攻击</h2>
<p>首先是，多触发器，单目标标签。 <span class="math display">\[
x+A\odot M_A \\
x+B\odot M_B \\
x+A\odot M_A+B\odot M_B
\]</span>
(4)有三个中毒样本，误分类标签都是c。两种掩码，每种掩码都是用同一种算法但是不同的location生成出来的。这样能够提高攻击的鲁棒性。</p>
<p>多触发器，多标签。 <span class="math display">\[
(x+A\odot M,c_1) \\
(x+B\odot M,c_2) \\
(x+C\odot M,c_3)
\]</span> 在测试中，只要有中毒样本有一种就行了。</p>
<h1 id="总结">总结</h1>
<p>本文是基于patch的后门攻击，相比于BadNet的single- pixel、pattern-
pixel更加现实，同时详细讲述了实施后门攻击的每一个步骤：</p>
<ul>
<li>训练干净模型</li>
<li>（这里没有选取掩码的形状，掩码默认7%图片大小的全1像素组合）</li>
<li>选取layer、neuron，然后根据neuron生成触发器</li>
<li>进行数据投毒，然后将毒化数据集对模型进行重训练。并且，作者为了保证干净样本的正确率，只对部分层进行了重新训练</li>
<li>对多触发器展开了实验（这部分意义不是很大，因为patch的触发器太容易肉眼看出，但是可以借鉴其思想：为了保证后门攻击的隐蔽性</li>
</ul>
<p>这篇文章是2021年中的，写作时间可能在2020年，细节讲的比较详细，从初学者的角度能够更好理解，然而patch的方法缺点太大，更好的方向是作者的2022年发表在NDSS上的论文：ATTEQ，mask和trigger都是通过DNN生成的，肉眼也不可见。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/08/Backdoor-Defense-with-Machine-Unlearning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/08/Backdoor-Defense-with-Machine-Unlearning/" class="post-title-link" itemprop="url">Backdoor_Defense_with_Machine_Unlearning</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-08 14:02:19" itemprop="dateCreated datePublished" datetime="2024-01-08T14:02:19+08:00">2024-01-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:35:43" itemprop="dateModified" datetime="2024-04-19T12:35:43+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="摘要">摘要</h1>
<p>本文提出了一种基于machine
unlearning（机器不学习，机器学习遗忘）的擦除后门攻击的方法，主要有两步：</p>
<ol type="1">
<li>触发器模式恢复：从受害者模型中提取出触发器的模式。这个问题等价于：从受害者模型中提取出一个特定的噪声信号（分布），这可以通过<strong>熵最大化生成模型</strong>来解决。</li>
<li>受害者模型净化：通过1中恢复出来的触发器模式，结合基于machine
unlearning的梯度上升的方法，来擦除模型污染的记忆（也就是模型遗忘）。</li>
</ol>
<p>对比之前的machine
unlearning方法，该方法不需要访问所有训练数据来进行重训练，并且比微调or修建方法更好。baseline有三个优的攻击方法，本文方法可以降低99%的攻击成功率在基准测试中。</p>
<h1 id="介绍">介绍</h1>
<p>总结了三种常见的后门擦除的方法：</p>
<ol type="1">
<li><p>微调</p>
<p>利用一小部分干净数据，对受害者模型进行微调，来擦除后门。</p>
<p>该方法有一定局限性，很难用一小部分数据来将后门神经元完全擦除[7,
xidian, ICLR]</p></li>
<li><p>修剪</p>
<p>对微调之后的模型，进行修剪，所谓修剪，就是将满足某种性质的神经元修剪掉（比如神经元对触发器样本激活值很大）。</p>
<p>这个方法的局限性在于，直接修剪掉后会对正常样本也造成影响。</p></li>
<li><p>知识蒸馏</p>
<p>还是[7]，用干净的模型来蒸馏掉受害者模型的脏知识，同时保证正确样本的正确率（不完全蒸馏掉）</p>
<p>问题在于干净的模型从哪里来？</p>
<p>该方法正确率较低，很大原因在于“干净模型”并不干净。</p></li>
</ol>
<p>本文通过机器学习遗忘的方法，来擦除后门，客服克服以下问题：</p>
<ol type="1">
<li><p>通过[14-16]的方法（熵最大生成模型），来生成触发器模式，<strong>不需要访问任何的训练数据</strong>。触发器模式即为模型需要遗忘的记忆。</p></li>
<li><p>之前的方法很多都需要重新训练，并且对训练数据集需要完全访问。本文通过1.
中生成的触发器模式，来进行梯度上升。</p>
<p>直接梯度上升会导致灾难性遗忘，因此本文增加了权重惩罚机制。</p></li>
</ol>
<h1 id="近期工作">近期工作</h1>
<h2 id="机器学习遗忘">机器学习遗忘</h2>
<p>简单介绍了一下机器学习遗忘的定义：消除某些特定样本对目标模型的影响。</p>
<p>发展：</p>
<ol type="1">
<li>[11]，2015，提出了机器学习遗忘，缺点：只能适用<strong>非适应性模型</strong>（non-adaptive），在适应性模型上性能表现非常差。</li>
<li>[12,
23-25]，近五年，提出了各种各样的基于重新训练的机器学习遗忘方法。</li>
</ol>
<p>目前的缺点是，重训练需要消耗大量的资源，而后门攻击的场景就是外包、迁移学习。所以现在的情况就是，若是硬要用机器学习遗忘来消除后门，那么就是：为了避免消耗资源，选择使用外包、迁移学习，然后得到带有后门的模型，最后通过机器学习遗忘，消耗大量资源重训练，来消除后门。</p>
<h1 id="概述">概述</h1>
<h2 id="威胁模型目标">威胁模型&amp;目标</h2>
<p>defender：</p>
<ul>
<li>不知道那一张图片被污染了，或者是哪一类被污染了</li>
<li>只能访问一部分验证集的数据，并不能访问训练集。</li>
</ul>
<p>goal： <span class="math display">\[
arg \min_\theta \mathcal L
(F_\theta(x_b),y_{real})+\lambda\vert\theta\vert
\]</span> <span class="math inline">\(\lambda\)</span>是惩罚细数，<span class="math inline">\(\vert\theta\vert\)</span>是惩罚项，目的是为了避免
灾难性遗忘。</p>
<p>本文工作：</p>
<ol type="1">
<li><p>触发器恢复</p>
<p>不同于往常使用GAN，本文使用的是熵最大生成模型；反转攻击过程，攻击过程是由输入推出输出，防御过程则是从输出反推出输入（的触发器模式）。</p></li>
<li><p>触发器模式遗忘</p>
<p>不同于基于重训练的mu，本文使用基于梯度上升的mu，来消除触发器对模型产生的负面影响。</p></li>
</ol>
<h1 id="通过机器学习遗忘的后门擦除">通过机器学习遗忘的后门擦除</h1>
<h2 id="触发器恢复">触发器恢复</h2>
<p>优化路径： <span class="math display">\[
\mathcal L_R=\frac{1}{b}\sum_{x\in
D^{&#39;}}(\max(0,\epsilon_i-F_{\theta_0}(x+G_i(\delta))[y_p])-\eta
H_i(G_i(\delta);\delta^{&#39;}))
\]</span> 符号表示：</p>
<ul>
<li><p><span class="math inline">\(G_i\)</span>:the i-th generative
model</p></li>
<li><p><span class="math inline">\(D^{&#39;}\)</span>: part of
validation datast</p></li>
<li><p><span class="math inline">\(\delta\)</span> and <span class="math inline">\(\delta^{&#39;}\)</span>: two voices sampled from
<span class="math inline">\(N(0,1)\)</span></p></li>
<li><p><span class="math inline">\(F_{\theta_0}\)</span>: backdoored
model</p></li>
<li><p><span class="math inline">\(H_i\)</span>: mutual information
estimator, [16]</p>
<ul>
<li>If X and Y are independent, <span class="math inline">\(H_i(X,Y)=0\)</span></li>
</ul></li>
<li><p><span class="math inline">\(\epsilon_i\)</span>: the threshold
from <span class="math inline">\([0,1]\)</span></p></li>
</ul>
<p>一个比较重要的观测：当输入$ x_i+<span class="math inline">\(时，会被误分类为\)</span>y_{target}<span class="math inline">\(；另外，当输入\)</span>x^{'}=x_0+<span class="math inline">\(时，同样会被误分类，\)</span><span class="math inline">\(是噪声，而对于一般的噪声，使得\)</span>xx_0$，很难被误分类。</p>
<p>因此，基于这个观测，再来看上述公式，作者是在整个噪声空间中寻找合适的噪声，<span class="math inline">\(L_R\)</span>即为优化路径。</p>
<h2 id="触发器模式遗忘">触发器模式遗忘</h2>
<p>直接使用梯度上升如下： <span class="math display">\[
\theta_t+\frac{\partial \mathcal L}{\partial \theta_t}\to \theta_{t+1}
\]</span>
然而直接使用梯度上升会导致灾难性遗忘，因此采取了两步来解决：</p>
<ol type="1">
<li>使用一部分验证集训练，确保模型不遗忘正常的记忆</li>
<li>加入动态惩罚机制，避免过度遗忘。</li>
</ol>
<p><span class="math display">\[
\mathcal L_U=\alpha(\mathcal L_{CE}(F_{\theta_j}(x_c),y_c)-\mathcal
L_{CE}(F_{\theta_j}(x_b),y_b))+\beta\sum_{k=1}^M\omega_k\vert\theta_{j,k},-\theta_{0,k}\vert_1
\]</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/02/probability/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/02/probability/" class="post-title-link" itemprop="url">probability</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-01-02 19:00:18" itemprop="dateCreated datePublished" datetime="2024-01-02T19:00:18+08:00">2024-01-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-01-06 21:22:00" itemprop="dateModified" datetime="2024-01-06T21:22:00+08:00">2024-01-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>《应用数理统计》主要考点</strong></p>
<h1 id="一-样本及抽样分布"><strong>一、</strong> 样本及抽样分布</h1>
<p><strong>三大分布，正态总体抽样分布的结论.</strong></p>
<h2 id="正态分布">正态分布</h2>
<p><span class="math inline">\(\frac{x-\mu}{\sigma}\sim
N(0,1)\)</span></p>
<p>求分位点：</p>
<figure>
<img data-src="./probability/image-20240102191102358.png" alt="image-20240102191102358">
<figcaption aria-hidden="true">image-20240102191102358</figcaption>
</figure>
<h2 id="卡方分布">卡方分布</h2>
<figure>
<img data-src="./probability/image-20240102191144243.png" alt="image-20240102191144243">
<figcaption aria-hidden="true">image-20240102191144243</figcaption>
</figure>
<p>有几个正态分布，自由度就是几（上式中是n）</p>
<p>卡方分布的性质：</p>
<ul>
<li>均值为n，方差2n</li>
<li>可加性<img data-src="./probability/image-20240102191557248.png" alt="image-20240102191557248"></li>
</ul>
<h2 id="t分布">t分布</h2>
<p>定义：<img data-src="./probability/image-20240102192437471.png" alt="image-20240102192437471"></p>
<p>X是标准正态分布，Y是自由度为n的卡方分布。</p>
<p>性质：</p>
<ul>
<li>关于纵轴对称（y）</li>
<li>自由度趋近无穷，t分布趋近标准正态分布</li>
</ul>
<h2 id="f分布">F分布</h2>
<p>定义：<img data-src="./probability/image-20240102193421871.png" alt="image-20240102193421871"></p>
<p>U、V分别是自由度为n1、n2的卡方分布</p>
<h2 id="抽样分布结论">抽样分布结论</h2>
<figure>
<img data-src="./probability/image-20240102193625542.png" alt="image-20240102193625542">
<figcaption aria-hidden="true">image-20240102193625542</figcaption>
</figure>
<figure>
<img data-src="./probability/image-20240102193636953.png" alt="image-20240102193636953">
<figcaption aria-hidden="true">image-20240102193636953</figcaption>
</figure>
<figure>
<img data-src="./probability/image-20240102193645677.png" alt="image-20240102193645677">
<figcaption aria-hidden="true">image-20240102193645677</figcaption>
</figure>
<h1 id="二-参数估计">二、 参数估计</h1>
<p><strong>矩估计，极大似然估计，点估计量的无偏性、有效性，正态总体参数的置信区间.</strong></p>
<h2 id="矩估计">矩估计</h2>
<p>步骤：</p>
<ul>
<li>求总体原点距</li>
<li>列方程组</li>
<li>解方程组</li>
</ul>
<p>重要公式：</p>
<ul>
<li><span class="math inline">\(D(x)=E(X^2)-E^2(X)\)</span></li>
<li><span class="math inline">\(A_2-A_1^2=\frac{n-1}{n}S^2\)</span></li>
<li>均匀分布字母U，均值为<span class="math inline">\(\frac{a+b}{2}\)</span>，方差为<span class="math inline">\(\frac {(b-a)^2}{12}\)</span></li>
</ul>
<h2 id="极大似然估计">极大似然估计</h2>
<p>步骤：</p>
<ul>
<li>先求出取一次的函数<span class="math inline">\(p(x,p)\)</span></li>
<li>然后求出取n次的函数，也就是似然函数<span class="math inline">\(L(p)\)</span></li>
<li>对似然函数取对数</li>
<li>求导数，得到<span class="math inline">\(\hat p\)</span></li>
<li>带入值计算似然估计值</li>
</ul>
<figure>
<img data-src="./probability/image-20240103131847162.png" alt="image-20240103131847162">
<figcaption aria-hidden="true">image-20240103131847162</figcaption>
</figure>
<h2 id="无偏性">无偏性</h2>
<p>统计量的均值和总体的均值一样：<span class="math inline">\(E(T)=E(X)\)</span></p>
<h2 id="有效性">有效性</h2>
<p>有多个统计量（这里为2），哪个方差小，哪个就有效 <span class="math display">\[
D(T_1)&lt;D(T_2) \\
T_1 better
\]</span></p>
<p>另外，保证有效性的前提，是二者都是无偏估计，也就是说: <span class="math display">\[
E(T_1)=E(T_2)=E(X)
\]</span></p>
<h2 id="正态总体参数的置信区间">正态总体参数的置信区间</h2>
<p>解题步骤：</p>
<figure>
<img data-src="./probability/image-20240105142244150.png" alt="image-20240105142244150">
<figcaption aria-hidden="true">image-20240105142244150</figcaption>
</figure>
<h3 id="均值的区间估计">均值的区间估计</h3>
<h4 id="方差已知">方差已知</h4>
<figure>
<img data-src="./probability/image-20240105145956865.png" alt="image-20240105145956865">
<figcaption aria-hidden="true">image-20240105145956865</figcaption>
</figure>
<h4 id="方差未知">方差未知</h4>
<figure>
<img data-src="./probability/image-20240105150006980.png" alt="image-20240105150006980">
<figcaption aria-hidden="true">image-20240105150006980</figcaption>
</figure>
<h3 id="方差的区间估计">方差的区间估计</h3>
<figure>
<img data-src="./probability/image-20240105150030876.png" alt="image-20240105150030876">
<figcaption aria-hidden="true">image-20240105150030876</figcaption>
</figure>
<h1 id="三-假设检验">三、 假设检验</h1>
<p>单个正态总体均值或方差的假设检验.</p>
<p>单侧检验用的都是<span class="math inline">\(\alpha\)</span>，而双侧检验用的则是<span class="math inline">\(\alpha /2\)</span></p>
<figure>
<img data-src="./probability/image-20240106162940605.png" alt="image-20240106162940605">
<figcaption aria-hidden="true">image-20240106162940605</figcaption>
</figure>
<h2 id="方差已知-u检验法">方差已知 u检验法</h2>
<ul>
<li>两个假设<span class="math inline">\(H_0: \mu=\mu_0\)</span>、<span class="math inline">\(H_1\)</span></li>
<li>统计量<span class="math inline">\(U=\frac{\bar X-\mu_0}{\sigma/\sqrt
n}\)</span>，得到拒绝域：<span class="math inline">\(u=\frac{\bar
x-\mu_0}{\sigma/\sqrt n}&gt;u_\alpha\)</span></li>
</ul>
<h2 id="方差未知-t检验法">方差未知 T检验法</h2>
<p>由于方差<span class="math inline">\(\sigma
^2\)</span>未知，因此用样本方差<span class="math inline">\(s^2\)</span>代替即可，</p>
<ul>
<li>两个假设<span class="math inline">\(H_0: \mu\ge\mu_0\)</span>、<span class="math inline">\(H_1\)</span></li>
<li>统计量<span class="math inline">\(T=\frac{\bar X-\mu_0}{S/\sqrt
n}\)</span>，得到拒绝域：<span class="math inline">\(t=\frac{\bar
x-\mu_0}{s/\sqrt n}&gt;t_\alpha(n-1)\)</span></li>
</ul>
<h2 id="方差检验">方差检验</h2>
<ul>
<li>统计量<span class="math inline">\(\mathcal
X^2=\frac{(n-1)S^2}{\sigma_0 ^2}\)</span></li>
<li>拒绝域：<span class="math inline">\(\mathcal X^2&gt;\mathcal
X^2_{1-\alpha}(n-1)\)</span></li>
</ul>
<h1 id="四-方差分析与正交试验设计">四、 方差分析与正交试验设计</h1>
<p>单因素方差分析法，正交试验数据分析.</p>
<h2 id="单因素方差分析法">单因素方差分析法</h2>
<figure>
<img data-src="./probability/image-20240104162957501.png" alt="image-20240104162957501">
<figcaption aria-hidden="true">image-20240104162957501</figcaption>
</figure>
<p><span class="math inline">\(X_{..}\)</span>表示的是所有元素的和，<span class="math inline">\(X_{i.}\)</span>表示的是第i行所有元素的和 <span class="math display">\[
S_T^2=\sum\sum x_{ij}^2-\frac{x^2_{..}}{n} \\
S_A^2=\sum \frac{x^2_{i.}}{n_i}-\frac{x^2_{..}}{n} \\
S^2_E=S^2_T-S_A^2
\]</span> 拒绝域：<span class="math inline">\(F&gt;F_\alpha(\alpha - 1,n
- \alpha)\)</span></p>
<h2 id="正交试验数据分析">正交试验数据分析</h2>
<p>lue</p>
<h1 id="五-线性回归分析">五、 线性回归分析</h1>
<p>一元线性回归分析：参数估计，回归方程，显著性检验，预测值和预测区间.</p>
<h2 id="一元线性回归">一元线性回归</h2>
<ul>
<li><span class="math inline">\(S_{xx}=\sum x_i^2-n\bar
x^2\)</span></li>
<li><span class="math inline">\(S_{yy}=\sum y_i^2-n\bar
y^2\)</span></li>
<li><span class="math inline">\(S_{xy}=\sum x_iy_i-n\bar x\bar
y\)</span></li>
<li><span class="math inline">\(\hat
b=\frac{S_{xy}}{S_{xx}}\)</span>，斜率</li>
<li><span class="math inline">\(\hat a=\bar y-\bar x\hat
b\)</span>，至此方程已经写出</li>
<li><span class="math inline">\(Q_e=S_{yy}-\hat b^2S_{xx}\)</span></li>
<li><span class="math inline">\(\hat
\sigma^2=\frac{Q_e}{n-2}\)</span>，至此，求出方差</li>
</ul>
<h2 id="显著性检验">显著性检验</h2>
<h3 id="t检验-显著性检验">T检验 显著性检验</h3>
<ul>
<li>统计量<span class="math inline">\(T=\frac{\hat b}{\hat
\sigma^2}\sqrt {S_{xx}}\)</span></li>
<li>拒绝域<span class="math inline">\(|t|&gt;t_{\frac{\alpha}{2}}(n-2)\)</span></li>
</ul>
<h3 id="f检验-方差分析法">F检验 方差分析法</h3>
<ul>
<li><span class="math inline">\(S_r=\hat b^2S_{xx}\)</span></li>
<li><span class="math inline">\(F=\frac{S_r}{Q_e/(n-2)}\)</span></li>
<li>拒绝域<span class="math inline">\(F&gt;F_\alpha
(1,n-2)\)</span></li>
</ul>
<h2 id="预测值">预测值</h2>
<p>直接将x带入y=a+bx，得到的就是点预测</p>
<h2 id="区间预测">区间预测</h2>
<h1 id="六多元统计分析">六、多元统计分析</h1>
<p>主成份分析、典型相关分析、聚类分析、判别分析等方法的思想及计算步骤（简答）.</p>
<h1 id="总结">总结</h1>
<h2 id="考点">考点</h2>
<h3 id="矩估计-1">矩估计</h3>
<p><span class="math display">\[
A_1=\mu \\
A_2=\mu^2+\sigma^2\\
A_2-A_1^2=\frac{n-1}{n}S
\]</span></p>
<h3 id="极大似然估计-1">极大似然估计</h3>
<ul>
<li>累乘</li>
<li>取对数</li>
<li>求导</li>
<li>得到估计值</li>
<li>带值计算</li>
</ul>
<h3 id="均值检验-方差已知">均值检验 方差已知</h3>
<ul>
<li>统计量<span class="math inline">\(U=\frac{\bar X-\mu_0}{\sigma/\sqrt
n}\)</span></li>
<li>拒绝域<span class="math inline">\(u=\frac{\bar x-\mu_0}{\sigma/\sqrt
n}&gt;u_\alpha\)</span></li>
</ul>
<h3 id="均值检验-方差未知">均值检验 方差未知</h3>
<ul>
<li>统计量<span class="math inline">\(T=\frac{\bar X-\mu_0}{s/\sqrt
n}\)</span></li>
<li>拒绝域<span class="math inline">\(|t=\frac{\bar x-\mu_0}{s/\sqrt
n}|&gt;t_\alpha(n-1)\)</span></li>
</ul>
<p>注意拒绝域多了个绝对值。</p>
<h3 id="方差检验-1">方差检验</h3>
<ul>
<li>统计量<span class="math inline">\(x=\frac{(n-1)S^2}{\sigma_0
^2}\)</span></li>
<li>拒绝域：<span class="math inline">\(x^2&gt;x^2_\alpha(n-1)\)</span></li>
</ul>
<h3 id="方差分析">方差分析</h3>
<p><img data-src="./probability/image-20240104162957501.png" alt="image-20240104162957501"> <span class="math display">\[
S_T^2=\sum\sum x_{ij}^2-\frac{x^2_{..}}{n} \\
S_A^2=\sum \frac{x^2_{i.}}{n_i}-\frac{x^2_{..}}{n} \\
S^2_E=S^2_T-S_A^2
\]</span> 拒绝域：<span class="math inline">\(F&gt;F_\alpha(\alpha - 1,n
- \alpha)\)</span></p>
<h3 id="线性回归">线性回归</h3>
<ul>
<li><span class="math inline">\(S_{xx}=\sum x_i^2-n\bar
x^2\)</span></li>
<li><span class="math inline">\(S_{yy}=\sum y_i^2-n\bar
y^2\)</span></li>
<li><span class="math inline">\(S_{xy}=\sum x_iy_i-n\bar x\bar
y\)</span></li>
<li><span class="math inline">\(\hat
b=\frac{S_{xy}}{S_{xx}}\)</span>，斜率</li>
<li><span class="math inline">\(\hat a=\bar y-\bar x\hat
b\)</span>，至此方程已经写出</li>
<li><span class="math inline">\(Q_e=S_{yy}-\hat b^2S_{xx}\)</span></li>
<li><span class="math inline">\(\hat
\sigma^2=\frac{Q_e}{n-2}\)</span>，至此，求出方差</li>
</ul>
<h3 id="t检验-显著性检验-1">T检验 显著性检验</h3>
<ul>
<li>统计量<span class="math inline">\(T=\frac{\hat b}{\hat
\sigma^2}\sqrt {S_{xx}}\)</span></li>
<li>拒绝域<span class="math inline">\(|t|&gt;t_{\frac{\alpha}{2}}(n-2)\)</span></li>
</ul>
<h3 id="f检验-方差分析法-1">F检验 方差分析法</h3>
<ul>
<li><span class="math inline">\(S_r=\hat b^2S_{xx}\)</span></li>
<li><span class="math inline">\(F=\frac{S_r}{Q_e/(n-2)}\)</span></li>
<li>拒绝域<span class="math inline">\(F&gt;F_\alpha
(1,n-2)\)</span></li>
</ul>
<h2 id="背书">背书</h2>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/30/matrix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/12/30/matrix/" class="post-title-link" itemprop="url">matrix</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-12-30 09:56:25" itemprop="dateCreated datePublished" datetime="2023-12-30T09:56:25+08:00">2023-12-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-01-07 16:23:21" itemprop="dateModified" datetime="2024-01-07T16:23:21+08:00">2024-01-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="第一章">第一章</h1>
<h2 id="子空间">子空间</h2>
<ul>
<li>加法</li>
<li>数乘</li>
<li>取值证明子空间非空</li>
</ul>
<h2 id="线性变换">线性变换</h2>
<ol type="1">
<li>证明线性变换
<ul>
<li>加法</li>
<li>数乘</li>
</ul></li>
<li>求线性变换T在基E下的矩阵
<ul>
<li>求出<span class="math inline">\(T(E_1)=(E_1,E_2,E_3)(x_1,x_2,x_3)^T\)</span></li>
<li>将x的向量拼起来，得到矩阵</li>
</ul></li>
</ol>
<h1 id="第二章">第二章</h1>
<h2 id="内积">内积</h2>
<ol type="1">
<li><p>证明内积</p>
<p>验证：</p>
<ul>
<li><span class="math inline">\((\alpha,\beta)=(\beta,\alpha)\)</span></li>
<li><span class="math inline">\((k\alpha,\beta)=k(\alpha,\beta)\)</span></li>
<li><span class="math inline">\((\alpha+\beta,\gamma)=(\alpha,\gamma)+(\beta,\gamma)\)</span></li>
<li><span class="math inline">\((\alpha,\alpha)\ge0\)</span></li>
</ul></li>
<li><p>求标准正交基</p>
<ul>
<li><p>最终都可以化成矩阵，例如：</p>
<figure>
<img data-src="./matrix/image-20231230101957379.png" alt="image-20231230101957379">
<figcaption aria-hidden="true">image-20231230101957379</figcaption>
</figure>
<figure>
<img data-src="./matrix/image-20231230102006811.png" alt="image-20231230102006811">
<figcaption aria-hidden="true">image-20231230102006811</figcaption>
</figure>
<p>把前两个当未知数，后三个依次取100 010 001</p>
<p>得到三个基。</p></li>
<li><p>正交化</p>
<figure>
<img data-src="./matrix/image-20231230102307464.png" alt="image-20231230102307464">
<figcaption aria-hidden="true">image-20231230102307464</figcaption>
</figure></li>
<li><p>单位化</p>
<figure>
<img data-src="./matrix/image-20231230102330894.png" alt="image-20231230102330894">
<figcaption aria-hidden="true">image-20231230102330894</figcaption>
</figure></li>
</ul></li>
</ol>
<h1 id="第三章">第三章</h1>
<h2 id="约旦标准型">约旦标准型</h2>
<ul>
<li>求出行列式因子<span class="math inline">\(D_1,D_2,D_3\)</span></li>
<li>求不变因子<span class="math inline">\(d_1,d_2,d_3\)</span></li>
<li>求初等因子</li>
<li>写Jordan块</li>
</ul>
<h2 id="最小多项式">最小多项式</h2>
<ul>
<li><p>求特征多项式</p>
<figure>
<img data-src="./matrix/image-20231230114208265.png" alt="image-20231230114208265">
<figcaption aria-hidden="true">image-20231230114208265</figcaption>
</figure></li>
<li><p>所有可能的最小多项式</p>
<figure>
<img data-src="./matrix/image-20231230114230409.png" alt="image-20231230114230409">
<figcaption aria-hidden="true">image-20231230114230409</figcaption>
</figure></li>
<li><p>验证：把<span class="math inline">\(\lambda\)</span>换成A，数字换成E，哪个为0矩阵，就是最小多项式</p></li>
</ul>
<h1 id="第四章">第四章</h1>
<h2 id="lu分解">LU分解</h2>
<p>将(A,E)进行初等变换，直到A变成了上三角矩阵，那么左边就是U，右边是L的逆矩阵，求逆得到L</p>
<figure>
<img data-src="./matrix/image-20240102151627607.png" alt="image-20240102151627607">
<figcaption aria-hidden="true">image-20240102151627607</figcaption>
</figure>
<h2 id="qr分解">QR分解</h2>
<p>方针的QR分解如下：</p>
<figure>
<img data-src="./matrix/image-20240102153251242.png" alt="image-20240102153251242">
<figcaption aria-hidden="true">image-20240102153251242</figcaption>
</figure>
<figure>
<img data-src="./matrix/image-20240102153301164.png" alt="image-20240102153301164">
<figcaption aria-hidden="true">image-20240102153301164</figcaption>
</figure>
<p>对于非方阵，需要使用施密特正交化：</p>
<figure>
<img data-src="./matrix/image-20240104202323908.png" alt="image-20240104202323908">
<figcaption aria-hidden="true">image-20240104202323908</figcaption>
</figure>
<figure>
<img data-src="./matrix/image-20240104202332599.png" alt="image-20240104202332599">
<figcaption aria-hidden="true">image-20240104202332599</figcaption>
</figure>
<h2 id="满秩分解">满秩分解</h2>
<figure>
<img data-src="./matrix/image-20240102162204976.png" alt="image-20240102162204976">
<figcaption aria-hidden="true">image-20240102162204976</figcaption>
</figure>
<p>C取得是初等变换后，除掉0行后剩下的矩阵</p>
<p>B取得是初等变换后得到的行最简H，”1“所在的列在原矩阵A中的表示。</p>
<h2 id="a"><span class="math inline">\(A^+\)</span></h2>
<figure>
<img data-src="./matrix/image-20240102162240251.png" alt="image-20240102162240251">
<figcaption aria-hidden="true">image-20240102162240251</figcaption>
</figure>
<h2 id="相容性">相容性</h2>
<p>若是<span class="math inline">\(AA^+b\ne b\)</span>，那么不相容</p>
<h2 id="奇艺值">奇艺值</h2>
<p>只需要会算奇艺值即可。</p>
<figure>
<img data-src="./matrix/image-20240102162724100.png" alt="image-20240102162724100">
<figcaption aria-hidden="true">image-20240102162724100</figcaption>
</figure>
<h1 id="第五章">第五章</h1>
<p>证明XXX是一种范数，略</p>
<h2 id="常见矩阵范数">常见矩阵范数</h2>
<figure>
<img data-src="./matrix/image-20240102163944561.png" alt="image-20240102163944561">
<figcaption aria-hidden="true">image-20240102163944561</figcaption>
</figure>
<figure>
<img data-src="./matrix/image-20240102163957039.png" alt="image-20240102163957039">
<figcaption aria-hidden="true">image-20240102163957039</figcaption>
</figure>
<p>总结；</p>
<figure>
<img data-src="./matrix/image-20240102164009644.png" alt="image-20240102164009644">
<figcaption aria-hidden="true">image-20240102164009644</figcaption>
</figure>
<h2 id="求最小二乘解">求最小二乘解</h2>
<p>先求出<span class="math inline">\(A^+\)</span></p>
<p>然后<img data-src="./matrix/image-20240102164106539.png" alt="image-20240102164106539"></p>
<p>极小范数的最小二乘解：<img data-src="./matrix/image-20240102164135525.png" alt="image-20240102164135525"></p>
<h1 id="第六章">第六章</h1>
<figure>
<img data-src="./matrix/image-20240107161839651.png" alt="image-20240107161839651">
<figcaption aria-hidden="true">image-20240107161839651</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">chengyiqiu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>

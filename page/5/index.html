<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width":280,"display":"post","offset":10,"onmobile":true},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":true},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="chengyiqiu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/5/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/5/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">chengyiqiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/chengyiqiu1121" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chengyiqiu1121" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/22/MetaPoison/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/22/MetaPoison/" class="post-title-link" itemprop="url">MetaPoison</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-22 20:28:07" itemprop="dateCreated datePublished" datetime="2023-10-22T20:28:07+08:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-11-13 15:44:29" itemprop="dateModified" datetime="2023-11-13T15:44:29+08:00">2023-11-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="abstract">abstract</h1>
<p>现有的攻击主要都是手工制作的攻击，为什么让机器去做呢？因为这通常是一个bilevel
optimization（双层优化）问题，这对于深度模型来说是不好求解的。</p>
<p>提出的攻击：MetaPoison。通过first- order
method（一阶方法）来近似bilevel optimization。</p>
<p>其特性：</p>
<ul>
<li>高效性：通过和clean-label方法对比</li>
<li>健壮性：对一个模型的中毒攻击能够同样适用于其他的一些架构和训练设置未知的模型上去。</li>
<li>通用性：不仅适用于微调场景，而且也能用作端到端场景下（clean-
label攻击没有这个性质）</li>
</ul>
<p>在现实世界中，对Google Cloud AutoML API进行了攻击。</p>
<h1 id="method">method</h1>
<h2 id="受限制的双层优化问题">受限制的双层优化问题</h2>
<p>双层优化问题的描述如下：</p>
<figure>
<img data-src="./MetaPoison/image-20231030151120750.png" alt="image-20231030151120750">
<figcaption aria-hidden="true">image-20231030151120750</figcaption>
</figure>
<p>s.t. <img data-src="./MetaPoison/image-20231030151152980.png" alt="image-20231030151152980"></p>
<p>符号：</p>
<ul>
<li><span class="math inline">\(X_c\)</span>：干净数据 ｜ <span class="math inline">\(X_p\)</span>： 中毒数据</li>
<li><span class="math inline">\(Y\)</span>：包含中毒攻击的样本以及正常样本 ｜
<span class="math inline">\(y_{adv}\)</span>：中毒样本</li>
</ul>
<p>先优化train阶段（<span class="math inline">\(\mathcal
L_{train}\)</span>使用的就是简单的交叉熵），然后再优化adversary阶段（<span class="math inline">\(\mathcal L_{adv}\)</span>使用的是<a target="_blank" rel="noopener" href="https://readpaper.com/paper/623763322802241536">Towards Evaluating
the Robustness of Neural Networks</a>中提到的adversarial loss <span class="math inline">\(f_6\)</span>），最终的目标是找到<span class="math inline">\(X_p^{*}\)</span></p>
<p>为什么标题中双层优化问题加了一个constrained，因为中毒后的样本应该和自然的样本比较相似。基于此，作者选取了一个扰动模型（<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2947028053">Functional Adversarial
Attacks</a>，称为<span class="math inline">\(f_g\)</span>，g代表的是模型的参数： <span class="math display">\[
x_p=f_g(x)+\delta
\]</span></p>
<h2 id="策略">策略</h2>
<p>将双层优化都最小化不太现实，这里作者选择：对于<span class="math inline">\(\mathcal
L_{train}\)</span>，使用K步SGD，然后再优化<span class="math inline">\(\mathcal
L_{adv}\)</span>。例如当K取2时，优化过程可以描述为：</p>
<figure>
<img data-src="./MetaPoison/image-20231030155536272.png" alt="image-20231030155536272">
<figcaption aria-hidden="true">image-20231030155536272</figcaption>
</figure>
<figure>
<img data-src="./MetaPoison/image-20231030155755080.png" alt="image-20231030155755080">
<figcaption aria-hidden="true">image-20231030155755080</figcaption>
</figure>
<p>上面的方法称为展开训练管道，其成功的应用不在少数（元学习、超参数搜索、架构搜索）</p>
<p>但将展开训练管道应用于本文的中毒攻击的双层优化问题，会有一些问题：</p>
<ol type="1">
<li>对权重初始化以及小批量数据的次序敏感，这些都是攻击者的知识涉及不到的。</li>
<li>作者的经验之谈：一个epoch内，使用单个代理网络来产生中毒，会使得这个网络对这一轮的数据过拟合，这样的后果就是模型对新数据的引导能力下降了（模型的目的是投毒使得受害者模型朝着<span class="math inline">\(\mathcal L_{adv}\)</span>的方向偏转）</li>
</ol>
<p>也就是说，本文需要的不是一个能够完美解决bilevel
optimization的模型，而是一个可以对初始化不敏感、对epoch不敏感的模型。也就是说需要提升模型的泛化能力。</p>
<p>作者选择使用<strong>集成</strong>以及<strong>按epoch交替学习</strong>的办法来增加最终得到模型的泛化能力。</p>
<ul>
<li>集成：有很多个代理模型来训练</li>
<li>按epoch交替学习：字面意思</li>
</ul>
<p>然后作者将他的工作和已存在的工作进行了对比，通过计算，作者的任务需要5760次传播，而对比的已存在的任务需要12000次传播。</p>
<h1 id="experience">experience</h1>
<figure>
<img data-src="./MetaPoison/image-20231030194721267.png" alt="image-20231030194721267">
<figcaption aria-hidden="true">image-20231030194721267</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/22/cs224w-ch8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/22/cs224w-ch8/" class="post-title-link" itemprop="url">cs224w_ch8</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-22 14:58:31" itemprop="dateCreated datePublished" datetime="2023-10-22T14:58:31+08:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-11-13 15:42:19" itemprop="dateModified" datetime="2023-11-13T15:42:19+08:00">2023-11-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="graph-augmentation">Graph augmentation</h1>
<p>for one graph G, if:</p>
<ul>
<li>G is too <strong>sparce</strong> =&gt; MP(message-passing) not
efficient</li>
<li>G is too <strong>dense</strong> =&gt; MP costly</li>
<li>G is too <strong>large</strong> =&gt; GPU memory not enough</li>
</ul>
<p>then it is unlikely to use the computational graph as the raw input.
<span class="math inline">\(G_{raw}\ne G_{computational}\)</span></p>
<p>Here are some methods to do Graph Augmentation:</p>
<figure>
<img data-src="./cs224w-ch8/image-20231022164424785.png" alt="image-20231022164424785">
<figcaption aria-hidden="true">image-20231022164424785</figcaption>
</figure>
<h2 id="feature-augmentation">feature augmentation</h2>
<h3 id="lake-feature">lake feature</h3>
<p>if we only have adj. matrix, the simple methods are:</p>
<ul>
<li>assign constant value to nodes(value 1)</li>
<li>Assign unique IDs to nodes(one-hot encoding)</li>
</ul>
<figure>
<img data-src="./cs224w-ch8/image-20231022164848622.png" alt="image-20231022164848622">
<figcaption aria-hidden="true">image-20231022164848622</figcaption>
</figure>
<h3 id="hard-to-learn-gnns-struct">hard to learn GNNs struct</h3>
<p>for example, the GNN can't capture the cycle length of node v:</p>
<figure>
<img data-src="./cs224w-ch8/image-20231022165312463.png" alt="image-20231022165312463">
<figcaption aria-hidden="true">image-20231022165312463</figcaption>
</figure>
<p>This means: <strong>use the graph struct as computational graph is
not enough. Nodes cannot learn the graph certain struct.</strong></p>
<p>the solution is: add more network struct frature to node.</p>
<figure>
<img data-src="./cs224w-ch8/image-20231022165503259.png" alt="image-20231022165503259">
<figcaption aria-hidden="true">image-20231022165503259</figcaption>
</figure>
<p>these can be seen in ch2 or 3.</p>
<h2 id="struct-augmentation">struct augmentation</h2>
<h3 id="add-virtual-edges">add virtual edges</h3>
<p>common approach: use <span class="math inline">\(\mathcal{A}+\mathcal{A}^2\)</span> instead <span class="math inline">\(\mathcal{A}\)</span> as computational graph.</p>
<p>for example, in bipartite graphs:</p>
<figure>
<img data-src="./cs224w-ch8/image-20231022165905886.png" alt="image-20231022165905886">
<figcaption aria-hidden="true">image-20231022165905886</figcaption>
</figure>
<p>if use <span class="math inline">\(\mathcal{A}+\mathcal{A}
^2\)</span>, the 2-hop nodes will be connected, which means we can get a
co-authors-paper network or co-paper- author network.</p>
<h3 id="add-virtual-ndoes">add virtual ndoes</h3>
<p>common approach: add a vitual node than connects to all nodes.</p>
<p>if the graph is too sparse, and 2 node distance 10-hops, then the
virtual node can improve the message passing.</p>
<figure>
<img data-src="./cs224w-ch8/image-20231022170418205.png" alt="image-20231022170418205">
<figcaption aria-hidden="true">image-20231022170418205</figcaption>
</figure>
<h3 id="node-neighbor-sample">node neighbor sample</h3>
<p>if a node's degree is too large(<span class="math inline">\(10^5
degrees\)</span>), then we can sample the most important 1000 or 10000
nodes to converge. And in next epoch, we randomly sample again to
increase the robust of model.</p>
<figure>
<img data-src="./cs224w-ch8/image-20231022170715701.png" alt="image-20231022170715701">
<figcaption aria-hidden="true">image-20231022170715701</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/22/FlowGNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/22/FlowGNN/" class="post-title-link" itemprop="url">FlowGNN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-22 07:53:34" itemprop="dateCreated datePublished" datetime="2023-10-22T07:53:34+08:00">2023-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-11-13 15:43:58" itemprop="dateModified" datetime="2023-11-13T15:43:58+08:00">2023-11-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="abstract">abstract</h1>
<p>the limitation:</p>
<ul>
<li><p>GNN needs fast inference.</p></li>
<li><p>Existing works focus on target GNN acceleration, such as
GCN.</p></li>
<li><p>And many works rely on pre-processing which is not suitable to
<strong>real-time application</strong>.</p></li>
</ul>
<p>This paper work:</p>
<ul>
<li>Propose FlowGNN, which is <strong>generalizable</strong> to the
majority of message -passing GNNs.</li>
</ul>
<p>and more in details:</p>
<ol type="1">
<li>a novel and <strong>scalable dataflow architecture</strong>(enhance
speed of message-passing)</li>
<li><del>real-time GNN inference without any pre-processing</del></li>
<li>verify the proposed architecture on FPGA board(Xilinx Alveo U50 FPGA
board)</li>
</ol>
<h1 id="related-work-and-motivation">Related work and motivation</h1>
<h2 id="related-work">Related work</h2>
<p>Mentioning a survey: <a target="_blank" rel="noopener" href="https://readpaper.com/paper/3214821766">Computing Graph Neural
Networks: A Survey from Algorithms to Accelerators</a>.</p>
<h2 id="limitation">Limitation</h2>
<p>The most significant is that <strong>advanced GNNs cannot be
simplified as matrix multiplications(the method is SpMM and GEMM), and
edge embeddings cannot be ignored.</strong></p>
<h3 id="edge-embedding">Edge embedding</h3>
<p>Edge embeddings are used to represent important edge attributes, such
as chemical bonds in a molecule.</p>
<p>this make the SpMM and GEMM not useful.</p>
<figure>
<img data-src="./FlowGNN/image-20231022095259558.png" alt="image-20231022095259558">
<figcaption aria-hidden="true">image-20231022095259558</figcaption>
</figure>
<p>if not use edge embedding, message passing is <span class="math inline">\(\phi (x_i^l)\)</span>, and it can be optimized by
GEMM and SpMM.However, if use embedding, it will be <span class="math inline">\(\phi (x_i^l,e_{i,j}^l)\)</span>, and the demension
of node representation and edge representation is not same.</p>
<figure>
<img data-src="./FlowGNN/image-20231022095645741.png" alt="image-20231022095645741">
<figcaption aria-hidden="true">image-20231022095645741</figcaption>
</figure>
<h3 id="invalid-existing-optimizations">Invalid existing
optimizations</h3>
<p>SOTA I-GCN merge the same neighbor node as one node to optimize.</p>
<figure>
<img data-src="./FlowGNN/image-20231022095925172.png" alt="image-20231022095925172">
<figcaption aria-hidden="true">image-20231022095925172</figcaption>
</figure>
<p>However, considering edge embedding, the <span class="math inline">\(e_{ac},e_{bc}\)</span> is not the same as <span class="math inline">\(e_{bc},e_{bd}\)</span></p>
<p>we cannot converge the node a and b</p>
<h3 id="non-trivial-aggregation">Non-trivial aggregation</h3>
<p>the GEMM and SpMM use a certain pattern to optimize. However ,the
compute coefficient is dynamic.</p>
<h3 id="anisotropic-gnns">Anisotropic GNNs</h3>
<p>such as GAT, it has a attention coefficient which is calculated by
<span class="math inline">\(x_i^{l},x_j^l\)</span>. and it is dynamic,
which prevents GAT from being expressed as matrix multiplications to
optimize.</p>
<h3 id="pre-processing">Pre-processing</h3>
<p>not applicable in RT application</p>
<h2 id="motivations-and-innovations">Motivations and Innovations</h2>
<p>Innovation:</p>
<ul>
<li>Explicit message passing for generality</li>
<li>Multi-queue multi-level parallelism for performance</li>
</ul>
<h1 id="generic-architecture">GENERIC ARCHITECTURE*</h1>
<h2 id="message-passing-mechanism">Message Passing Mechanism</h2>
<figure>
<img data-src="./FlowGNN/image-20231022110739588.png" alt="image-20231022110739588">
<figcaption aria-hidden="true">image-20231022110739588</figcaption>
</figure>
<p><img data-src="./FlowGNN/image-20231022110042383.png" alt="image-20231022110042383"> <span class="math display">\[
\mathcal{MP scatter} \\
m_{1\to 0}^{l-1}=\phi (x_1^{l-1},e_{0,1}^{l-1}) \\
\mathcal{MP gather} \\
m_0^l=\mathcal A(m_{1\to0}^{l-1}) \\
m_1^l=\mathcal A(m_{0\to1}^{l-1},m_{2\to1}^{l-1},m_{3\to1}^{l-1}) \\
\mathcal{NT} \\
x_1^l=\gamma (m_1^l,x_1^{l-1})
\]</span></p>
<p>3 phases:</p>
<ol type="1">
<li><p><strong>message passing(gather)</strong>:</p>
<p>from message buffer get <span class="math inline">\(m\)</span>, and
do aggregating <span class="math inline">\(A(m_{2\to1}^l, m_{3\to1}^l,
m_{4\to1}^l)\)</span>.</p>
<p>the <span class="math inline">\(\mathcal{A}(.)\)</span> function
could be <strong>sum, max, mean, std.dev</strong>.</p></li>
<li><p><strong>node transformation</strong>:</p>
<p><span class="math inline">\(\gamma (x_1^l, m_1^l)\)</span>.</p>
<p><span class="math inline">\(\gamma (.)\)</span> could be
<strong>full-connected layer, MLP</strong>...</p></li>
<li><p><strong>message passing(scatter)</strong>:</p>
<p><span class="math inline">\(\phi (x_1^{l+1},e_{1,2}^{l+1})\to m_{1\to
2}^{l+1}\)</span>. Sent it to message buffer for the next layer Message
passing(gather)</p></li>
</ol>
<h2 id="baseline-dataflow-architecture">Baseline Dataflow
Architecture</h2>
<figure>
<img data-src="./FlowGNN/image-20231022130835181.png" alt="image-20231022130835181">
<figcaption aria-hidden="true">image-20231022130835181</figcaption>
</figure>
<p>use ping-pang buffer(b =&gt; d):</p>
<p><img data-src="./FlowGNN/image-20231022192909514.png" alt="image-20231022192909514"></p>
<h2 id="proposed-flowgnn-architecture">Proposed FlowGNN
Architecture</h2>
<figure>
<img data-src="./FlowGNN/image-20231022135221394.png" alt="image-20231022135221394">
<figcaption aria-hidden="true">image-20231022135221394</figcaption>
</figure>
<figure>
<img data-src="./FlowGNN/image-20231022144445441.png" alt="image-20231022144445441">
<figcaption aria-hidden="true">image-20231022144445441</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/18/cs224w-ch7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/18/cs224w-ch7/" class="post-title-link" itemprop="url">cs224w_ch7</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-18 21:57:39" itemprop="dateCreated datePublished" datetime="2023-10-18T21:57:39+08:00">2023-10-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-11-09 09:18:53" itemprop="dateModified" datetime="2023-11-09T09:18:53+08:00">2023-11-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="a-single-layer-og-gnn">a single layer og GNN</h1>
<p>there are many different GNN: GCN, GraphSAGE, GAT...</p>
<p>the difference between them mainly are:</p>
<ul>
<li>message send</li>
<li>message aggregation</li>
</ul>
<figure>
<img data-src="./cs224w-ch7/image-20231018220120532.png" alt="image-20231018220120532">
<figcaption aria-hidden="true">image-20231018220120532</figcaption>
</figure>
<h2 id="message-send">message send</h2>
<p><span class="math display">\[
m_u^l=\mathcal {MSG}^{(l)}(h_u^{l-1})
\]</span></p>
<p>moostly the message function is linear: <span class="math display">\[
m_u^l=W^{(l)}h_u^{(l-1)}
\]</span> <img data-src="./cs224w-ch7/image-20231018220634661.png" alt="image-20231018220634661"></p>
<h2 id="message-aggregation">message aggregation</h2>
<p>the aggregate function could be: sum, average, or max polling...</p>
<p>and its previous message also should be considered, so:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231018220734835.png" alt="image-20231018220734835">
<figcaption aria-hidden="true">image-20231018220734835</figcaption>
</figure>
<figure>
<img data-src="./cs224w-ch7/image-20231018220745103.png" alt="image-20231018220745103">
<figcaption aria-hidden="true">image-20231018220745103</figcaption>
</figure>
<h1 id="gcn">GCN</h1>
<p>Lets look at GCN, single layer:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231018220913386.png" alt="image-20231018220913386">
<figcaption aria-hidden="true">image-20231018220913386</figcaption>
</figure>
<ul>
<li>message send: <strong>one linear and a normalized factor <span class="math inline">\(\frac{1}{N}\)</span></strong></li>
<li>message aggregate: <strong>use <span class="math inline">\(SUM(.)\)</span> as the aggregate
function</strong></li>
</ul>
<h1 id="graphsage">GraphSAGE</h1>
<h2 id="single-attention">Single attention</h2>
<figure>
<img data-src="./cs224w-ch7/image-20231018221152676.png" alt="image-20231018221152676">
<figcaption aria-hidden="true">image-20231018221152676</figcaption>
</figure>
<p>it can select <span class="math inline">\(SUM(.),MAX(.)...\)</span>
as its AGG.</p>
<p>and the linear is behand AGG with a concat.</p>
<p>What's more, the AGG also canbe:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231018221459065.png" alt="image-20231018221459065">
<figcaption aria-hidden="true">image-20231018221459065</figcaption>
</figure>
<h1 id="gat">GAT</h1>
<figure>
<img data-src="./cs224w-ch7/image-20231018221534957.png" alt="image-20231018221534957">
<figcaption aria-hidden="true">image-20231018221534957</figcaption>
</figure>
<p>Intuition: different neighbors set different <strong>attention
coefficient</strong>.</p>
<p>for GCN, it is <span class="math inline">\(\frac{1}{N}\)</span></p>
<p>and for CAT, how to caculate attention?</p>
<p>the importance of u towards v is:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231018221924962.png" alt="image-20231018221924962">
<figcaption aria-hidden="true">image-20231018221924962</figcaption>
</figure>
<p>the weight is form a linear:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231018222042889.png" alt="image-20231018222042889">
<figcaption aria-hidden="true">image-20231018222042889</figcaption>
</figure>
<p>and for a node v, its attention is:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231018222004730.png" alt="image-20231018222004730">
<figcaption aria-hidden="true">image-20231018222004730</figcaption>
</figure>
<h2 id="mult-attention">Mult-attention</h2>
<figure>
<img data-src="./cs224w-ch7/image-20231018222156770.png" alt="image-20231018222156770">
<figcaption aria-hidden="true">image-20231018222156770</figcaption>
</figure>
<p>the reason is: avoid the attention coefficient to trap into local
optimization</p>
<h1 id="deep-learning-module">Deep learning module</h1>
<figure>
<img data-src="./cs224w-ch7/image-20231019080319778.png" alt="image-20231019080319778">
<figcaption aria-hidden="true">image-20231019080319778</figcaption>
</figure>
<h2 id="batch-normalization">batch normalization</h2>
<p>Goal: stablize the train stage</p>
<p>Idea:</p>
<ul>
<li>Re-center the node mean to 0</li>
<li>Re-scale the variance to 1</li>
</ul>
<p>Setup:</p>
<ul>
<li><p>Re-center and re-scale:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231019080836608.png" alt="image-20231019080836608">
<figcaption aria-hidden="true">image-20231019080836608</figcaption>
</figure></li>
<li><p>use trainable parameter <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\gamma\)</span> to normalize the label</p>
<figure>
<img data-src="./cs224w-ch7/image-20231019081048015.png" alt="image-20231019081048015">
<figcaption aria-hidden="true">image-20231019081048015</figcaption>
</figure></li>
</ul>
<h2 id="dropout">Dropout</h2>
<p>Goal: prevent overfitting</p>
<p>Idea:</p>
<ul>
<li>when training, randomly(the prob. p) set some neurons to 0</li>
<li>when testing, using all neurons to computer.</li>
</ul>
<p>In mlp:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231019082644910.png" alt="image-20231019082644910">
<figcaption aria-hidden="true">image-20231019082644910</figcaption>
</figure>
<p>in GNN, it is in the stage of <strong>message send</strong>, in
linear layer:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231019082752171.png" alt="image-20231019082752171">
<figcaption aria-hidden="true">image-20231019082752171</figcaption>
</figure>
<h2 id="activation">Activation</h2>
<figure>
<img data-src="./cs224w-ch7/image-20231019083002574.png" alt="image-20231019083002574">
<figcaption aria-hidden="true">image-20231019083002574</figcaption>
</figure>
<h1 id="stack-layers-of-a-gnn">Stack Layers of a GNN</h1>
<p>how to stack single GNN layer?</p>
<ul>
<li>stack layers sequentially</li>
<li>add skip connections</li>
</ul>
<h2 id="stack-layers-sequentially">stack layers sequentially</h2>
<p>let's see a 3 layers GNNs:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021214229778.png" alt="image-20231021214229778">
<figcaption aria-hidden="true">image-20231021214229778</figcaption>
</figure>
<p>what's the problem?</p>
<p>It might <strong>over-smoothing</strong></p>
<p>The notion is: <strong>in the i th layer(such as 4th, 5th...), all
node embeddings converge to the same value.</strong> This means in the
last layer, all nodes are same. And our object is to make distinguish
deferent nodes.</p>
<p>let's talk about an another notion: <strong>Receptive
Field</strong></p>
<p>it means: <strong>the set of nodes that determine the enbedding of a
node of interest.</strong></p>
<p>and in GNN, the receptive field of one node can be seen as K-hop
neighborhood.</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021215129650.png" alt="image-20231021215129650">
<figcaption aria-hidden="true">image-20231021215129650</figcaption>
</figure>
<p>and the over-smoothing problem can be represent as:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021215316837.png" alt="image-20231021215316837">
<figcaption aria-hidden="true">image-20231021215316837</figcaption>
</figure>
<p>so, the lesson is: we should determine the layers number
cautious.</p>
<p>And the experience is: <strong>the GNNs layers number is often the
receptive field of nodes plus one.</strong></p>
<h2 id="enhance-the-expression-power">enhance the expression power</h2>
<p>the next problem is: how could <strong>enhance the expression
power</strong> of GNN?</p>
<ol type="1">
<li><p>add layers that not passing message</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021215956703.png" alt="image-20231021215956703">
<figcaption aria-hidden="true">image-20231021215956703</figcaption>
</figure></li>
<li><p>Increasing the expressive power withen each layers</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021220204140.png" alt="image-20231021220204140">
<figcaption aria-hidden="true">image-20231021220204140</figcaption>
</figure></li>
</ol>
<h2 id="skip-connection">skip connection</h2>
<p>the problem is: what if some downstream task <strong>still needs many
GNN layers</strong>?</p>
<p>the intuition is from ResNet.</p>
<p>we could add skip connections in GNNs.</p>
<p>one way:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021221203305.png" alt="image-20231021221203305">
<figcaption aria-hidden="true">image-20231021221203305</figcaption>
</figure>
<p>Another:</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021221218844.png" alt="image-20231021221218844">
<figcaption aria-hidden="true">image-20231021221218844</figcaption>
</figure>
<p>why does it useful?</p>
<p>the skip connection model can create a mixture of n models.</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021221332742.png" alt="image-20231021221332742">
<figcaption aria-hidden="true">image-20231021221332742</figcaption>
</figure>
<p>the difference of GCN and the GCN with skip connection</p>
<figure>
<img data-src="./cs224w-ch7/image-20231021221451314.png" alt="image-20231021221451314">
<figcaption aria-hidden="true">image-20231021221451314</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/17/DAGAD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/17/DAGAD/" class="post-title-link" itemprop="url">DAGAD</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-17 20:21:36" itemprop="dateCreated datePublished" datetime="2023-10-17T20:21:36+08:00">2023-10-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-01-13 18:01:34" itemprop="dateModified" datetime="2024-01-13T18:01:34+08:00">2024-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>小组基本信息：</p>
<ul>
<li>小组方向：AI算法在入侵检测、恶意软件识别、恶意流量识别方面的应用</li>
<li>论文题目：DAGAD: Data Augmentation for Graph Anomaly Detection</li>
</ul>
<h1 id="摘要">摘要</h1>
<ol type="1">
<li>检测异常结点，属于结点型任务</li>
<li>目前存在的两个问题：
<ul>
<li>异常结点很难被捕获，其异常行为很微小，并且往往没有关于异常结点的先验知识</li>
<li>现实世界中大部分的结点都是正常的，就像银行贷款一样，往往1w人里面只有几个人是不还贷款的“异常结点”。存在严重的类别不平衡问题。</li>
</ul></li>
<li>本文的模型：
<ul>
<li>GNN将非欧数据压缩为d维向量（表征学习）</li>
<li>图增强模块，通过对生成的d维向量增加扰动，来进行数据增强，使用增强之后的生成数据作为训练集。</li>
<li>一个用来对类别不平衡数据进行分类的模型</li>
</ul></li>
<li>在DAGAD的架构下（分别是基于DAGAD的GCN和GAT），测试了三个数据集。</li>
</ol>
<h1 id="介绍">介绍</h1>
<p>根据下游任务，也可以将图异常检测划分为：node-level, link-level,
graph-level。下面以经融交易举例子：</p>
<ul>
<li>异常结点：诈骗犯</li>
<li>异常边：异常交易</li>
<li>异常子图：诈骗窝</li>
</ul>
<p>该文章针对异常结点的检测。</p>
<p>现在的图异常检测都是通过图的拓扑结构以及特征信息来进行的。不足之处在于：</p>
<ul>
<li>异常样本太少了：例如在交易场景，90%的人在受到诈骗之后不会像平台反馈，这就<strong>导致了异常结点、异常边被标记为正常</strong>！</li>
<li>类别不平衡</li>
</ul>
<p>另外，以前的方法在处理有限的异常结点时，没有充分利用异常结点，这也影响了最后模型区分异常结点和正常结点的能力。</p>
<h1 id="框架">框架</h1>
<h2 id="图神经网络">图神经网络</h2>
<p>本文中作者使用GCN或GAT来将结点特征压缩为d维向量。</p>
<figure>
<img data-src="./DAGAD/image-20231108220041190.png" alt="image-20231108220041190">
<figcaption aria-hidden="true">image-20231108220041190</figcaption>
</figure>
<figure>
<img data-src="./DAGAD/image-20231108220205538.png" alt="image-20231108220205538">
<figcaption aria-hidden="true">image-20231108220205538</figcaption>
</figure>
<h2 id="数据增强">数据增强</h2>
<ol type="1">
<li><strong>表征增强</strong></li>
</ol>
<p>如果直接使用GNN后得到的表征，来进行异常检测，那么最终得到的是一个次优的模型。因为类别严重不平衡这个问题没有得到处理。</p>
<p>本文中使用的增强方法和cs224w中讲到的对图结构增强或者是结点特征增强不同，本文的表征增强方法是：通过GNN生成的表征，来生成新的表征，来增加最终的预测模型捕捉异常样本的能力。</p>
<p>PS，回顾cs224w中的图增强</p>
<ul>
<li>结点特征增强：给予结点相同的初始向量、给定结点唯一ID、使用图元、PageRank、聚类系数……</li>
<li>图结构增强：增加一个虚拟结点让其和所有其余结点相连、使用<span class="math inline">\(\mathcal A+\mathcal
A^2\)</span>来代替邻接矩阵作为计算图……</li>
</ul>
<figure>
<img data-src="./DAGAD/image-20231108230031175.png" alt="image-20231108230031175">
<figcaption aria-hidden="true">image-20231108230031175</figcaption>
</figure>
<ol start="2" type="1">
<li><strong>互补学习</strong></li>
</ol>
<p>在最终的预测部分时，有两个分类器，其中分类器A对普通的concat的数据进行训练；而分类器B则既对普通concat的数据训练，也对打乱后并且concat的数据进行训练。</p>
<p>其intuition有点类似于ResNET：</p>
<figure>
<img data-src="./DAGAD/image-20231108231330236.png" alt="image-20231108231330236">
<figcaption aria-hidden="true">image-20231108231330236</figcaption>
</figure>
<figure>
<img data-src="./DAGAD/image-20231108231421016.png" alt="image-20231108231421016">
<figcaption aria-hidden="true">image-20231108231421016</figcaption>
</figure>
<ol start="3" type="1">
<li><strong>总结构以及算法</strong></li>
</ol>
<figure>
<img data-src="./DAGAD/image-20231108231516480.png" alt="image-20231108231516480">
<figcaption aria-hidden="true">image-20231108231516480</figcaption>
</figure>
<figure>
<img data-src="./DAGAD/image-20231108231608172.png" alt="image-20231108231608172">
<figcaption aria-hidden="true">image-20231108231608172</figcaption>
</figure>
<h2 id="类别不平衡问题">类别不平衡问题</h2>
<p>其实就是在loss前面加一个因子，可以理解为惩罚，多类惩罚大，少类惩罚小。例如：</p>
<figure>
<img data-src="./DAGAD/image-20231108232102552.png" alt="image-20231108232102552">
<figcaption aria-hidden="true">image-20231108232102552</figcaption>
</figure>
<h1 id="实验">实验</h1>
<p>配置好环境后，直接运行代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore main.py</span><br></pre></td></tr></table></figure>
<p>后面的参数表示的是忽略警告信息。</p>
<p>运行结果如下：</p>
<figure>
<img data-src="./DAGAD/image-20231130194645150.png" alt="image-20231130194645150">
<figcaption aria-hidden="true">image-20231130194645150</figcaption>
</figure>
<p>论文中的实验结果如下：</p>
<figure>
<img data-src="./DAGAD/image-20231130194713432.png" alt="image-20231130194713432">
<figcaption aria-hidden="true">image-20231130194713432</figcaption>
</figure>
<p>可以看到实验结果基本吻合。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/16/cs224w-ch6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/16/cs224w-ch6/" class="post-title-link" itemprop="url">cs224w_ch6</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-16 19:36:50" itemprop="dateCreated datePublished" datetime="2023-10-16T19:36:50+08:00">2023-10-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-17 10:47:11" itemprop="dateModified" datetime="2023-10-17T10:47:11+08:00">2023-10-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>in node embedding, we use <strong>encoder</strong> to map original
network node to embedding space, the encoder is: <span class="math display">\[
z_v=Z.v
\]</span> the matrix is what we need to learn.</p>
<p>now, we use deep learning-based method as our encoder, which is
composed of multiple layers of non-linear transformations.</p>
<figure>
<img data-src="./cs224w-ch6/image-20231016195600647.png" alt="image-20231016195600647">
<figcaption aria-hidden="true">image-20231016195600647</figcaption>
</figure>
<p>What makes graph representation learning so difficult?</p>
<figure>
<img data-src="./cs224w-ch6/image-20231016195941481.png" alt="image-20231016195941481">
<figcaption aria-hidden="true">image-20231016195941481</figcaption>
</figure>
<ul>
<li>no fixed graph</li>
<li>Dynamic and no fixed fratures</li>
</ul>
<h1 id="basics-of-dl">Basics of DL</h1>
<p>we usually view the task as an Optimization problem, which means we
need to min. the objective function(loss function).</p>
<p>for predict task, use L2 loss: <span class="math display">\[
L(y,f(x))=||y-f(x)||_2
\]</span> or L1 loss.</p>
<p>for classify problem, we use cross entropy(CE) <span class="math display">\[
CE(y,f(x))=-\sum_{i=1}^C(y_i\log f(x)_i)
\]</span></p>
<p><span class="math display">\[
f(x)=softmax(g(x))
\]</span></p>
<p>g is the model.</p>
<h1 id="deep-learning-for-graph">Deep Learning for graph</h1>
<p>what if we directly feed the graph adj. matrix and feature set?</p>
<figure>
<img data-src="./cs224w-ch6/image-20231016201516077.png" alt="image-20231016201516077">
<figcaption aria-hidden="true">image-20231016201516077</figcaption>
</figure>
<p>Problem:</p>
<ul>
<li>Parameter <span class="math inline">\(O(|V|)\)</span>, certainly
speaking is <span class="math inline">\(O(|V|+num_{frature})\)</span></li>
<li>the graph size is fixed</li>
<li>sensitive to node ordering</li>
</ul>
<p>what about convolutions?</p>
<figure>
<img data-src="./cs224w-ch6/image-20231016201921224.png" alt="image-20231016201921224">
<figcaption aria-hidden="true">image-20231016201921224</figcaption>
</figure>
<p>problem:</p>
<ul>
<li>no stride or slide</li>
<li>permutation invariance（改变排序不变性）</li>
</ul>
<figure>
<img data-src="./cs224w-ch6/image-20231016202616104.png" alt="image-20231016202616104">
<figcaption aria-hidden="true">image-20231016202616104</figcaption>
</figure>
<p>graph and node representation should be the same for plan1 and
plan2.</p>
<p>we need a permutation invarient function!</p>
<p>and maps, cons cannot solve this.</p>
<h1 id="graph-convolutional-networks">Graph Convolutional Networks</h1>
<p>main problems are:</p>
<ol type="1">
<li><p>too many parameter</p></li>
<li><p>order invariance</p></li>
</ol>
<p>first we solve proble 1!</p>
<p>Lets consider mlp <span class="math inline">\(\to\)</span> CNN</p>
<p>we use the kernel to share parameter and aggregate
information(spacial)</p>
<p>can we apply it to GNN?</p>
<p><strong>idea: for node v, use it as an kernel to aggregate
information from <span class="math inline">\(N(v)\)</span>, thus, node's
neiborhood defins the computation graph</strong></p>
<figure>
<img data-src="./cs224w-ch6/image-20231017102318921.png" alt="image-20231017102318921">
<figcaption aria-hidden="true">image-20231017102318921</figcaption>
</figure>
<figure>
<img data-src="./cs224w-ch6/image-20231017102403312.png" alt="image-20231017102403312">
<figcaption aria-hidden="true">image-20231017102403312</figcaption>
</figure>
<p>now we solve the prob.1, how to keep order invariance?</p>
<figure>
<img data-src="./cs224w-ch6/image-20231017104641358.png" alt="image-20231017104641358">
<figcaption aria-hidden="true">image-20231017104641358</figcaption>
</figure>
<p>the approach is: <strong>Average information from neighbors and apply
a neural network</strong></p>
<p>now we can get the formulation of GNN(GCN):</p>
<figure>
<img data-src="./cs224w-ch6/image-20231017103110872.png" alt="image-20231017103110872">
<figcaption aria-hidden="true">image-20231017103110872</figcaption>
</figure>
<p>and the matrix formulation:</p>
<figure>
<img data-src="./cs224w-ch6/image-20231017103158325.png" alt="image-20231017103158325">
<figcaption aria-hidden="true">image-20231017103158325</figcaption>
</figure>
<figure>
<img data-src="./cs224w-ch6/image-20231017103350574.png" alt="image-20231017103350574">
<figcaption aria-hidden="true">image-20231017103350574</figcaption>
</figure>
<h1 id="train-gnn">Train GNN</h1>
<h2 id="supervised-learning">Supervised learning</h2>
<p><span class="math display">\[
\min _{\theta}\mathcal{L}(y,f(z_v))
\]</span></p>
<p>e.g., drug classification(toxic or not)</p>
<figure>
<img data-src="./cs224w-ch6/image-20231017104129035.png" alt="image-20231017104129035">
<figcaption aria-hidden="true">image-20231017104129035</figcaption>
</figure>
<p>the <span class="math inline">\(f(x_v)\)</span> is <span class="math inline">\(\sigma (z_v^T\theta)\)</span></p>
<h2 id="unsupervised-learning">Unsupervised learning</h2>
<p><span class="math display">\[
\mathcal{L}=\sum_{z_u,z_v}CE(y_{u,v},DEC(z_u,z_v))
\]</span></p>
<p>if node u and v are similar, then <span class="math inline">\(y_{u,v}=1\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/16/cs224w-ch4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/16/cs224w-ch4/" class="post-title-link" itemprop="url">cs224w_ch4</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-10-16 09:00:19 / Modified: 16:28:00" itemprop="dateCreated datePublished" datetime="2023-10-16T09:00:19+08:00">2023-10-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pagerank">PageRank</h1>
<p>how to represent page as graph:</p>
<ul>
<li>Node: web pages</li>
<li>Edge: hyperlinks</li>
</ul>
<p>Not only page network, here are citation natwork and reference
network:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016105115978.png" alt="image-20231016105115978">
<figcaption aria-hidden="true">image-20231016105115978</figcaption>
</figure>
<p>The problem is <strong>how could we measure the important of a web
page so that we can rank them.</strong></p>
<p>the idea is: <strong>links and votes</strong></p>
<h2 id="links-and-votes">links and votes</h2>
<p>the intuition is that <strong>Page is more important if it has more
links</strong></p>
<p>consider 2 web page:</p>
<ul>
<li>www.stanford.edu has 23,400 in-links</li>
<li><a href>thispersondoesnotexist.com</a> has 1 in-link</li>
</ul>
<p>why we don't consider out-link?</p>
<p>Because in your website, you can set a lot of out-links, and it is
easy to implement. So the inportance only take in-link into
consideration.</p>
<p>so, what is vote?</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016110419927.png" alt="image-20231016110419927">
<figcaption aria-hidden="true">image-20231016110419927</figcaption>
</figure>
<p>we use in-links to caculate the importance of node j, j have 2
in-links, so it's importance is above.</p>
<p>And consider other nodes, such as node i, has 3 out-links, so its
importance to others is divided to <span class="math inline">\(\frac{r_i}{3}\)</span></p>
<p>for a 3 node graph:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016110800556.png" alt="image-20231016110800556">
<figcaption aria-hidden="true">image-20231016110800556</figcaption>
</figure>
<p>we can get the equation for each node: <img data-src="./cs224w-ch4/image-20231016110819595.png" alt="image-20231016110819595"></p>
<h2 id="matrix-formulation">Matrix Formulation</h2>
<p>Let us start at some notion.</p>
<ol type="1">
<li><p>Stochastic adjacency matrix <span class="math inline">\(M\)</span></p>
<p>Here are the rules:</p>
<ul>
<li><span class="math inline">\(d_i\)</span> is the out degree of node
<span class="math inline">\(i\)</span></li>
<li>if <span class="math inline">\(i\to j\)</span>, then <span class="math inline">\(M_{ji}=\frac{1}{d_i}\)</span>, which means the
importance of <span class="math inline">\(i\)</span> is divided and
given to <span class="math inline">\(j\)</span></li>
</ul></li>
<li><p>Rank vector <span class="math inline">\(r\)</span></p>
<p><span class="math inline">\(r_i\)</span> is the importance of page
<span class="math inline">\(i\)</span>, and <span class="math inline">\(\sum_ir_i=1\)</span>.</p></li>
</ol>
<p>and the flow equation can be written as: <span class="math display">\[
r=M.r
\]</span> <img data-src="./cs224w-ch4/image-20231016111626006.png" alt="image-20231016111626006"></p>
<h2 id="connection-to-random-walk">Connection to Random walk</h2>
<p>we have considered the importance of node. now lets start at one page
i, and which page should we select next?</p>
<ol type="1">
<li>at timepoint t, the surfer is at page i</li>
<li>at timepoint t+1, surfer choose an put-link from i randomly.</li>
<li>the surfer at page j</li>
<li>repeat</li>
</ol>
<figure>
<img data-src="./cs224w-ch4/image-20231016131736772.png" alt="image-20231016131736772">
<figcaption aria-hidden="true">image-20231016131736772</figcaption>
</figure>
<p>so, here are some notions:</p>
<ul>
<li><span class="math inline">\(p(t)\)</span>: the coordinate of the
probability of node i at the time t. it includes the next pages
probability.</li>
<li><span class="math inline">\(p(t)\)</span> is a probability
distribution over pages</li>
</ul>
<p>this process can be performed as this fomula: <span class="math display">\[
p(t+1)=M.p(t)=p(t)
\]</span></p>
<p><span class="math display">\[
r=M.r
\]</span></p>
<p><span class="math inline">\(r\)</span> is the stationary distribution
for random walk</p>
<p>in ch2, the centrality: <span class="math display">\[
\lambda c=Ac
\]</span> c is eigenvector, <span class="math inline">\(\lambda\)</span>
is eigenvalue</p>
<p>so eigenvector is r, eigenvector is 1 <span class="math display">\[
1.r=M.r
\]</span></p>
<h1 id="solve-pagerank">Solve PageRank</h1>
<h2 id="notion-and-procedure">notion and procedure</h2>
<p>we have the equation with eigenvalue 1 and eigenvector <span class="math inline">\(r\)</span>, and its equal form is:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016144335069.png" alt="image-20231016144335069">
<figcaption aria-hidden="true">image-20231016144335069</figcaption>
</figure>
<p>now we use iterative procedure to solve it:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016144426163.png" alt="image-20231016144426163">
<figcaption aria-hidden="true">image-20231016144426163</figcaption>
</figure>
<p>the whole procedure is as follow:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016144523411.png" alt="image-20231016144523411">
<figcaption aria-hidden="true">image-20231016144523411</figcaption>
</figure>
<p>Here are some example:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016144806032.png" alt="image-20231016144806032">
<figcaption aria-hidden="true">image-20231016144806032</figcaption>
</figure>
<h2 id="problem">problem</h2>
<p>this procedure has 2 problem:</p>
<ol type="1">
<li><p>dead ends</p>
<p>which means the page have no out-links</p>
<p>it will lead to important 'fall cliff'</p></li>
<li><p>Spider traps</p>
<p>absorbe all importance</p></li>
</ol>
<h3 id="spider-trap">spider trap</h3>
<figure>
<img data-src="./cs224w-ch4/image-20231016145129148.png" alt="image-20231016145129148">
<figcaption aria-hidden="true">image-20231016145129148</figcaption>
</figure>
<p>Here is solution.</p>
<p>at each step:</p>
<ul>
<li>with the prob. <span class="math inline">\(\beta\)</span>, use
random link</li>
<li>with the prob. <span class="math inline">\(1-\beta\)</span>, jump to
a teleport</li>
<li>Usually us <span class="math inline">\(\beta=0.8\to0.9\)</span></li>
</ul>
<figure>
<img data-src="./cs224w-ch4/image-20231016145825068.png" alt="image-20231016145825068">
<figcaption aria-hidden="true">image-20231016145825068</figcaption>
</figure>
<p>so, use teleport, the surfer will stay at node m, after few step,
surfer will jump to the teleport, which could be any node in the
graph</p>
<h3 id="dead-end">dead end</h3>
<figure>
<img data-src="./cs224w-ch4/image-20231016145215400.png" alt="image-20231016145215400">
<figcaption aria-hidden="true">image-20231016145215400</figcaption>
</figure>
<p>the solution is same with spider trap, just use teleport</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016150936154.png" alt="image-20231016150936154">
<figcaption aria-hidden="true">image-20231016150936154</figcaption>
</figure>
<p>see node m, it has no out-links, we use teleport, and each prob. is
<span class="math inline">\(\frac{1}{N}\)</span> N is all graph node,
include m itself</p>
<h3 id="googles-solution">Google's solution</h3>
<figure>
<img data-src="./cs224w-ch4/image-20231016151116458.png" alt="image-20231016151116458">
<figcaption aria-hidden="true">image-20231016151116458</figcaption>
</figure>
<h3 id="e.g.">e.g.</h3>
<figure>
<img data-src="./cs224w-ch4/image-20231016151135339.png" alt="image-20231016151135339">
<figcaption aria-hidden="true">image-20231016151135339</figcaption>
</figure>
<p>because of teleport, the gree nodes, which have no in degree, also
have their importance. and we can adjust <span class="math inline">\(\beta\)</span> to change its value, according to
the reality. if it is important than we set, then we set <span class="math inline">\(\beta\)</span> lower.</p>
<h1 id="personalized-and-restart-pagerank">personalized and restart
pagerank</h1>
<p>let's see the difference:</p>
<ol type="1">
<li><p>pagerank</p>
<p>jump to any node</p></li>
<li><p>Personalized pagerank</p>
<p>Jump to a set of teleport nodes <span class="math inline">\(S\)</span></p></li>
<li><p>random walks with restart</p>
<p>teleport to the starting node : <span class="math inline">\(S=\{Q\}\)</span></p></li>
</ol>
<p>the form in simulation:</p>
<figure>
<img data-src="./cs224w-ch4/image-20231016155859558.png" alt="image-20231016155859558">
<figcaption aria-hidden="true">image-20231016155859558</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/13/cs224w-ch2-lab/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/13/cs224w-ch2-lab/" class="post-title-link" itemprop="url">cs224w_ch2_lab</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-10-13 21:04:56 / Modified: 21:10:39" itemprop="dateCreated datePublished" datetime="2023-10-13T21:04:56+08:00">2023-10-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>用NetworkX来创建、计算图</p>
<p>默认创建的是undirected graph，当然也可以使用direct graph的class：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="comment"># Create an undirected graph G</span></span><br><span class="line">G = nx.Graph()</span><br><span class="line"><span class="built_in">print</span>(G.is_directed()) <span class="comment">#false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a directed graph H</span></span><br><span class="line">H = nx.DiGraph()</span><br><span class="line"><span class="built_in">print</span>(H.is_directed())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add graph level attribute</span></span><br><span class="line">G.graph[<span class="string">&quot;Name&quot;</span>] = <span class="string">&quot;Bar&quot;</span></span><br><span class="line"><span class="built_in">print</span>(G.graph)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/13/high-performance-computer-network-lecture1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/13/high-performance-computer-network-lecture1/" class="post-title-link" itemprop="url">high_performance_computer_network_lecture1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-10-13 14:17:33 / Modified: 19:21:02" itemprop="dateCreated datePublished" datetime="2023-10-13T14:17:33+08:00">2023-10-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">高性能计算机网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>课程要求：</p>
<ul>
<li><p>27学时线上+27课时线下</p></li>
<li><p>考试占比50%，线上考试</p></li>
<li><p>线上刷视频、做练习、讨论区（权重最高，占平时成绩50%的60%）提问+回答问题</p></li>
</ul>
<h3 id="因特网结构">因特网结构</h3>
<p>IP-based framework</p>
<p>从IP网拓展到了物联网，其原因是智能终端的增多。</p>
<p>校园网的连接： <span class="math display">\[
武理\stackrel{光纤}{\longrightarrow}华科\stackrel{光纤}{\longrightarrow}清华\stackrel{光纤}{\longrightarrow}外网
\]</span>
所以理论上访问武汉市的外网的速度慢于访问清华的内网，只不过现在由于速度的提升，这点时延差在人类的感知上可以忽略。</p>
<p>4G、5G指的不是以太网、蓝牙、星闪，指的是基站，无线蜂窝通信。</p>
<p>huawei mate60的天线是中国移动做的。</p>
<figure>
<img data-src="./high-performance-computer-network-lecture1/image-20231013160341062.png" alt="image-20231013160341062">
<figcaption aria-hidden="true">image-20231013160341062</figcaption>
</figure>
<p>图中有四个自治系统（AS），其中最上层的是根服务器，称为transit，第二层的称为Stub。</p>
<p>一般而言，一个AS要想访问其他AS，必须通过连接并途径transit。但是更好的做法是直接在两个AS之间建立一条链路。</p>
<p>像移动、电信等ISP，都属于AS，个人用户可以选择光纤、拨号等形式进行介入，而cellphone则是通过无线蜂窝接入的。</p>
<h3 id="调频与扩频">调频与扩频</h3>
<p>网络发展阶段：</p>
<ol type="1">
<li>IP网：第一阶段</li>
</ol>
<ul>
<li>FTP</li>
<li>HTTP</li>
<li>SMTP</li>
<li>P2P</li>
</ul>
<ol start="2" type="1">
<li><p>基于云：物联网出现后，存储容量、处理器速度大幅提升。</p></li>
<li><p>基于AI：对万物建模，万物互联（物联网）时延低，AI的三个特点：</p></li>
</ol>
<ul>
<li>大模型：参数基本是GB起步，甚至TB，因此将模型参数存在云上更为现实，这就要求我们的基础网络具备大带宽、低时延的特点</li>
<li>大算力：数据中心级别的算力，进行并行计算，同样需要低时延的特性</li>
<li>大数据：需要大带宽的特性</li>
</ul>
<p>这几个阶段是逐渐拓展的，云包含IP网，基于AI的包含基于云的。</p>
<h4 id="数字基带传输">数字基带传输</h4>
<p>电磁波的分类：</p>
<ul>
<li>长波：波长100</li>
<li>中波：波长几米到几十</li>
<li>短波：分米级别</li>
<li>微波：毫米级</li>
<li>Tera Hz</li>
<li>红外线：缺点，绕不过障碍物</li>
<li>可见光</li>
</ul>
<p>波长跟频率：<span class="math inline">\(\lambda
=\frac{c}{f}\)</span></p>
<p>香农定理： <span class="math display">\[
信道极限传输速率=带宽B\log (1+信噪比\frac{S}{N})
\]</span> 波长越短，越难以饶过障碍物</p>
<p>很乱。。。。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/13/cs224w-ch3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/13/cs224w-ch3/" class="post-title-link" itemprop="url">cs224w_ch3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-13 10:44:37" itemprop="dateCreated datePublished" datetime="2023-10-13T10:44:37+08:00">2023-10-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-17 17:18:14" itemprop="dateModified" datetime="2023-10-17T17:18:14+08:00">2023-10-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>ch2讲的就是我们如何设计特征，来尽量准确的表示这个网络，然后再交给机器学习算法如SVM，最后得到我们的预测：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231013104858822.png" alt="image-20231013104858822">
<figcaption aria-hidden="true">image-20231013104858822</figcaption>
</figure>
<p>事实上我们可能会花大部分的时间去做特征工程。</p>
<p>这一节考虑的是，能否不用特征工程。</p>
<p>图表征学习：自动获取网络的特征。</p>
<h2 id="node-embedding">node embedding</h2>
<p>结点嵌入两个很重要的特征；</p>
<ul>
<li>无监督：训练不需要利用结点的label，也不需要feature</li>
<li>task
independent：嵌入就是一个提取网络特征的过程，可以将提取出的特征用于任何适合的机器学习算法，也就是与下游任务无关。</li>
</ul>
<figure>
<img data-src="./cs224w-ch3/image-20231013105154723.png" alt="image-20231013105154723">
<figcaption aria-hidden="true">image-20231013105154723</figcaption>
</figure>
<p>图嵌入是干这样的一件事：将node
u自然而然的映射（map）到一个d维的向量中去。这个过程被称为node
embedding</p>
<p>嵌入的原理是这样的：如果两个node的d维向量有相似性，那么这两个node本身也很可能有相似性。</p>
<p>完成了结点嵌入之后，我们就可以用这个d维的向量来做downstream
task了</p>
<figure>
<img data-src="./cs224w-ch3/image-20231013105532825.png" alt="image-20231013105532825">
<figcaption aria-hidden="true">image-20231013105532825</figcaption>
</figure>
<h3 id="deepwalking">DeepWalking</h3>
<figure>
<img data-src="./cs224w-ch3/image-20231013110146538.png" alt="image-20231013110146538">
<figcaption aria-hidden="true">image-20231013110146538</figcaption>
</figure>
<p>这是一个小型的网络，将图嵌入到了一个2d空间，可以看到相同颜色的结点在图上和被嵌入的空间中都是离得比较近的。</p>
<h3 id="embedding">Embedding</h3>
<p>更抽象的描述是这样：</p>
<p><img data-src="./cs224w-ch3/image-20231013123405368.png" alt="image-20231013123405368" style="zoom:25%;"></p>
<p>至于用dot
product（点积）的原因是，其代表的是这两个向量之间的余弦，例如如果两个向量是垂直的话，dot
product就为0了。</p>
<p>嵌入的步骤：</p>
<ol type="1">
<li><p>使用Encoder将node映射到嵌入空间</p>
<p><span class="math inline">\(ENC(v)=z_v\)</span></p>
<p>这个嵌入空间通常是64d到1000d的</p></li>
<li><p>定义一个结点相似函数，用来测量图中被嵌入到node
pairs之间的相似度</p></li>
<li><p>使用Decoder将嵌入结点映射为相似度</p></li>
<li><p>优化Encoder的参数，使得结点相似度和嵌入结点相似度近似相等。</p></li>
</ol>
<p><span class="math display">\[
similarity(u,v)\approx z_v^Tz_u
\]</span></p>
<p>这里我们选择的解码器是非常简单的，仅仅是两个向量的dot product</p>
<h3 id="shallow-encoder">shallow encoder</h3>
<p>最简单的编码方式： <span class="math display">\[
ENC(v)=z_v=Z.v
\]</span> - Z：要学习的矩阵，行代表的是低维向量，列代表的是结点。 -
v：v是一个列向量，其中大部分元素是0，除了要得到的结点v的那一个地方为1。</p>
<p>如<span class="math inline">\(v=[0,0,1,0,0,0]\)</span></p>
<p>对于这种编码器，我们需要学习的就是Z：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231013195103736.png" alt="image-20231013195103736">
<figcaption aria-hidden="true">image-20231013195103736</figcaption>
</figure>
<p>这个方法的缺点：当图比较大时，假设嵌入维度为1000，结点数为100w，那么就有10亿参数。而造成这个matrix如此大的原因是：我们计算了每个node的嵌入向量，当需要某个node的嵌入向量时，可以直接从这个超级大矩阵里面去做一次查找(look-up)。</p>
<p>那么最后，我们来考虑怎么来定义node similarity？可以采用random
walks</p>
<h2 id="random-walks">Random walks</h2>
<h3 id="deepwalk">DeepWalk</h3>
<h4 id="notion">notion</h4>
<p>回顾一下 两个非线性函数：</p>
<ol type="1">
<li>softmax</li>
</ol>
<p>这里给到softmax的解释：a soft version of a maximum
function，最大值函数的软版本。</p>
<ol start="2" type="1">
<li>sigmoid</li>
</ol>
<p>sigmoid可以任何实数压缩到0～1之间。</p>
<p>另外还有两个概念：</p>
<ul>
<li><span class="math inline">\(z_u\)</span>：结点u的嵌入</li>
<li><span class="math inline">\(P(v|z_u)\)</span>：从u开始，使用随机游走访问v的概率</li>
</ul>
<p>那么什么是随机游走呢：从一个结点u开始，随机的选取它的一个邻居v，作为next
step，依此类推。</p>
<p>这里给了下面这个定义，不是很理解：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015203440876.png" alt="image-20231015203440876">
<figcaption aria-hidden="true">image-20231015203440876</figcaption>
</figure>
<h4 id="detail">detail</h4>
<p>基于随机游走的嵌入可以用两步表示：</p>
<ol type="1">
<li><p>使用一个策略R，来估计访问结点v的概率</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015203738556.png" alt="image-20231015203738556">
<figcaption aria-hidden="true">image-20231015203738556</figcaption>
</figure></li>
<li><p>优化嵌入，通过编码这一步随机游走</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015203753465.png" alt="image-20231015203753465">
<figcaption aria-hidden="true">image-20231015203753465</figcaption>
</figure></li>
</ol>
<p>然后为什么选随机游走（优点）：</p>
<ul>
<li>如果从u开始，走了v，那么可以认为u和v是类似的</li>
<li>不需要考虑整个图全局信息，只需要考虑path中同时出现的random walk</li>
</ul>
<p>随机游走步骤：</p>
<ol type="1">
<li><p>从每一个u开始，走固定的长度，通过使用随机策略R</p></li>
<li><p>对于每一个u，收集其<span class="math inline">\(N_R(u)\)</span></p></li>
<li><p>通过对数似然函数进行优化：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015210342311.png" alt="image-20231015210342311">
<figcaption aria-hidden="true">image-20231015210342311</figcaption>
</figure>
<p>同样也可以讲其表示称下面这种形式：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015210423990.png" alt="image-20231015210423990">
<figcaption aria-hidden="true">image-20231015210423990</figcaption>
</figure>
<p>其中可以将对数里面的参数写成下面的softmax形式，那么这个结果其实就是u之后v的概率</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015210646749.png" alt="image-20231015210646749">
<figcaption aria-hidden="true">image-20231015210646749</figcaption>
</figure>
<p>所以最终的损失函数如下：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015210720744.png" alt="image-20231015210720744">
<figcaption aria-hidden="true">image-20231015210720744</figcaption>
</figure></li>
</ol>
<p>但是有个问题，这里有两层嵌套，意味着时间复杂度是<span class="math inline">\(O(|V|^2)\)</span>，复杂度太高了！</p>
<h4 id="negative-sample">negative sample</h4>
<p>选择使用负采样来近似softmax的分母：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015211112148.png" alt="image-20231015211112148">
<figcaption aria-hidden="true">image-20231015211112148</figcaption>
</figure>
<p>k是一般取5～20</p>
<p>最开始是DeepWalk提出了random
walks（走固定长度，使用随机策略）。这样的similarity表现还不错，从最终结果来看，嵌入空间和图空间中，nearby的点是对应的。</p>
<figure>
<img data-src="./cs224w-ch3/image-20231013110146538.png" alt="image-20231013110146538">
<figcaption aria-hidden="true">image-20231013110146538</figcaption>
</figure>
<p>但是这样定义的similarity太受限制了，于是很多人尝试优化。</p>
<h3 id="node2vec">node2vec</h3>
<p>idea：使用灵活的、有偏好的随机游走，例如当进行下一步时，可以选择更广或者更深，也就是DFS和BFS的思想</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015213201541.png" alt="image-20231015213201541">
<figcaption aria-hidden="true">image-20231015213201541</figcaption>
</figure>
<p>这里面有两个参数：</p>
<ul>
<li>p：可以看到之前的结点</li>
<li>q：选择使用DFS（outwards）还是BFS（inwards）</li>
</ul>
<p>下面这例子完美表示了两个参数的用途：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015213554066.png" alt="image-20231015213554066">
<figcaption aria-hidden="true">image-20231015213554066</figcaption>
</figure>
<p>w从s1来的，那么下一步，若是选择inwards，可以去s2（和s1距离相同），若是选outwards，可以走s3，还可以回到s1。</p>
<p>我们将其量化：</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015213929100.png" alt="image-20231015213929100">
<figcaption aria-hidden="true">image-20231015213929100</figcaption>
</figure>
<p>我们可以调整p、q来得到不同的策略R。</p>
<h3 id="other-random-walk">other random walk</h3>
<p>这是一些其他的关于随机游走的优化。</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015200000371.png" alt="image-20231015200000371">
<figcaption aria-hidden="true">image-20231015200000371</figcaption>
</figure>
<h2 id="embedding-entire-graph">Embedding entire graph</h2>
<p>Goal: to embed the entire graph or sub-graph!</p>
<ul>
<li><p>entire graph</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015221015877.png" alt="image-20231015221015877">
<figcaption aria-hidden="true">image-20231015221015877</figcaption>
</figure></li>
<li><p>Sub-graph</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015221050844.png" alt="image-20231015221050844">
<figcaption aria-hidden="true">image-20231015221050844</figcaption>
</figure></li>
</ul>
<p>the application(task):</p>
<ul>
<li>Classifying toxic vs. non-toxic molecules</li>
<li>Identifying anomalous graphs</li>
</ul>
<h3 id="approach-1">Approach 1</h3>
<p>it is simple and effective, which is:</p>
<ol type="1">
<li><p>use node2vec or deepwalks to caculate the embed node u of <span class="math inline">\(z_u\)</span></p></li>
<li><p>then sum or average <span class="math display">\[
z_G=\sum_{v\epsilon G}z_v
\]</span></p></li>
</ol>
<h3 id="approach-2">Approach 2</h3>
<p>use a virtual node to represent the graph, and by using node2vec or
deepwaks to embedding the virtual node to embedding space.</p>
<figure>
<img data-src="./cs224w-ch3/image-20231015221722630.png" alt="image-20231015221722630">
<figcaption aria-hidden="true">image-20231015221722630</figcaption>
</figure>
<h3 id="approach-3">Approach 3</h3>
<h4 id="idea-1">Idea 1</h4>
<p>use anonymous walks to instead random walks.</p>
<figure>
<img data-src="./cs224w-ch3/image-20231016082050748.png" alt="image-20231016082050748">
<figcaption aria-hidden="true">image-20231016082050748</figcaption>
</figure>
<p>feature is:</p>
<ul>
<li>Anonymous</li>
<li>Capture the struct rather than node pairs</li>
</ul>
<p>with the length of step increasing, the number of anonymous walks
(the anonymous walks vector <span class="math inline">\(Z_G(i)\)</span>,
for l=3, the dimensions of <span class="math inline">\(Z_G(i)\)</span>
is 5) <strong>exponentially</strong> increase.</p>
<figure>
<img data-src="./cs224w-ch3/image-20231016082759928.png" alt="image-20231016082759928">
<figcaption aria-hidden="true">image-20231016082759928</figcaption>
</figure>
<figure>
<img data-src="./cs224w-ch3/image-20231016082950394.png" alt="image-20231016082950394">
<figcaption aria-hidden="true">image-20231016082950394</figcaption>
</figure>
<p>We have the vector now, so how many walks should we sample to
represent the whole distribution?</p>
<p>use this formula:</p>
<figure>
<img data-src="./cs224w-ch3/image-20231016083437104.png" alt="image-20231016083437104">
<figcaption aria-hidden="true">image-20231016083437104</figcaption>
</figure>
<h4 id="idea-2">Idea 2</h4>
<p>Above, we use a vector <span class="math inline">\(Z_G(i)\)</span> to
represent the distribution, it is a set of probability about every
walk.</p>
<p>the other idea is use walks ranther than probability: <span class="math display">\[
Z=\{z_i:i=1...\eta\} \\
\]</span> <span class="math inline">\(\eta\)</span> is the number of
sampled anonymous walks.</p>
<p>so here is the idea and how we learning the walks embeddings?</p>
<p>First, sample some walks:</p>
<figure>
<img data-src="./cs224w-ch3/image-20231016084518021.png" alt="image-20231016084518021">
<figcaption aria-hidden="true">image-20231016084518021</figcaption>
</figure>
<p>Than, learn to predict walks which is co-occur in <span class="math inline">\(\Delta\)</span> size window</p>
<p>e.g., predict <span class="math inline">\(w_3\)</span> given <span class="math inline">\(w_1,w_2,\Delta=2\)</span></p>
<figure>
<img data-src="./cs224w-ch3/image-20231016084700692.png" alt="image-20231016084700692">
<figcaption aria-hidden="true">image-20231016084700692</figcaption>
</figure>
<p>so, different from DeepWalk, node2vec, the neighbor set is: <span class="math display">\[
N_R(u)=\{w_1^u,w_2^u...w_T^u\}
\]</span> <img data-src="./cs224w-ch3/image-20231016084952691.png" alt="image-20231016084952691"></p>
<p><span class="math inline">\(Z_G\)</span> is a optimized vector
parameter</p>
<figure>
<img data-src="./cs224w-ch3/image-20231016085824928.png" alt="image-20231016085824928">
<figcaption aria-hidden="true">image-20231016085824928</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/6/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">chengyiqiu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>

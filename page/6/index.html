<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width":280,"display":"post","offset":10,"onmobile":true},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":true},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/6/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="chengyiqiu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/6/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/6/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="chengyiqiu"
      src="/images/pig.gif">
  <p class="site-author-name" itemprop="name">chengyiqiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/chengyiqiu1121" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chengyiqiu1121" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/13/20h-write-sci/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/13/20h-write-sci/" class="post-title-link" itemprop="url">20h_write_sci</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-10-13 08:53:02 / Modified: 08:58:06" itemprop="dateCreated datePublished" datetime="2023-10-13T08:53:02+08:00">2023-10-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/writing-paper/" itemprop="url" rel="index"><span itemprop="name">writing  paper</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure>
<img data-src="./20h-write-sci/image-20231013085627802.png" alt="image-20231013085627802">
<figcaption aria-hidden="true">image-20231013085627802</figcaption>
</figure>
<figure>
<img data-src="./20h-write-sci/image-20231013085640782.png" alt="image-20231013085640782">
<figcaption aria-hidden="true">image-20231013085640782</figcaption>
</figure>
<h2 id="abstract">0 <strong>Abstract</strong></h2>
<p>本部分最后写。不要太长，突出重点，一般在150词左右。</p>
<p>第1句：介绍<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=工程&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">工程</a>背景。</p>
<p>第2-3句：由<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=工程问题&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">工程问题</a>引出本文研究内容，强调研究内容对解决该工程问题的重要意义。如：Thus,
the XX is the key problem in the engineering design of XX.</p>
<p>第4-5句：介绍本文核心工作。如：In this paper, XX experiment was
performed to study XX problem, and XX model was proposed to predict the
responses the XX. Using this model, a series of numerical simulations
were conducted aiming for XX.</p>
<p>第6-7句：介绍本文工作的主要结论。如：The results indicate that XX. It
is noted that the XX. With the increase of load amplitude, XX increases
downward significantl. The proposed XX model is appropriate for the
assessment of XX evolution process.</p>
<p>Keywords: 一般五个。</p>
<h2 id="introduction"><strong>1 Introduction</strong></h2>
<p><strong>工程大背景→工程具体问题→本研究中的更具体问题。</strong></p>
<p>第一段：工程大背景，该工程问题的重要性及解决问题的紧迫性。讲问题要从大到小，聚焦在该工程问题的核心控制因素上（即是本文研究内容）。写法如下：</p>
<p>In recent years，XX develops rapidly. XXX.</p>
<p>第二段：关于本问题的研究现状，同时突出目前研究的不足（该不足是与本文研究<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=创新&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">创新</a>嗲相比的不足，以求突出本文研究内容的创新性）。千万不要记流水账，虽然写起来容易，但是会给审稿专家留下不好印象，认为对该问题缺乏深入认识。一定要以问题为导向进行<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=分类&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">分类</a>。</p>
<p>如：There have been many studies so far about the XX problem. XX [1],
XX et al. [2] and XX[15] proposed and developed XX method. The method
provides a good evaluation tool for XX, but it is too simplified to
consider the effects of XX, XX and XX.</p>
<p>至少应该有80%的引用文献是在近五年发表的。</p>
<p>若是多个问题，可将“第二段”拆写成多段，每段讨论一个问题。</p>
<p>第三段：介绍本文目标、工作和主要结论（比<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=abstract&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">abstract</a>要详细，可以存在一定程度重复）。</p>
<p>This paper aims to solve XX problem. In this paper, XX experiments
were performed firstly, and it is found that XX. Then, XX numerical
model was established, which can consider the effects of XX. Later, a
series of numerical studies based on XX are performed to investigate XX.
It is pointed out that the XX.</p>
<h2 id="xx-experiment-considerding-xx-effects"><strong>2 XX experiment
considerding XX effects</strong></h2>
<h3 id="experimental-introduction"><strong>2.1 Experimental
introduction</strong></h3>
<p>介绍试验的基本情况，包括试验材料、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=试验设备&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">试验设备</a>等信息。</p>
<h3 id="experiment-design-and-procedures"><strong>2.2 Experiment design
and procedures</strong></h3>
<p>介绍<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=试验设计&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">试验设计</a>和试验步骤。包括试验目的，<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=研究方法&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">研究方法</a></p>
<p>给出开展试验的组数、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=研究变量&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">研究变量</a>，并用表格展示。</p>
<h3 id="experiment-results"><strong>2.3 Experiment results</strong></h3>
<p>讨论试验结果，总结试验规律，解释试验现象背后机制、机理。</p>
<p>可与已有试验结果对比分析，讨论差异以及原因。</p>
<p>甚至可以凝练出指导<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=工程实践&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">工程实践</a>的公式，提升论文创新性。</p>
<h2 id="xx-numerical-model-considering-xx-effects"><strong>3 XX
numerical model considering XX effects</strong></h2>
<h3 id="definition-of-xx-numerical-model"><strong>3.1 Definition of XX
numerical model</strong></h3>
<p>介绍使用的软件、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=数值模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">数值模型</a>基本信息以及主要的建模过程等信息。</p>
<h3 id="parameters-of-xx-model-and-calibrations"><strong>3.2 Parameters
of XX model and calibrations</strong></h3>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=数值模拟&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">数值模拟</a>最为重要，也是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=审稿人&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">审稿人</a>最为关注的就是<strong>模型参数</strong>的标定过程，参数有哪些？是如何确定的？具不具有信服力？<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=参数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">参数</a>是模型的基础，务必重视，并讲清楚。</p>
<h3 id="model-verification-with-field-test-results"><strong>3.3 Model
verification with field test results</strong></h3>
<p>另一个非常重要的部分就是验证数值模型是正确的，只有证明的数值模型是正确的，后续的数值研究才有意义。一般，可通过试验、现场监测数据、理论计算值，甚至他人的数值模拟结果进行验证。</p>
<h2 id="simulation-and-discussion">4 <strong>Simulation and
discussion</strong></h2>
<p>介绍数值模拟研究目的、计算方案以及计算结果。计算结果一般都非常多，可筛选几个具有代表性的物理量进行深入分析，分析不同因素影响下这些<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=物理量&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">物理量</a>的变化规律及内在物理机制；分析XX破坏过程及原因；基于大量的数值计算结果，构建可用于XX<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=工程设计&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">工程设计</a>分析的<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=数据库&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">数据库</a>，为构建评估方法奠定基础。更重要的是，通过<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=数值计算&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">数值计算</a>研究，得出对工程实践具有指导意义的结论或评价方法。</p>
<p>In this section, a series of numerical <a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=simulations&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">simulations</a>
for XX are performed using the proposed XX method. XXX.The simulation
results about the evolutions of XX are presented and discussed
thoroughly.</p>
<p>Therefore, in the actual engineering, XX should be the controlling
factor in the design of XX, which must be careful enough for it.</p>
<p>数值计算中的一些非普通、难理解的现象可用他人研究成果进行支持，如 This
phenomenon is supported by the work of XX.</p>
<p>可以通过<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=discussion&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">discussion</a>提高论文水平。针对本论文中发现的新现象、新结论、新方法等创新之处进行探讨，吸引审稿人注意力。具体地，可以解释现象背后机制，与他人研究现象、结论对比<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=分析&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">分析</a>，对比现有<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=设计方法&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3224310098%7D">设计方法</a>的不足等。</p>
<h2 id="conclusions"><strong>5 Conclusions</strong></h2>
<p>采用总分模式，即先写一段“帽”，再列3-5个干条。</p>
<p>“帽”还是总结本文主要工作，可借鉴、甚至复制abstract和introduction中相关表述。如：</p>
<p>In this paper, a series of XX experiments were performed to
investigate XX. XX feature is studied, the effects of XX on the XX are
thoroughly discussed. Based on XX model, XX method is proposed to
evaluate the XX. Numerical studies are performed to investigate the
evolutions of XX. The main conclusions can be drawn as follows:</p>
<p>（1）凝练论文最核心创新点，避免没有意义的结论，不要出现“妈妈是女人”这种废话结论。别让审稿人觉得你在侮辱他！</p>
<p>（2）针对特定工况下的结论，尽量少提或不提，因为这些结论没有工程普适应，容易被审稿人攻击。</p>
<p>（3）XX</p>
<h2 id="acknowledgements"><strong>Acknowledgements</strong></h2>
<p>The authors are grateful to the support from National Natural Science
Foundation of China (Grant no. XXX), XX Provincial Natural Science
Foundation of China (Grant no. XXX).</p>
<h2 id="references"><strong>References</strong></h2>
<p>多引用国际顶刊，近五年论文。</p>
<p>转载</p>
<p>作者：博士大师兄-木水
链接：https://www.zhihu.com/question/620016786/answer/3224310098
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/10/cs224w-ch2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/10/cs224w-ch2/" class="post-title-link" itemprop="url">cs224w_ch2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-10 13:59:16" itemprop="dateCreated datePublished" datetime="2023-10-10T13:59:16+08:00">2023-10-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-12 22:00:35" itemprop="dateModified" datetime="2023-10-12T22:00:35+08:00">2023-10-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="node-level-feature">node-level feature</h2>
<p>这一节主要讲node-level features</p>
<p>我们关注的两种feature：</p>
<ul>
<li>structure feature：例如图的topology</li>
<li>feature of nodes attribution</li>
</ul>
<p>这里我们先假设node已经有一些feature了，比如蛋白质的化学结构等其他属性。</p>
<p>在此基础之上，我们还需要确定一些特征：这个node在这个网络中position，应该如何去描述？</p>
<p>当上面的这俩都被确定了，我们就拥有了整个网络的topology。</p>
<p>传统的机器学习做法是：确定好图的nodes、links、graph，然后表示称特征向量，然后再给到学习算法。</p>
<p>首先考虑一个semi- supervised场景，</p>
<figure>
<img data-src="./cs224w-ch2/image-20231010142809277-6919289.png" alt="image-20231010142809277">
<figcaption aria-hidden="true">image-20231010142809277</figcaption>
</figure>
<p>规则：</p>
<p>给灰色的上色（presict</p>
<ul>
<li>绿色的至少有两个相邻的边</li>
<li>红色至少有一个边</li>
</ul>
<p>可以这样去手工制作特征：</p>
<ul>
<li>将node degree作为结点的拓扑结构特征</li>
<li>node centralty？</li>
</ul>
<p>然后再考虑整个图的特征。</p>
<p>如果只是考虑用node
degree作为结点的特征，degree其实只考虑了它们的neighbor，并且没有考虑他们各自不同的重要性。因此如果直接将degree作为feature，然后扔给机器学习算法，那么如下图中的C和E，他们的degree都是3，模型就无法分辨它们了。</p>
<figure>
<img data-src="./cs224w-ch2/image-20231010144414392.png" alt="image-20231010144414392">
<figcaption aria-hidden="true">image-20231010144414392</figcaption>
</figure>
<h3 id="node-centrality">Node centrality</h3>
<p>结点中心性</p>
<p>Idea: the more important my friends are,the higher my importance
is.</p>
<p>可以用下式表示： <span class="math display">\[
c_v=\frac{1}{\lambda}\sum _{u\in N(v)}c_u
\]</span> 左边代表的是中心结点的重要性
，右边代表的是neighbor的重要性的和再乘以一个factor（归一化）。</p>
<p>也可以写成下面： <span class="math display">\[
\lambda c=Ac
\]</span> c是中心结点的一些特征组成的向量。</p>
<p>对于A则是这样描述的：adjacent matrix, <span class="math inline">\(A_{uv}=1\)</span> if <span class="math inline">\(u\in N(v)\)</span></p>
<p>然后由于我们考虑的undirected graph，所以<span class="math inline">\(\lambda
_{max}\)</span>一直是正的并且是唯一的。</p>
<p>这就是node centrality的定义。</p>
<h3 id="betweenness-centrality">betweenness centrality</h3>
<figure>
<img data-src="./cs224w-ch2/image-20231010153035055.png" alt="image-20231010153035055">
<figcaption aria-hidden="true">image-20231010153035055</figcaption>
</figure>
<p>对于边缘的结点，没有最短路径通过他，因此betweenness centrality为0</p>
<p>对于中间点如c，A到B的最短为ABC，A到D的最短为ACD……</p>
<h3 id="closeness-centrality">closeness centrality</h3>
<figure>
<img data-src="./cs224w-ch2/image-20231010153320262.png" alt="image-20231010153320262">
<figcaption aria-hidden="true">image-20231010153320262</figcaption>
</figure>
<p>以A为起点的，到其他点的点最短距离加起来，取倒数。</p>
<p>怎么体现重要性呢？</p>
<p>分母越大，代表在越边缘的地方，这个closeness centrality就越小。</p>
<h3 id="clustering-coefficient">Clustering coefficient</h3>
<p>聚类系数。</p>
<figure>
<img data-src="./cs224w-ch2/image-20231010162005064.png" alt="image-20231010162005064">
<figcaption aria-hidden="true">image-20231010162005064</figcaption>
</figure>
<p>研究聚类系数的意义是：<strong>当你和你的邻居是链接的时候，你的邻居的邻居是否也是连接的？</strong></p>
<p>上面是怎么算的呢？</p>
<ul>
<li>图1，v周围有4个结点，这四个结点彼此相连需要<span class="math inline">\(C_4^2=6\)</span>条边，所以分母是6，而现实中这四个点也正是彼此相连，因此分子也是6，所以聚类系数为1</li>
<li>图2，分母6，分子3，所以聚类系数0.5</li>
</ul>
<p>还有一种算法是： <span class="math display">\[
CC(u)=\frac{2R_u}{k_u (k_u -1)}
\]</span> <span class="math inline">\(R_u\)</span>：邻居结点的关系数，或者说三角形数</p>
<p><span class="math inline">\(K_u\)</span>：u的一阶邻节点数</p>
<p>聚类系数的意义是，如果两个人有相同的朋友，那么这两个人迟早也会成为朋友，这就是社交网络的扩张方式，是以<strong>三角形闭合</strong>的形式来完成的。</p>
<h3 id="graphlets">graphlets</h3>
<p>图元。</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012183058595.png" alt="image-20231012183058595">
<figcaption aria-hidden="true">image-20231012183058595</figcaption>
</figure>
<p>中文名：有根连接的非同构子图。如上，两个结点只有一个图元，三个结点有两个图元，其中<span class="math inline">\(G_1\)</span>有两类结点，node 1和node
2是异构的，node 1和node 3是同构的。</p>
<h3 id="gdv">GDV</h3>
<p>有了Grapglets的定义，可以定义GDV（graphlets degree
vector，图元度向量），这是<strong>属于图元的结点特征</strong>，</p>
<p>可以这样理解：</p>
<ul>
<li>graph degree代表的是node接触到的edge的数量</li>
<li>clustering coefficient表示的是node参与或者接触的三角形的个数</li>
<li><strong>grapglets degree
vector表示结点参与的图元的数量。</strong></li>
</ul>
<p>一般只观察三个以内的graphlets。</p>
<p>举例子</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012184847587.png" alt="image-20231012184847587">
<figcaption aria-hidden="true">image-20231012184847587</figcaption>
</figure>
<p>计算<span class="math inline">\(v\)</span>的图元度向量</p>
<p>首先，我们只考虑2或者3的图元，有以下几种可能：</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012185000246.png" alt="image-20231012185000246">
<figcaption aria-hidden="true">image-20231012185000246</figcaption>
</figure>
<p><span class="math inline">\(v\)</span>在图元中可能有上面的几种位置：<span class="math inline">\(a,b,c,d\)</span>，这意味着我们最终得到的GDV是一个<span class="math inline">\((4,1)\)</span>的tensor，我们一类一类排序如下：</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012185144784.png" alt="image-20231012185144784">
<figcaption aria-hidden="true">image-20231012185144784</figcaption>
</figure>
<p>最后得到的结果是：<span class="math inline">\(GDV=[2,1,0,2]\)</span></p>
<p>使用<span class="math inline">\(GDV\)</span>能够更好的比较两个不同node的neighbor的相似度。</p>
<h2 id="link-level-feature">Link-level feature</h2>
<p>Link-level task是这样的：</p>
<ul>
<li>利用已存在的link去预测新的llink</li>
<li>所有的没有link的node会被结合称pairs，然后排序，然后前k个node
pairs会被预测出来</li>
</ul>
<p>关键是如何设计node pairs的特征</p>
<p>有两种方法去进行link的预测：</p>
<ol type="1">
<li><p>随机移除一组links，然后让机器学习算法去预测他们。</p>
<p>主要适用于静态网络。</p></li>
<li><p>在<span class="math inline">\(t_0\)</span>时间对graph进行预测，预测的结果是未来会出现的link的列表，然后到<span class="math inline">\(t_1\)</span>时间时，我们看这些边是否真的出现了，然后去调整我们的算法。</p>
<p>主要适用于随时间变化的网络，如社交网络、交易网络</p></li>
</ol>
<p>现在可以来描述方法了--如何描述node pairs的特征</p>
<p>首先有一对结点<span class="math inline">\((x,y)\)</span>，我们计算他们有多少条公共边（这只是一种方法），然后算出一个分数<span class="math inline">\(c(x,y)\)</span>，然后将这些分数进行排序，选择前n个进行预测，在测试时间，我们可以看到前n个有多少真的出现了。这种方法是上面基于时间的预测。</p>
<h3 id="最短距离">最短距离</h3>
<figure>
<img data-src="./cs224w-ch2/image-20231012202339435.png" alt="image-20231012202339435">
<figcaption aria-hidden="true">image-20231012202339435</figcaption>
</figure>
<p>若是用这个来描述，那么<span class="math inline">\((B,H)\)</span>和<span class="math inline">\((D,F)\)</span>没有任何区别，但是前者其实有一个共同的邻居，联系更紧密</p>
<h3 id="局部邻居重叠">局部邻居重叠</h3>
<figure>
<img data-src="./cs224w-ch2/image-20231012202833459.png" alt="image-20231012202833459">
<figcaption aria-hidden="true">image-20231012202833459</figcaption>
</figure>
<p>其中第二个式子试图对共同的邻居数进行归一化。</p>
<p>而第三个式子，则是依据这样的一个道理：两者之间有共同的邻居，这个邻居的degree越少越好，这就代表两者越close</p>
<p>局部邻居重叠的问题在于，如下图：</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012203157149.png" alt="image-20231012203157149">
<figcaption aria-hidden="true">image-20231012203157149</figcaption>
</figure>
<p>尽管A和E没有共同邻居，他们的path大于2，他们的metric将会一直是0；但是，这两个结点在未来还是很有可能会连接。</p>
<h3 id="全局邻居重叠">全局邻居重叠</h3>
<p>通过Katz index计算全局邻居重叠。</p>
<p>idea is: 计算出之间距离为l的path数目</p>
<p>通过下面这个公式： <span class="math display">\[
S_{v_1v_2}=\sum _{l=1}^{\infty}\beta ^lA_{v_1v_2}^l
\]</span> 其中beta是discount factor（0～1），path越长，discount越多</p>
<p>也可以用下面的公式简单计算：</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012204209259.png" alt="image-20231012204209259">
<figcaption aria-hidden="true">image-20231012204209259</figcaption>
</figure>
<h2 id="graph--level-feature">graph- level feature</h2>
<h3 id="kernel-method">kernel method</h3>
<p>kernel
matrix有一些硬性要求：如特征值要有大雨0的特征值（半正定），对称矩阵。</p>
<p>kernel可以测量两个graph的相似性，用的不是feature vector，而是kernel
matrix <span class="math display">\[
K(G_1,G_2)=\Phi (G_1)^T\Phi(G_2)
\]</span>
一旦kernel被创建好了，那就可以用支持核方法的机器算法来进行训练了。</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012211504003.png" alt="image-20231012211504003">
<figcaption aria-hidden="true">image-20231012211504003</figcaption>
</figure>
<p>上面两种是最重要的核，下面几种则是不要求的</p>
<p>简单介绍下Bag-of-Words（BoW），词袋，例如我们要表示一篇文档，可以把里面的词都挑出来，然后按照频率来进行排序，这就是词袋方法。</p>
<p>但是我们不能简单的将node视为词，否则就会发生下面这种情况：</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012212052689.png" alt="image-20231012212052689">
<figcaption aria-hidden="true">image-20231012212052689</figcaption>
</figure>
<h3 id="degree-kernel">degree kernel</h3>
<p>将结点的度视为词，然后装进袋子：</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012212328492.png" alt="image-20231012212328492">
<figcaption aria-hidden="true">image-20231012212328492</figcaption>
</figure>
<h3 id="graphlets-kernel">graphlets kernel</h3>
<p>idea：计算图中不同图元的个数</p>
<p>kernel的图元和node-
level的图元有点不同，kernel的图元中的结点可以是孤立的、没有链接、没有根的</p>
<figure>
<img data-src="./cs224w-ch2/image-20231012212953447.png" alt="image-20231012212953447">
<figcaption aria-hidden="true">image-20231012212953447</figcaption>
</figure>
<p>我们用一个graphlets count list <span class="math inline">\(f_G\)</span>来表示图元特征</p>
<figure>
<img data-src="./cs224w-ch2/%E6%88%AA%E5%B1%8F2023-10-12%2021.33.35.png" alt="截屏2023-10-12 21.33.35">
<figcaption aria-hidden="true">截屏2023-10-12 21.33.35</figcaption>
</figure>
<p>比较难数</p>
<p>有了feature vector之后，就可以计算kernel了： <span class="math display">\[
K(G_1,G_2)=f_{G_1}^Tf_{G_2}
\]</span> 当两个vector尺寸不一样时，可以考虑归一化： <span class="math display">\[
h_G=\frac{f_G}{Sum(f_G)}
\]</span></p>
<p><span class="math display">\[
K(G_1,G_2)=h_{G_1}^Th_{G_2}
\]</span></p>
<p>？？？不给例子？？</p>
<p>另外，不可避免的，计算图元的代价很大。在计算及格图元的时候还好，但是一旦数量往上升，开销会成指数级别上升。</p>
<h3 id="wl-kernel">WL kernel</h3>
<figure>
<img data-src="./cs224w-ch2/image-20231012215018706.png" alt="image-20231012215018706">
<figcaption aria-hidden="true">image-20231012215018706</figcaption>
</figure>
<p>过程有点复杂，但是这个算法比较高效。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/09/cs224w-ch1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/09/cs224w-ch1/" class="post-title-link" itemprop="url">cs224w_ch1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-09 18:07:15" itemprop="dateCreated datePublished" datetime="2023-10-09T18:07:15+08:00">2023-10-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-11 09:20:28" itemprop="dateModified" datetime="2023-10-11T09:20:28+08:00">2023-10-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs224w/" itemprop="url" rel="index"><span itemprop="name">cs224w</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="why-graphs">1.1 why graphs</h2>
<p>首先要回答标题这个问题，为什么是图？抽象的图可以用一些结点和边来表示：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009173202938.png" alt="image-20231009173202938">
<figcaption aria-hidden="true">image-20231009173202938</figcaption>
</figure>
<p>而生活中的很多物体、场景都可以抽象为图：</p>
<p>距离、地面图：</p>
<p><img data-src="./cs224w-ch1/image-20231009173340485.png" alt="image-20231009173340485" style="zoom:33%;"></p>
<p>现实中的一些网络：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009173426133.png" alt="image-20231009173426133">
<figcaption aria-hidden="true">image-20231009173426133</figcaption>
</figure>
<p>知识图谱、场景图、代码编译图、生物分子、计算机3D图形：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009173547896.png" alt="image-20231009173547896">
<figcaption aria-hidden="true">image-20231009173547896</figcaption>
</figure>
<p>我们可以使用图对上面这些以及更多的生活中的基础场景进行建模，然后来进行处理。</p>
<p>如今的深度学习时代，有很多非常强有力的工具能够处理序列/网格数据，如：语音、文本等，也能够很好的处理fixed
image来进行预测和分类，在这些方面已经有了惊人的成就了。但是，对于graph和network，这种具有任意大小、任意拓扑的数据结构，它没有序列数据那样具有spatial
locality（空间局部性），在文本、语音中有左和右，在图片中有上和下，但是对于图graph，我们没有任何的参考点，没有任何的顺序。</p>
<p>我们期望的是在graph上建立神经网络，输入是我们的graph，输出被期望是在一个结点的多个方面去做预测，如预测结点类型、结点属性、结点的下一个路径等。</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009174815960.png" alt="image-20231009174815960">
<figcaption aria-hidden="true">image-20231009174815960</figcaption>
</figure>
<p>另外，feature engineering也不再需要，现在是representation
learning，机器会自动找到更好的representation，然后来做下游任务。</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009175137515.png" alt="image-20231009175137515">
<figcaption aria-hidden="true">image-20231009175137515</figcaption>
</figure>
<p>representation learning：自动提取或者学习特征。</p>
<p>除了上面那个神经网络架构，我们的目标还可以表示为下面的形式：将graph嵌入到一个d维的向量中，这个向量就是我们最终的representation。</p>
<figure>
<img data-src="./cs224w-ch1/image-20231010110432270.png" alt="image-20231010110432270">
<figcaption aria-hidden="true">image-20231010110432270</figcaption>
</figure>
<h2 id="application-of-graph-ml">1.2 application of graph ml</h2>
<p>graph ml任务可以分为好几种：</p>
<ul>
<li>Node-level：预测结点的属性
<ul>
<li>如用户类型分类</li>
</ul></li>
<li>edge-level：预测两个node之间是否缺失边
<ul>
<li>知识图谱</li>
</ul></li>
<li>sub graph-level：社区预测</li>
<li>Graph-level：对图进行分类
<ul>
<li>例如画出一个分子图，来预测它的属性</li>
</ul></li>
<li>Graph-generalizing：用已存在的药物发现新的药物</li>
</ul>
<h3 id="edge-level">edge-level</h3>
<p>一个真实的应用：AlphaFold，DeepMind研发的框架，用来预测蛋白质，给定一些氨基酸，能否预测出这个蛋白质出来。这就属于是edge-
level task</p>
<p>PS：<strong>DeepFold获得2023年的诺贝尔奖！</strong></p>
<p>另外一个link-level
task是药物副作用，有很多年纪大的人有很多co-exist的疾病，要同时服用很多种药物，那么这些药物和药物之间是否具有某种联系（link/edge），但是这样的组合很多，不可能去通过排列组合来尝试。所以能否建立一个系统，来判断药物之间是否有edge？</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009185858019.png" alt="image-20231009185858019">
<figcaption aria-hidden="true">image-20231009185858019</figcaption>
</figure>
<p>生物学家已经能够通过实验确定两种蛋白质之间是否有作用或者反应，但是药物与药物之间是否有反应还未知。</p>
<h3 id="node-level-task">Node-level task</h3>
<p>一个最明显的就是推荐系统：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009184014176.png" alt="image-20231009184014176">
<figcaption aria-hidden="true">image-20231009184014176</figcaption>
</figure>
<p>其中node可以是人或者item（衣服、音乐、食物、电影……），当人跟item交互，人购买了衣服，听了音乐，那么他们之间就有一条edge。</p>
<p>下面一个推荐系统，我们的任务是把node做一个合适的嵌入：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009184433408.png" alt="image-20231009184433408">
<figcaption aria-hidden="true">image-20231009184433408</figcaption>
</figure>
<p>可以这么理解，更相关的node应该被嵌入到一起（比如上面的将图嵌入到一个d维的向量中去，这两个蛋糕应该被嵌入到一个相同的向量下标中去）。</p>
<h3 id="sub-graph-level">Sub-graph level</h3>
<p>例子：Google map</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009191024327.png" alt="image-20231009191024327">
<figcaption aria-hidden="true">image-20231009191024327</figcaption>
</figure>
<p>node代表的是路段，edge代表的是两段路之间的边缘，也就是两段路是不是连接的。</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009191133035.png" alt="image-20231009191133035">
<figcaption aria-hidden="true">image-20231009191133035</figcaption>
</figure>
<p>并且GNN是根据每段路的路况、长度等因素训练而成的。</p>
<h2 id="choice-of-graph-representation">1.3 choice of graph
representation</h2>
<p>选择什么是边、结点很重要，有时是独一无二的，不然会影响到最终的模型的性能。</p>
<p>介绍了一下图的基本定义，这里有一个不熟悉的点：</p>
<p>bipartite graph：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009193652336.png" alt="image-20231009193652336">
<figcaption aria-hidden="true">image-20231009193652336</figcaption>
</figure>
<p>bipartite
graph有两类结点，两类结点之间互相会link，同一个部分的各个节点并不会interact。</p>
<p>下面是举例：</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009193757002-6851477.png" alt="image-20231009193757002">
<figcaption aria-hidden="true">image-20231009193757002</figcaption>
</figure>
<p>由bipartite graph，可以演变出fold
network，例如作者合作网络，左边是作者，右边是书，1、2、3共同写了一本书A，2、5共同写了B，那么可由中间演变出左边的fold
network</p>
<figure>
<img data-src="./cs224w-ch1/image-20231009194322173-6851803.png" alt="image-20231009194322173">
<figcaption aria-hidden="true">image-20231009194322173</figcaption>
</figure>
<p>反过来，也可以由书推到作者，生成上面右边的fold network</p>
<p>下面开始将如何去represent graph</p>
<h3 id="adjacent-metric">adjacent metric</h3>
<figure>
<img data-src="./cs224w-ch1/image-20231009194721176.png" alt="image-20231009194721176">
<figcaption aria-hidden="true">image-20231009194721176</figcaption>
</figure>
<p>adjacent
metric的缺点就是其太稀疏（sparse）了，以人类为例子，画一张图，我们每个人的out
degree也就那几十几百个，不会是几百万个，所以这张图中有很多元素是0</p>
<h3 id="edge-list">edge list</h3>
<figure>
<img data-src="./cs224w-ch1/image-20231009195356051.png" alt="image-20231009195356051">
<figcaption aria-hidden="true">image-20231009195356051</figcaption>
</figure>
<p>这样的表示存储起来就小多了，但是其问题在于，很难对图进行操作，例如想算一个node的out
degree，比较麻烦。</p>
<h3 id="adjacent-list">adjacent list</h3>
<figure>
<img data-src="./cs224w-ch1/image-20231009195603472.png" alt="image-20231009195603472">
<figcaption aria-hidden="true">image-20231009195603472</figcaption>
</figure>
<p>相对而言这是一种比较折中的存储结构了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/09/first-gnnbook-ch2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/09/first-gnnbook-ch2/" class="post-title-link" itemprop="url">first_gnnbook_ch2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-09 14:50:13" itemprop="dateCreated datePublished" datetime="2023-10-09T14:50:13+08:00">2023-10-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-11 09:20:04" itemprop="dateModified" datetime="2023-10-11T09:20:04+08:00">2023-10-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Graph-Neural-Networks-Foundations-Frontiers-and-Applications/" itemprop="url" rel="index"><span itemprop="name">Graph Neural Networks: Foundations, Frontiers, and Applications</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="摘要">摘要</h2>
<p>图表征学习的目的是：将图中的结点以低维度表征的形式表现出来，同时又改变图原本的结构。</p>
<h2 id="图表征学习介绍">图表征学习介绍</h2>
<p>图表征学习的一大困难是：如何有效的表示图，使得一些先进的方法如模式识别、分析、预测，能够被高效的运用在图上，不管是时间还是空间上。</p>
<p>以传统的方式表示图（<span class="math inline">\(G=(V,E)\)</span>），在main对数百万个结点时，分析起来会有以下问题：</p>
<ul>
<li>计算复杂度高</li>
<li>不能并行计算</li>
<li>不适用于机器学习方法</li>
</ul>
<p>要想让图表征学习能够被分析、运算，有以下两个目标</p>
<ul>
<li>图能够被重构到可以被运算的表征空间中去。</li>
<li>这个表征空间支持图推断</li>
</ul>
<p>满足以上两个要求，就意味着可以用图来做：分类、预测等任务了。</p>
<p>有三个方法：传统图嵌入、现代图嵌入、图神经网络</p>
<h2 id="传统图嵌入">传统图嵌入</h2>
<p>传统图嵌入可以看成一种降维技术，它将图重构为一个特征表征数据集（像图片数据集），其目标函数正是完成图的重构。</p>
<h2 id="现代图嵌入">现代图嵌入</h2>
<p>现代图嵌入为了更好的推断，将考虑更多丰富的信息。根据图嵌入保护的信息类型的不同，可做以下分类：</p>
<ul>
<li>图结构和属性保护图嵌入</li>
<li>基于边信息的图嵌入</li>
<li>高级信息保护图嵌入</li>
</ul>
<p>用到的方法有：矩阵分解、随机游走、深度神经网络</p>
<h3 id="结构属性保护图嵌入">结构属性保护图嵌入</h3>
<p>图的结构和属性很大程度上影响图的推断，所以最基本的是先保护好图的结构和属性。图的结构包括一维结构和高维结构。不同的图有不同的属性/性质，如：有向图有不对称传递性；信号图能用结构平衡理论。。</p>
<h4 id="结构保护图嵌入学习">结构保护图嵌入学习</h4>
<p>常用的结构有：结构、高维临近结点、图社区</p>
<p>。。。看不下去了。。。综述一样</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/08/poisoning-attack-on-dl-wtp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/08/poisoning-attack-on-dl-wtp/" class="post-title-link" itemprop="url">Poisoning Attacks on Deep Learning based Wireless Traffic Prediction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-08 19:58:10" itemprop="dateCreated datePublished" datetime="2023-10-08T19:58:10+08:00">2023-10-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:50:09" itemprop="dateModified" datetime="2024-04-19T12:50:09+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>从背景、问题、方法、结论、创新点、相关工作、评价等几个方面做论文笔记</p>
<p>1、研究动机是什么</p>
<p>poisoning
attack这个问题在CV领域已经有人做了，但在WTP领域还是空白。</p>
<p>2、主要解决了什么问题</p>
<p>作者提出了两种攻击方式，分别是在集中式和分布式场景下，对训练阶段进行中毒攻击；并提出了两种防御方法，验证了其有效性。</p>
<p>3、所提方法是什么</p>
<p>集中式场景--数据中毒攻击--数据清洗；</p>
<p>分布式场景--模型中毒攻击--异常检测。</p>
<p>4、关键结果和结论是什么</p>
<p>5、创新点在哪里，这篇论文到底有什么贡献？</p>
<p>在WTP领域提出两种中毒攻击并且提出了解决方法。</p>
<p>在WTP这是一个全新的问题。</p>
<p>6、有值得阅读的相关文献吗</p>
<p>有很多，可以列成树了都，比如在这篇文章中作者做了很多假设，而有的假设是existing
work，有的则不是，作者文章中选择了稍微简单一点的假设，便于处理，但从本文中还是可以看到很多别的方向的。</p>
<ul>
<li>集中式场景下，假设malicious client智能知道自己的数据</li>
<li>分布式场景下，malicious client也是独立的</li>
<li>分布式场景下，malicious
client上传增量模型用于更新事，假设模型不会发生碰撞</li>
<li>...</li>
</ul>
<p>7、综合评价如何？</p>
<p>看数据的话是好的，中毒后，MSE飙升；使用了提出的防御方法后，MSE又降下来了。</p>
<p>8、用于定量评估的数据集是什么？代码有没有开源？</p>
<p>两个数据集，在Google Drive中可下载；</p>
<p>代码开源了部分</p>
<p>9、下一步呢？有什么工作可以继续深入？</p>
<p>如问题6</p>
<h3 id="摘要">摘要</h3>
<p>本文的工作：</p>
<ul>
<li>在无限流量预测领域，针对训练阶段的脆弱性，提出了2种攻击方式
<ul>
<li>扰动掩盖策略</li>
<li>调优和缩放方法</li>
</ul></li>
<li>针对攻击，提出了两种防御方法
<ul>
<li>数据清洗</li>
<li>异常检测</li>
</ul></li>
</ul>
<p>本文对集中式和分布式的场景都进行了实验。</p>
<h3 id="介绍">介绍</h3>
<p>作者不光吹捧了下已有的工作，还进行了对比，提升了多少多少（优点），然后指出这些工作用的是DL，但是都是在非对抗环境下完成的，如果是对抗环境可能情况完全不一样（malicious
client）。然后就是针对不同场景，阐述对抗环境下模型训练的潜在危害：集中式场景下，恶意客户端可以将有毒数据混入数据集上传给云服务器；分布式场景下，则是可能会将中毒模型增量上传到云服务器。</p>
<p>作者表示，人为导向的预测只需要少量的有毒数据即可。举的例子有信息安全（AES的加密）、推荐系统、以及向深度学习的模型中植入后门。</p>
<p>但是在无限流量预测这个领域，中毒攻击还没有被探索。作者做了好几个假设：</p>
<ul>
<li>集中式场景下，恶意客户端只能访问他自己的流量数据</li>
<li>分布式场景下，恶意客户端提交模型增量更新的时候不会发生碰撞，同时也不能一起合作。</li>
</ul>
<p>基于这几个假设，作者提出了扰动掩盖策略：<strong>利用有限的数据，来模仿集中式模型的优化过程</strong>。大概做法是，将本地的数据集分为两部分：10(1-p)%的干净数据以及100p%的加了扰动的数据，将这些数据扔给本地的代理模型进行训练、优化，使得这些扰动看起来更加普遍；调优和缩放方法则是运用于分布式场景下，这个看不太懂，等下看公式。</p>
<p>然后针对这两个attack，作者测试了以前的防御方法（数据消毒和随机平滑），但是性能不是很好。然后这里作者有提出了一个假设：在两个相邻时间点之间，无线流量的量很少变化很多，然后定义了一个adjacent
distance，将这个距离最大的点移除（数据消毒）。另外，还实现了一些健壮性的回归方法。（existing
work）</p>
<p>作者做了一些实验，用的数据集是“wireless traffic data from Telecom
Italia”，然后使用的模型是LSTM、ConvLSTM……实验结果显示中毒攻击可以使训练好的model的MSE提高很多。然后对比之下，使用刚刚提到的数据消毒以及异常检测方法，</p>
<h3 id="背景以及真正的工作">背景以及真正的工作</h3>
<h4 id="符号及表示">符号及表示</h4>
<p>用<span class="math inline">\(x_t\)</span>代表时刻t之前的一部分流量数据，<span class="math inline">\(y_t\)</span>表示t时刻的流量，模型用<span class="math inline">\(f_{\theta}(.)\)</span>表示，预测结果<span class="math inline">\(y^{-}_t=f_{\theta}(x_t)\)</span>，数据集由k个客户端创建：<span class="math inline">\(D_k=\{x_i^k,y_i^k\}\)</span></p>
<p>existing work是这样训练模型的：使得其MSE最小。</p>
<p>本文中的攻击，会在自变量和因变量上加上扰动：<span class="math inline">\(x_i^k+\delta_{x_i^k}\)</span>，<span class="math inline">\(y_i^k+\delta _{y_i^k}\)</span></p>
<h4 id="数据中毒攻击--dl">数据中毒攻击--DL</h4>
<p>数据中毒攻击的一假设是：攻击者只能参与数据的准备阶段，不能干扰模型的优化以及推导过程。</p>
<p>至于中毒攻击，无论是数据中毒还是模型中毒：</p>
<ul>
<li>有目的性的数据中毒攻击会误导模型的预测结果</li>
<li>无目的性的数据中毒攻击则是降低模型的性能</li>
</ul>
<h4 id="模型中毒攻击--fl">模型中毒攻击--FL</h4>
<p>模型中毒攻击能够直接修改上传的模型更新，这种中毒有着很好的攻击性能。但是一些先进的回归算法能够识别并且丢弃掉这些中毒更新，因此本文的工作之一是：将模型中毒看成一个优化问题--得到最优的中毒更新。</p>
<h3 id="问题规划">问题规划</h3>
<h4 id="dl-based-watp">DL based WATP</h4>
<h5 id="集中式">集中式</h5>
<p>问题场景：</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009085127126.png" alt="image-20231009085127126">
<figcaption aria-hidden="true">image-20231009085127126</figcaption>
</figure>
<p>抽象为优化问题：</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009085211353.png" alt="image-20231009085211353">
<figcaption aria-hidden="true">image-20231009085211353</figcaption>
</figure>
<ol type="1">
<li>这两个式子的右边都是MSE loss的形式。</li>
<li>意思是：使得perturbation data的loss最小，求出参数<span class="math inline">\(\theta\)</span>，然后使得clean data的MSE最大</li>
<li>这样虽然不能干涉调优过程，但是mislead了调优方向，从而mislead了output</li>
</ol>
<h5 id="分布式">分布式</h5>
<p>问题场景</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009090132294.png" alt="image-20231009090132294">
<figcaption aria-hidden="true">image-20231009090132294</figcaption>
</figure>
<p>抽象为优化问题</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009090147875.png" alt="image-20231009090147875">
<figcaption aria-hidden="true">image-20231009090147875</figcaption>
</figure>
<p>解读：下式是模型参数更新，使得更新后的模型的loss最大，从而降低performance</p>
<h4 id="威胁模型">威胁模型</h4>
<h5 id="攻击者的目标">攻击者的目标</h5>
<p>本文中主要是非目的性攻击，也就是单纯的降低模型的性能。</p>
<h5 id="攻击者的认知">攻击者的认知</h5>
<p>集中式场景下，攻击者只有自己的数据，并且不知道中心结点的服务器的神经网络架构。因此攻击者只能选择其他的架构，并初始化一个模型，并在上面做中毒数据的调整。</p>
<p>分布式场景下，假设攻击者每一个回合都能接收到服务器发来的权重，并且权重是没有加密的/或者是用一个普通的密钥来进行加密（若是每个client的密钥都不一样，那对于服务器的管理、客户端的解密都是非常麻烦的），即使没有接收到最新的模型权重，也可以用历史模型权重来代替它。</p>
<h5 id="攻击者的能力">攻击者的能力</h5>
<p>集中式场景下，会对perturbation加以限制；分布式场景下恶意客户端不会碰撞。</p>
<ul>
<li>碰撞会给恶意客户端之间带来额外的沟通开销</li>
<li>碰撞会让恶意客户端提交更新延迟一点，这会让服务器产生怀疑</li>
</ul>
<h3 id="攻击算法">攻击算法</h3>
<h4 id="集中式-1">集中式</h4>
<p>由于本文假设的是恶意客户端只有他自己的数据（这是全局数据的一个子集），因此用现有的方法可能会造成次优攻击（sub-optimal
attack），意思就是掌握的信息不够多，可能发起的不是最优的攻击。</p>
<p>因此作者提出掩盖扰动策略：在有限的数据下，尽可能使得扰动数看起来正常。</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009102033036.png" alt="image-20231009102033036">
<figcaption aria-hidden="true">image-20231009102033036</figcaption>
</figure>
<h4 id="分布式-1">分布式</h4>
<p>普通的client是最小化loss，而malicious
client是最大化loss（调优），然后对参数更新进行一个放缩。</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009102200880.png" alt="image-20231009102200880">
<figcaption aria-hidden="true">image-20231009102200880</figcaption>
</figure>
<h3 id="防御">防御</h3>
<p>下面介绍几种潜在的防御方法。</p>
<p>只介绍了有用的两个，其他两个后面会作为反面教材进行测试。</p>
<h4 id="数据消毒">数据消毒</h4>
<p>有一种数据消毒方法为(<strong>existing
work</strong>)：先估计全部数据集的数据，找出数据的形心（data
centroid），然后将距离这个中心最远的点移除。最简单的做法是，直接算出均值，作为形心的近似值。这种方法对于本文中考虑的场景并不适用。因此作者提出了adjacent
distance：</p>
<figure>
<img data-src="./poisoning-attack-on-dl-wtp/image-20231009103145961.png" alt="image-20231009103145961">
<figcaption aria-hidden="true">image-20231009103145961</figcaption>
</figure>
<p>对所有的样本都计算出adjacent
distance，然后把100p%的discard，p代表的是我们认为的潜在的malicious
client的部分。</p>
<h4 id="异常检测">异常检测</h4>
<ol type="1">
<li>计算出所有model update的<span class="math inline">\(L_2\)</span>范数，取中位数记为<span class="math inline">\(\mu _t\)</span></li>
<li>将所有的<span class="math inline">\(L_2\)</span>范数和<span class="math inline">\(\mu _t\)</span>进行相除，取中位数，记<span class="math inline">\(\sigma _t\)</span></li>
<li>规定，所有model update的最大<span class="math inline">\(L_2\)</span>范数不超过<span class="math inline">\(c_1\mu _t\)</span>；并且不超过<span class="math inline">\(\mu _t+c_2\sigma _t\)</span></li>
</ol>
<p>这个阈值是动态的，在本文的实验中，<span class="math inline">\(c_1=40,c_2=400\)</span>比较好</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/08/dsp-ch2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/08/dsp-ch2/" class="post-title-link" itemprop="url">dsp_ch2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-08 18:09:48" itemprop="dateCreated datePublished" datetime="2023-10-08T18:09:48+08:00">2023-10-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-11 09:19:16" itemprop="dateModified" datetime="2023-10-11T09:19:16+08:00">2023-10-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="信号的基本概念">信号的基本概念</h2>
<p>信号的定义：随时间变化的有限实值函数。其有两个特性：</p>
<ul>
<li>实值性：信号的取值都是实数。</li>
<li>有限性：信号的值是有限值，从功率的角度来看，功率是有限的，能量是有限的，信号自然也是有限的。</li>
</ul>
<p>以确定性为标准，信号可分为确定信号和随机信号：</p>
<ul>
<li>确定信号：对于任意时刻，都可以确定信号的值。</li>
<li>随机信号：只能从概率分布的角度描述随机信号的相位or幅度。</li>
</ul>
<p>从时间变量（定义域）的取值是否连续可分为：连续信号 or 离散信号</p>
<p>从定义域以及值域的取值是否连续（同时，二者都），可分为模拟信号 or
数字信号。</p>
<h2 id="信号的时域描述">信号的时域描述</h2>
<p>对模拟信号<span class="math inline">\(x_a(t)\)</span>从时间上进行采样，可得到离散信号<span class="math inline">\(x(n)\)</span>: <span class="math display">\[
x_a(t)|_{t=nT_s}=x_a(nT_s)=x(n)
\]</span> 公式(1)展示了采样的原理。其中<span class="math inline">\(T_s\)</span>表示采样周期，采样频率<span class="math inline">\(f_s=\frac{1}{T_s}\)</span></p>
<p>例如，对于离散正弦信号，就可以通过采样模拟正弦信号<span class="math inline">\(x_a(t)=A\sin(2\pi ft+\phi)\)</span>来得到： <span class="math display">\[
x_a(t)|_{t=nT_s}=A\sin(2\pi fnT_s+\phi)=A\sin(\Omega
T_sn+\phi)=A\sin(\omega n+\phi)
\]</span> 其中，<span class="math inline">\(\omega\)</span>为数字角频率，<span class="math inline">\(\Omega\)</span>为模拟角频率。</p>
<p>复信号（欧拉公式）： <span class="math display">\[
e^{j\omega n}=\cos(\omega n)+j\sin(\omega n)
\]</span></p>
<h2 id="信号的频域描述">信号的频域描述</h2>
<p>离散傅立叶变换DTFT： <span class="math display">\[
X(e^{j\omega})=DTFT[x(n)]=\sum_{n=-\infty}^{\infty}x(n)e^{-j\omega n}
\]</span>
由于正弦信号的周期性，可以得到任意信号的DTFT都具备周期性，周期为2<span class="math inline">\(\pi\)</span></p>
<p>时域采样等于频域周期延拓：</p>
<figure>
<img data-src="./dsp-ch2/image-20231008192446790.png" alt="image-20231008192446790">
<figcaption aria-hidden="true">image-20231008192446790</figcaption>
</figure>
<p>由上图也可得知，要想采样之后能够完全恢复出模拟信号来，要满足下式：
<span class="math display">\[
\Omega _s&lt;2\pi \\
f_s&gt;2f_{max}
\]</span></p>
<h2 id="从模拟信号到数字信号">从模拟信号到数字信号</h2>
<figure>
<img data-src="./dsp-ch2/image-20231008190038100.png" alt="image-20231008190038100">
<figcaption aria-hidden="true">image-20231008190038100</figcaption>
</figure>
<ol type="1">
<li><p>采样</p>
<p>将模拟信号从时间上等间隔采样，得到的是离散时间信号</p></li>
<li><p>量化</p>
<p>将每个采样点的幅度以最小化的数量单位<span class="math inline">\(\Delta\)</span>的整数倍来度量，这样幅度也是离散的了，得到的是数字信号</p></li>
<li><p>编码</p>
<p>对幅度进行二进制编码</p></li>
</ol>
<h2 id="参数选择">参数选择</h2>
<p>前面讲了满足采样定理之后，可以保证采样之后的信号频谱不发生混叠。但是现实中可能会有噪声以及其他干扰信号。那么应该如何处理？</p>
<p><img data-src="./dsp-ch2/%E6%88%AA%E5%B1%8F2023-10-08%2019.44.03.png" alt="截屏2023-10-08 19.44.03">title:</p>
<p>加个滤波器做卷积即可</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/08/first-gnnbook-ch1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/08/first-gnnbook-ch1/" class="post-title-link" itemprop="url">first_gnnbook_ch1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-08 14:01:05" itemprop="dateCreated datePublished" datetime="2023-10-08T14:01:05+08:00">2023-10-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-11 09:19:08" itemprop="dateModified" datetime="2023-10-11T09:19:08+08:00">2023-10-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Graph-Neural-Networks-Foundations-Frontiers-and-Applications/" itemprop="url" rel="index"><span itemprop="name">Graph Neural Networks: Foundations, Frontiers, and Applications</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="摘要">摘要</h2>
<p>介绍了一下这章干什么，讲表示学习（表征学习），然后主要关注DL方面的方法。解释了DL：一系列非线性变换，以得到更抽象、更有用的表示。然后是表征学习可以运用的领域：图片、nlp、演讲信号、网络……</p>
<h2 id="表征学习介绍">表征学习介绍</h2>
<p>踩了一波ML：依赖算法、数据特征的选取。不好的特征可能会影响算法、包含过多冗余信息。</p>
<p>然后给出表示学习的目的：<strong>从数据中提取出足够但是有限的特征</strong>。传统的做法是这样，利用<strong>特征工程</strong>--利用人的先验知识以及领域专家知识，来人工提取特征。并且，很大一部分的精力是放在数据预处理以及数据转换身上（也就是通俗的<strong>玩数据</strong>）。特别的，又踩了一波特征工程，就是利用的独创性和先验知识提取特征，<strong>先有人工再有智能。</strong>下面对特征工程的缺点进行了归纳：</p>
<ol type="1">
<li>需要模型开发者和领域专家共同协作。</li>
<li>人工提取特特征可能是不完全的、有偏好（甚至偏见的）。另外，人类自身的知识也是有限性的，并且同一领域的不同专家的见解也可能不一样。</li>
</ol>
<p>传统的方法，属于比较”浅“的模型，它们的目的是对数据进行变换，以提取出更有用的信息。
还得是基于DL的表征学习，大致有这两类：</p>
<ol type="1">
<li><p>监督学习</p>
<p>最后的全连接层输出的就是原始数据的最终表示（final
representation）</p></li>
<li><p>无监督学习：试图让模型找到数据内在的结构 ｜ 数据潜在的分布。</p>
<p>这里还提到了预任务：“<strong>The pre-tasks are utilized to explore
the supervision information from large amounts of unlabelled
data</strong>”。和预训练（拿别人训练好的模型过来微调，前提是最后的分类得相同）不同，预任务是从大量的没有标签的数据中提取监督信息。基于这些提取好的监督信息，无监督学习就可以从数据中提取出更有意义的表示。</p></li>
<li><p>转移学习（transfer learning）：</p>
<p>利用现在已有的数据、标签、模型，来学习一个新的模型，这个模型能够泛化之前学习的内容，然后针对具体的某一个任务。</p></li>
<li><p>reinforcement learning, few-shot learning, and disentangled
representa- tion learning etc.</p></li>
</ol>
<p>最后讲了下怎么评价一个好的表征学习，除了抽象的定义之外（<strong>representation
learning is about learning the (underlying) features of the data that
make it easier to extract useful information when building classifiers
or other
predictors</strong>），更直观的评估是看它在下游任务上的性能：</p>
<ol type="1">
<li>对于生成式任务（GPT），要看它是否能捕获到更后的（未来的）分布</li>
<li>对于预测任务，捕获最小的但是足够的信息来正确的预测到目标。</li>
</ol>
<h2 id="不同研究领域的表征学习">不同研究领域的表征学习</h2>
<p>4个领域</p>
<ul>
<li>图像</li>
<li>语音识别</li>
<li>自然语言处理</li>
<li>网络分析</li>
</ul>
<h3 id="图像">图像</h3>
<p>图像表征学习的目的是：在像素数据和人类语义之间搭起桥梁。</p>
<p>介绍了一下历史，从前的特征工程都是人工特征工程，是人先提取特征，然后给到机器。比如手写字母，有人提取了字母的结构特征。这种都是需要利用人力提取特征、利用并且依赖于人的先验知识。</p>
<p><strong>有监督学习的图像表征学习</strong>，模型很多样，从Hinton提出的深度表征学习，为了对抗SVM在Minist上良好的性能，到Hinton的表示Alex搞的AlexNet，然后VGG、GoogleNet、ResNet……；大数据集也有很多：ImageNet、OpenImage等。</p>
<p><strong>无监督图像表征学习</strong>，首先建立图像或者视频数据集非常昂贵，费人力费钱，因此有很多无监督的方法。</p>
<ol type="1">
<li>pretext
task：前置任务，模型先在前置任务上学习，这样有助于模型更好地理解目标任务。比如说先学纹理、阴影等低级特征，然后在学部分高级点的特征，最后再给到下游任务，下游任务的数据集往往不是很大，这时用pretext
task可以改善性能、减少过拟合</li>
</ol>
<p><strong>transfer
leading，也称表征学习</strong>。对于不同的问题，很多问题的数据集都是在同一个特征空间中、或者是服从同一个分布，更重要的是，很多问题的测试集还不能获取。迁移学习是这样做的，利用其他相关的、相近的领域的先验知识来进行学习，称这些为<strong>source
domains</strong>，而目标任务的实际应用领域称为<strong>target
domains</strong>。一般而言，有好几个source domains，只有一个target
domain，训练集和测试集额度数据就是来源于这两类domains。将表征学习用到图像上：</p>
<ul>
<li>特征表示知识迁移：利用已经提取好的特征，将target source映射到source
domains，这样映射之后，target和source之间的差异能够显著减少。</li>
<li>基于分类的知识迁移：共享相同的特征，将source domain
models视为先验知识，不同于上面这种方法（减小target和source之间的差异），基于分类的知识迁移试图学到一个新的target
domain model，并且在提供的target 和source domain上泛化误差最小。</li>
</ul>
<p><strong>语音识别和nlp先略过，这里直接看看网络。</strong></p>
<h3 id="网络">网络</h3>
<p>这里的网络是一个很泛的概念，不只是计算机网络，还有cyber-
network（网中网）：社交网络，生物网络、电话网络、交通运输网络……这些在数学上可以表示为图。不仅如此，图片、文字等都可以表现为图的形式。如何有效的把表征学习用到图上是一个很重要的问题，因为图的规模可能会很大，像维基百科的引用图，非常庞大的图，有很多节点。另外，研究这个问题可以对很多其他的学科产生推进作用（社交网络中的广告推荐系统、生物蛋白质预测……）。</p>
<p>传统的特征工程应用到图上时，往往只能捕捉到一些简单的特征：</p>
<ul>
<li>edge：边的长度……</li>
<li>node：结点的角度、中心……</li>
<li>graph：平均路径长度……</li>
<li>super-graph：子图、图形图案……</li>
</ul>
<p>在这里更能体现出传统特征工程的局限性了，这些预先定义好的特征是相当有限的，忽略掉了很多重要的模式。另外，在这些手工特征上做计算也不容易，昂贵并且高的复杂度。</p>
<p>比较新的是网络表征学习（network representation learning,
NRL），和图像中的表征学习一样，它试图去找到潜在的、低维的图的表示，并且保留图的拓扑结构、结点信息、边信息。在找到好的表征之后，在其基础之上，就可以用机器学习的那一套去做了。（所以有人说GNN就是一个提取特征/表征的工具）2000年有人用图嵌入算法去降维，图嵌入是依赖于独立同分布的数据的，因此不适用于大多情景。到08年才有人做出了有意义的工作，已经能够做一些结点分类、路径预测等任务了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/07/NovelADS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/07/NovelADS/" class="post-title-link" itemprop="url">NovelADS</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-07 17:09:52" itemprop="dateCreated datePublished" datetime="2023-10-07T17:09:52+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:48:24" itemprop="dateModified" datetime="2024-04-19T12:48:24+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>从背景、问题、方法、结论、创新点、相关工作、评价等几个方面做论文笔记</p>
<p>1、研究动机是什么</p>
<p><strong>这个智能交通领域中，传统的CAN协议太脆弱了，很有可能会威胁行人和乘客的安全</strong></p>
<p>2、主要解决了什么问题</p>
<p><strong>提出了新的网络架构，用来做异常检测</strong></p>
<p>3、所提方法是什么</p>
<p><strong>有M1～M4这4个模型，然后三个攻击场景，然后做实验。</strong></p>
<p>4、关键结果和结论是什么</p>
<p><strong>在table 7和table
8中，看到和已存在的工作的结果相比，效果是非常好的。</strong></p>
<p>5、创新点在哪里，这篇论文到底有什么贡献？</p>
<ul>
<li><strong>提出了新的模型，并且性能上更好，对比已存在的工作。</strong></li>
<li><strong>threshold算法来确定阈值</strong></li>
</ul>
<p>6、有值得阅读的相关文献吗</p>
<p><strong>在table 7中，Song et.
al[13]的效果也很好，可以去阅读一下，文章是20年的文章</strong></p>
<p>7、综合评价如何？</p>
<p>8、用于定量评估的数据集是什么？代码有没有开源？</p>
<p>数据集为：</p>
<figure>
<img data-src="./NovelADS/image-20231008125436132.png" alt="image-20231008125436132">
<figcaption aria-hidden="true">image-20231008125436132</figcaption>
</figure>
<p>9、下一步呢？有什么工作可以继续深入？</p>
<ul>
<li><strong>本文中的攻击场景只有三种，可以考虑更多的攻击场景，然后进行实验</strong></li>
<li><strong>接着改善模型架构，以获得更好的性能or更短的时延。</strong></li>
</ul>
<p>文章标题是：一种用于车内网的新型的异常检测网络</p>
<p>关键字：</p>
<ul>
<li>车内网，应该是车的内部的一些部件来进行信息通信</li>
<li>异常检测网络：网络指的是ML里的网络，然后研究的目标是来进行异常检测</li>
</ul>
<h3 id="introduction">introduction</h3>
<p>在introduction里，作者吹了一下前人的成果，并且在最后一段中立下了flag
&amp; method：</p>
<ul>
<li><p>使用的是<strong>无监督学习</strong>来提取CAN报文的特征，并且能够防御<strong>零日攻击</strong></p></li>
<li><p>用的是CNN &amp;
LSTM组合，CNN用来提取CAN报文中的空间信息，LSTM用来处理序列数据</p></li>
<li><p>提出了新的阈值方法，这个阈值是这样的到的：当传入流量数据时，对误差进行重构，根据重构误差得到阈值。此方法跟模型没有任何关系。</p></li>
<li><p>使用precision、recall、F1
score这几个指标，来比较不同模型的性能。还测量了预测、分类花费的时间，可以在真实世界中使用。</p></li>
</ul>
<h3 id="real-work">real work</h3>
<p>首先介绍了两种入侵检测系统：</p>
<ul>
<li>基于签名的检测系统
<ul>
<li>基于签名的方法只能监测到数据库中现有的攻击类型（这是在大量的有label的数据的情况下），对于新型的攻击是不可用的。</li>
</ul></li>
<li>异常检测系统
<ul>
<li>基于异常检测的方法，是一种无监督的方法，仅仅需要知道普通报文数据的行为，然后画出基准线，在基准线之外的就归类为异常报文</li>
</ul></li>
</ul>
<p>然后介绍了一下别人的成果：基于机器学习的和传统的方法。由于车流量数据的增长，也有一些人用DL来处理这个问题，并且大部分效果比之前的ML或者是传统方法好。最后作者做了个总结：“this
technique involves using handcrafted features, which require a lot of
domain
expertise.”这也是监督学习的一个很大的问题，需要专业领域知识（领域专家）+AI工程师来合理解决问题。</p>
<h3 id="background">background</h3>
<p>介绍CAN、CNN、LSTM。。。</p>
<h4 id="can">CAN</h4>
<p>CAN是车内的ECU（电子控制单元）通信用的协议，然后典型的CAN报文如下：</p>
<figure>
<img data-src="./NovelADS/image-20231007191251030.png" alt="image-20231007191251030">
<figcaption aria-hidden="true">image-20231007191251030</figcaption>
</figure>
<p>值得注意的是，尽管CAN的格式是公开的，但是其语义每个厂商各不相同，并且有的是不公开的。</p>
<h4 id="cnn">CNN</h4>
<p>对于文本数据，用的是一维的卷积层来提取空间特征。</p>
<p>上面提到了CAN的语义不能够确切的知道，因此这里使用CNN来提取潜在的空间特征。</p>
<h4 id="lstm">LSTM</h4>
<p>没什么新意。</p>
<h3 id="detection-scenario-and-data-pre--processing">detection scenario
and data pre- processing</h3>
<p>讲整体架构、检测场景、以及数据预处理</p>
<h4 id="检测场景">检测场景</h4>
<p>假设，攻击者既可以物理接入，也能够远程接入，来对系统发起攻击。</p>
<p>那么ADS是这样工作的：捕获一段序列数据，扔进训练好的模型里，然后得到结果，整个架构、工作流如下：</p>
<figure>
<img data-src="./NovelADS/image-20231007200325055.png" alt="image-20231007200325055">
<figcaption aria-hidden="true">image-20231007200325055</figcaption>
</figure>
<p>可以看到，序列进入模型，出来的就是正常or异常结果。本质就是一个二分类模型。</p>
<h4 id="数据预处理">数据预处理</h4>
<p>首先作者介绍了一下其使用的数据集，是第34篇文章中用到的数据集。然后其组成包括正常的CAN报文以及异常的报文，异常报文有一下几类：</p>
<ul>
<li>DOS</li>
<li>fuzzy attack</li>
<li>spoofing attack
<ul>
<li>RPM Gauge Spoofing</li>
<li>Gear Spoofing</li>
</ul></li>
</ul>
<p>异常数据被标识为T（label），正常为R</p>
<p>然后开始对原始数据集做预处理，使用的是滑动窗口的方法。<del>一般的CAN报文长度为100bit，设置窗口为50bit，原始数据通过窗口将变成很多等长（50bit）的数据，如果这些等长数据中包含的异常数据部分大于一半，那么就为anomaly，反之为normal。</del></p>
<p>这里有个疑问，按上面说，输入到模型中的数据长度应该是50，但是架构图中与处理部分，<del>出来的数据是100的，9个通道</del>
（<strong>正确答案是，将100条报文拼在一起，如果异常的大于一半，那么鉴定为anomaly</strong>）。后面看代码找找答案。</p>
<p>看了下代码，里面怎么对数据进行预处理：</p>
<ul>
<li>首先就是需要将原始数据都压缩到0～1之间，数据集中大部分都做好了，只有index=1的还是16进制的格式，并且没有进行归一化</li>
<li>压缩之后，取出id，以及d[0]~d[7]（有效载荷）这9个index，这时预处理已经基本完成，数据的shape为(19776,
100, 9)</li>
<li>使用train test split</li>
</ul>
<h3 id="methodology">methodology</h3>
<p>本文所选的方法有一个很重要的假设：异常数据和正常数据能够通过阈值来分开。</p>
<h4 id="时间序列模型架构的选取">时间序列模型架构的选取</h4>
<p>作者进行了几个架构的对比：</p>
<ul>
<li>M1: LSTM</li>
<li>M2: CNN+LSTM</li>
<li>M3: LSTM+LSTM</li>
<li>M4: CNN+LSTM+LSTM</li>
</ul>
<h4 id="训练阶段">训练阶段</h4>
<p>两个目的：</p>
<ul>
<li>模型权重的训练</li>
<li>阈值的确定</li>
</ul>
<p>阈值的选定根据下面的公式来的： <span class="math display">\[
threshold=\mu _{genuine}+K*\sigma _{genuine}
\]</span> K是用网格搜索法搜索出来的，从0～10，步长为0.025</p>
<h3 id="experiment-result-and-analysis">Experiment result and
analysis</h3>
<p>作者选取的异常为正例，然后下面是三个指标： <span class="math display">\[
P=\frac{TP}{TP+FP} \\
R=\frac{TP}{TP+FN} \\
\phi=\frac{2PR}{P+R}
\]</span></p>
<p>这三个指标：</p>
<figure>
<img data-src="./NovelADS/image-20231008130748714.png" alt="image-20231008130748714">
<figcaption aria-hidden="true">image-20231008130748714</figcaption>
</figure>
<p>后面作者分析的时候，也是很看重<span class="math inline">\(\phi\)</span>这个指标。</p>
<h4 id="dos-attack">Dos attack</h4>
<p>洪泛攻击使得ECU之间无法通信。</p>
<p>具体做法是：<strong>让整个网络中充满着高优先级的报文</strong>。这样那些低优先级的报文就会饿死。</p>
<p>实验结果表明M2表现最好。</p>
<h4 id="fuzzy-attack">Fuzzy attack</h4>
<p>发送ID、数据有效载荷、长度的随机组合，使得系统不能正常工作。</p>
<p>M2最好</p>
<h4 id="spoofing-attack">Spoofing attack</h4>
<p>注入这样的异常报文：具有特定ID的报文。这样系统就无法识别哪条报文是正常的了。</p>
<p>M2最好。</p>
<h4 id="analysis">analysis</h4>
<p>将本文中的几个模型进行了对比，然后跟存在的工作进行了对比：</p>
<figure>
<img data-src="./NovelADS/image-20231008122218737.png" alt="image-20231008122218737">
<figcaption aria-hidden="true">image-20231008122218737</figcaption>
</figure>
<p>目前看来效果是非常好的，感觉没有什么可以提升的空间了。。。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/09/02/EasyRL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/02/EasyRL/" class="post-title-link" itemprop="url">EasyRL</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-09-02 11:07:15" itemprop="dateCreated datePublished" datetime="2023-09-02T11:07:15+08:00">2023-09-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-11 09:18:32" itemprop="dateModified" datetime="2023-10-11T09:18:32+08:00">2023-10-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/EasyRL/" itemprop="url" rel="index"><span itemprop="name">EasyRL</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>EasyRL</p>
<h1 id="绪论">绪论</h1>
<h2 id="强化学习概述">强化学习概述</h2>
<p>以智能体（agent）为对象：agent从环境中获取状态s以及奖励r（这在时间<span class="math inline">\(t_0\)</span>没有），然后做出一个决策a，agent需要极大化奖励r</p>
<p>环境（environment）：接受agent的决策a，输出下一个s和r</p>
<figure>
<img data-src="./EasyRL/截屏2023-09-02%2009.05.37.png" alt="截屏2023-09-02 09.05.37">
<figcaption aria-hidden="true">截屏2023-09-02 09.05.37</figcaption>
</figure>
<pre><code>RL和监督学习（supervised learning）有很大区别：</code></pre>
<table>
<colgroup>
<col style="width: 40%">
<col style="width: 59%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">SL</th>
<th style="text-align: center;">RL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">数据有label</td>
<td style="text-align: center;">没有label，只有奖励（delay）</td>
</tr>
<tr class="even">
<td style="text-align: center;">假设数据服从iid</td>
<td style="text-align: center;">前后数据有很强的关联性</td>
</tr>
<tr class="odd">
<td style="text-align: center;">学习器根据label来对修正预测</td>
<td style="text-align: center;">learner需要不断探索、利用，以极大化奖励</td>
</tr>
<tr class="even">
<td style="text-align: center;">最好的效果是和人一样</td>
<td style="text-align: center;">效果没有上限</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">agent的action会影响后来的数据</td>
</tr>
</tbody>
</table>
<p>强化学习的应用：</p>
<ul>
<li>DeepMind走路的智能体</li>
<li>机械臂抓取，学习到一个统一的抓取算法</li>
<li>OpenAI机械臂玩魔方</li>
<li>穿衣股的智能体</li>
</ul>
<figure>
<img data-src="./EasyRL/截屏2023-09-02%2009.52.11.png" alt="截屏2023-09-02 09.52.11">
<figcaption aria-hidden="true">截屏2023-09-02 09.52.11</figcaption>
</figure>
<h2 id="序列决策">序列决策</h2>
<p>上一节中说的状态s，也可以称为<strong>观测（observation）</strong>，简称o，智能体最终的目标就是，<strong>从这些观测中学到能够极大化奖励的策略</strong>。</p>
<p>这里对状态s和观测做一个区分：</p>
<ul>
<li>状态是对世界的完整描述</li>
<li>观测是对状态的部分描述</li>
</ul>
<p>也就是说，环境输出状态，智能体得到观测，这中间是有<strong>信息损失</strong>的。</p>
<p>奖励是环境给智能体的一种反馈信号，能够显示智能体在某一步的决策效果如何。但是这个奖励往往是延后的（delay
reward），很可能是在一局游戏结束之后才能反馈给agent。</p>
<p>下面能够更清楚的阐述状态和观测。</p>
<p>可以把历史看作观测、动作、奖励的序列： <span class="math display">\[
H_t=o_1,a_1,r_1,...,o_t,a_t,r_t
\]</span> 整个游戏的状态可以表述为： <span class="math display">\[
s_t=f(H_t)
\]</span> 环境有环境的函数<span class="math inline">\(s_t^e\)</span>来更新状态，而智能体也有智能体的函数<span class="math inline">\(s_t^a\)</span>更新状态。当智能体和环境能够互相观察到对方的所有状态时，称这个环境是<strong>完全可观测的（fully
observed）</strong>。<span class="math inline">\(o_t=s_t^a=s_t^e\)</span>，这时将强化学习建模为一个马尔可夫决策过程。</p>
<p>但是大部分情况智能体只能得到局部的状态，这时环境为<strong>部分可观测的</strong>。将我们的模型建为<strong>部分可观测马尔可夫决策过程</strong>，这是马尔可夫决策过程的一个泛化。自动驾驶就是这样的，智能体能观测到车上的所有的传感器的信息，并不能得到全部的环境的信息。</p>
<h2 id="动作空间">动作空间</h2>
<p>动作空间指的是：在给定环境中，agent可采取的有效动作的集合。分两类：</p>
<ul>
<li>离散动作空间：简单迷宫只有东南西北四个方向</li>
<li>连续动作空间：复杂迷宫机器人可以360度旋转</li>
</ul>
<h2 id="智能体的组成成分">智能体的组成成分</h2>
<h3 id="策略函数">策略函数</h3>
<p>策略的定义：策略是智能体的动作模型。</p>
<p>在实现上，策略是一个函数，输入为状态，输出为动作。有两种策略：</p>
<ul>
<li>随机性策略：<span class="math inline">\(\pi\)</span>函数，输入一个状态，输出智能体所有动作的概率（0.7向左，0.3向右），对于某一种状态，随机性策略会按照某种特定的概率分布来进行action</li>
<li>确定性策略：对于一种状态，输出总是确定的。</li>
</ul>
<p>通常采用随机性策略，这样能让智能体更好的探索环境，尤其是在多个智能体的情况下。</p>
<h3 id="价值函数">价值函数</h3>
<p>价值函数反应当前的状态的好坏，可以使用Q函数。</p>
<h3 id="模型">模型</h3>
<p>模型指的是对环境进行建模，而不是我们训练出来的深度学习的模型。</p>
<p>模型决定下一步的状态，模型的输入为：当前的状态以及智能体采取的动作；输出为：下一步的状态。</p>
<p><strong>策略+价值函数+模型=马尔可夫决策过程。</strong></p>
<p>有两种RL：</p>
<ul>
<li>基于策略的强化学习（policy-based
RL）：当智能体已经学好整个环境后，在每一个状态都能得到最佳的action</li>
<li>基于价值的强化学习（value-based
RL）：每一步的决策跟价值函数有关系，每一步都是以价值函数为导向。</li>
</ul>
<h2 id="智能体的类型">智能体的类型</h2>
<h3 id="policy-or-value-based">policy or value based</h3>
<p>通过对智能体是学习价值还是策略，我们还可以对智能体进行划分：</p>
<ul>
<li>value-based agent：显式学习价值函数，隐式学习策略
<ul>
<li>value-based：不会学习策略（显），会维护一张价值表或者价值函数，使得我们的长期价值能够最大化。</li>
<li>一般在离散环境下进行使用（如俄罗斯方块，围棋）</li>
</ul></li>
<li>policy-based agent：直接学习策略
<ul>
<li>policy-
based：RL会不断对策略进行优化，使得对于每一个状态，都能做出能够获得最大奖励的决策。</li>
<li>在工业机器人这种连续环境下一般使用policy based</li>
</ul></li>
<li>演员-评论员智能体（actor-critic agent）：同时学习价值和策略
<ul>
<li>二者同时进行，可以加速学习过程。</li>
</ul></li>
</ul>
<p>policy based和value based分别有其学习算法，policy based
使用的是基于梯度的，梯度策略算法（policy gradient，PG）；而value
based则是使用的Q算法（Q-learning）</p>
<h3 id="model-based">model based</h3>
<p>根据agent有没有学习环境模型来进行分类：</p>
<ul>
<li>model-based：会通过学习环境状态的转移来采取动作
<ul>
<li>model
based需要知道环境的<strong>状态转移函数</strong>以及奖励函数，这样就能推断出在采取某一action后会带来的reward和下一个state。因此，model
based 可以在一个虚拟环境中使用，而不需要在真实环境中进行学习。</li>
</ul></li>
<li>model-free：智能体没有得到环境的转移，只通过学习价值函数和策略函数来进行决策
<ul>
<li>但是在实际应用中，智能体很难知道环境状态转移函数（还是自动驾驶的例子，智能体只能知道有限个传感器的数据，并不能知道环境的所有状态），因此大多数情况下我们使用的是model
free</li>
</ul></li>
</ul>
<figure>
<img data-src="./EasyRL/截屏2023-09-04%2017.25.58.png" alt="截屏2023-09-04 17.25.58">
<figcaption aria-hidden="true">截屏2023-09-04 17.25.58</figcaption>
</figure>
<h2 id="学习和规划">学习和规划</h2>
<p>learning和planning，分别考虑下面两个场景：</p>
<ul>
<li>在不知道环境时，智能体要一直和环境交互，来改进策略。这是一个学习过程。</li>
</ul>
<figure>
<img data-src="./EasyRL/截屏2023-09-04%2017.33.37.png" alt="截屏2023-09-04 17.33.37">
<figcaption aria-hidden="true">截屏2023-09-04 17.33.37</figcaption>
</figure>
<ul>
<li>在智能体能够知道环境中的所有信息时，智能体能够计算出一个完美的模型，然后去做决策。这是一个规划过程。</li>
</ul>
<figure>
<img data-src="./EasyRL/截屏2023-09-04%2017.33.54.png" alt="截屏2023-09-04 17.33.54">
<figcaption aria-hidden="true">截屏2023-09-04 17.33.54</figcaption>
</figure>
<p>我们可以先让智能体跟环境交互，学到一个虚拟环境后，再在环境中进行计算，做决策。</p>
<h2 id="探索和利用">探索和利用</h2>
<p>关于探索和利用：</p>
<ul>
<li>探索：指的是智能体去探索环境，通过不断的试错，来发现哪些动作可以带来奖励。</li>
<li>利用：利用好目前已知的动作，来获得奖励。</li>
</ul>
<p>这里有一个问题：是<strong>长期奖励</strong>还是<strong>短期奖励</strong>。对于当前环境，智能体的已知动作空间中，已经有动作能够带来不错的奖励时，这时智能体是选择探索还是利用呢？我们需要权衡利弊。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在赛车游戏中，赛车可以通过吃道具来加分，吃完了道具会隔段时间刷新。有可能会出现这种情况：智能体一直在原地兜圈，等待道具刷新...</span><br></pre></td></tr></table></figure>
<h1 id="马尔可夫决策过程">马尔可夫决策过程</h1>
<h2 id="markov-process">Markov process</h2>
<h3 id="markov-property">Markov property</h3>
<p>在给定过去状态以及现在状态的情况下，未来的状态仅依赖于当前状态（只取决于现在）</p>
<h3 id="markov-chain">Markov chain</h3>
<p>Markov chain满足Markov property，可以用以下公式来描述： <span class="math display">\[
h_t={s_1, ...,s_t} \\
p(s_{t+1}|h_t)=p(s_{t+1}|s_t)
\]</span> 也就是说，从历史中去推未来，和从当前状态推未来是等价的。</p>
<p>从<span class="math inline">\(s_t\)</span>转移到<span class="math inline">\(s_{t+1}\)</span>，和从过去转移到<span class="math inline">\(s_{t+1}\)</span>是等价的。</p>
<p>离散的Markov process 称为Markov chain，如下图所示：</p>
<p><img data-src="./EasyRL/截屏2023-09-04 19.26.14.png" alt="截屏2023-09-04 19.26.14" style="zoom: 50%;"></p>
<p>上图中有四个状态，s1有0.1的概率转移到其本身，有0.2的概率转移到s2，有0.7的概率转移的到s4。</p>
<p>可以用<strong>状态转移矩阵P</strong>来描述状态转移<span class="math inline">\(p(s_{t+1}=s^{&#39;}|s_t=s)\)</span></p>
<p><img data-src="./EasyRL/截屏2023-09-04 19.30.02.png" alt="截屏2023-09-04 19.30.02" style="zoom:33%;"></p>
<p>状态转移矩阵表示的是当前从状态<span class="math inline">\(s_t\)</span>到状态<span class="math inline">\(s_{t+1}\)</span>的所有概率</p>
<h2 id="markov-reward-process">Markov reward process</h2>
<p>MRP是Markov chain+reward function。</p>
<p>奖励reward，用<strong>R</strong>表示，如果状态有限，可以把R写成一个向量。</p>
<h3 id="return-and-value-function">return and value function</h3>
<p>horizon定义为范围，表示的是一个回合的长度（也就是采集一次轨迹，要采集多远）。</p>
<p>return则是定义为奖励的逐步叠加，称为<strong>回报</strong>，用G表示。</p>
<p><span class="math inline">\(\gamma\)</span>是折扣因子，会对后面的奖励进行折扣。</p>
<p>假设现在是时间t，t之后的奖励序列为：<span class="math inline">\(r_{t+1},r_{t+2}..\)</span>，那么回报为： <span class="math display">\[
G_t=r_{t+1}+\gamma r_{t+2}+\gamma ^2r_{t+2}+...
\]</span>
上面这个式子表示我们更希望得到现在的奖励，以后得到的奖励都会大打折扣。</p>
<p>这个回报也称为折扣回报（discounted
return），当有了折扣回报后，可以定义状态的价值，也就是<strong>状态价值函数</strong>（state-
value function）： <span class="math display">\[
V^t(s)=E(G_t|s_t=s)
\]</span> State-value
function表示的<strong>是智能体进入某个状态后，未来能够获得的奖励。</strong></p>
<p>使用折扣因子的理由：</p>
<ul>
<li>有些Markov process是带环的，这样可以避免智能体一直进入环内</li>
<li>不能完美模拟环境、对未来的评估不一定准确、不能完全信任模型。这种不确定性导致我们需要<span class="math inline">\(\gamma\)</span></li>
<li>更希望现在获得奖励，但是也可以调整<span class="math inline">\(\gamma\)</span>，例如设置成0表示只关心当下奖励，设置成1表示未来的奖励没有打折扣。<span class="math inline">\(\gamma\)</span>是一个超参数。</li>
</ul>
<p>可以用向量来表示奖励函数，例如进入s1会得到奖励5，s7会得到奖励10，其他状态无奖励：
<span class="math display">\[
R=[5,0,0,0,0,0,10]
\]</span> 然后设置好<span class="math inline">\(\gamma=0.5\)</span>后，就能通过采样得到回报return：</p>
<p><img data-src="./EasyRL/截屏2023-09-05 10.17.38.png" alt="截屏2023-09-05 10.17.38" style="zoom:33%;"></p>
<p>得到return后，还没有得到value
function，我们可以吧以s4开头的所有轨迹都加起来取平均值（期望），以这个值来衡量进入状态s4的价值。这种计算价值函数的方法称为：蒙特卡洛（MonteCarlo，MC）采样。</p>
<h3 id="bellman-equation">bellman equation</h3>
<p>bellman equation的推导如下：</p>
<p><img data-src="./EasyRL/截屏2023-09-05 13.54.23.png" alt="截屏2023-09-05 13.54.23" style="zoom: 33%;"></p>
<ul>
<li>其中从第四行到第五行的原因：<strong>回报的期望是等于回报的期望的期望</strong>。或者说是全期望公式：</li>
</ul>
<p><span class="math display">\[
E[V(s_{t+1}|s_t)]=E[E[G_{t+1}|s_{t+1}]|s_t]=E(G_{t+1}|s_t)
\]</span></p>
<ul>
<li>第五行到第六行的原因是：<span class="math inline">\(E[X]=\sum_{\\i}E[X|A_i]p(A_i)\)</span></li>
</ul>
<p>bellman equation的表示如下： <span class="math display">\[
V(s)=R(s)+\gamma \sum _{s^{&#39;}\epsilon S}p(s^{&#39;}|s)V(s^{&#39;})
\]</span>
第一个式子是表示的即时奖励，第二个式子表示的是未来奖励的折扣总和，<span class="math inline">\(s^{&#39;}\)</span>表示的是未来的某个状态，<span class="math inline">\(p(s^{&#39;}|s)\)</span>表示的是当前状态转移到未来状态的概率。</p>
<p>bellman
equation表示的就是当前状态的价值。也可以说是当前状态和未来状态的迭代关系。</p>
<p>将其写成矩阵形式如下：</p>
<figure>
<img data-src="./EasyRL/截屏2023-09-05%2010.28.56.png" alt="截屏2023-09-05 10.28.56">
<figcaption aria-hidden="true">截屏2023-09-05 10.28.56</figcaption>
</figure>
<p>这个方程可以得到其解析解（analytic solution） <span class="math display">\[
V=R+\gamma PV \\
V=(E-\gamma P)^{-1}R
\]</span>
数学可解，但是让计算机去算比较困难，这个过程的时间复杂度是<span class="math inline">\(O(N^3)\)</span>，当状态非常多时是算不出来的。</p>
<h3 id="计算mrp价值的迭代算法">计算MRP价值的迭代算法</h3>
<p>这个价值，默认就是<strong>状态价值</strong>了。</p>
<ul>
<li>蒙特卡洛方法（基于<strong>采样</strong>）</li>
<li>bellman equation（基于<strong>动态规划</strong>）</li>
<li>时序差分学习（TD learning）</li>
</ul>
<p>蒙特卡洛方法就是上面讲的那样，以当前状态出发，在一个horizon内，找出若干真实轨迹（可能是1000），然后求均值，作为当前状态的value。</p>
<p><img data-src="./EasyRL/截屏2023-09-05 10.40.09.png" alt="截屏2023-09-05 10.40.09" style="zoom: 33%;"></p>
<p>而bellman
equation则是通过不断的自举（bootstrapping），直到方程收敛（当前状态和上一个状态差别不大）</p>
<p><img data-src="./EasyRL/截屏2023-09-05 10.41.55.png" alt="截屏2023-09-05 10.41.55" style="zoom:33%;"></p>
<h2 id="markov-decision-process">Markov decision process</h2>
<p>马尔可夫决策过程，即MDP，是MRP+decision。状态转移的条件也变了： <span class="math display">\[
p(s_{t+1}=s^{&#39;}|s_t=s,a_t=a)
\]</span>
未来的状态不仅仅取决于当前的状态，还取决于当前智能体采取的动作。</p>
<p>奖励函数R也是一样，之前的奖励函数就是一个向量，每个状态对应一个奖励。现在奖励函数还取决于动作：
<span class="math display">\[
R(s_t=s,a_t=a)=E[r_t|s_t=s,a_t=a]
\]</span></p>
<h3 id="policy-in-mdp">policy in MDP</h3>
<p>将当前状态带入策略函数，既可以得出下一步该采取什么动作，输出值为一个概率
<span class="math display">\[
\pi (a|s)=p(a_t=a|s_t=s)
\]</span> 这个概率表示的就是某一个决策的概率是多少。</p>
<p>那么当我们已知策略函数<span class="math inline">\(\pi\)</span>时，就可以得到新的转移函数的表达式了，这个新的状态转移函数（下式的左边）中去掉了a，也就是得到了一个MRP的转移。</p>
<p>式子(13)sum的里面，左边是采取某个动作的概率，右边是在状态s以及采取这个动作的条件下，转移到新状态的概率。所以左边本质上也是一个求期望的过程，对状态求期望。
<span class="math display">\[
P_{\pi} (s^{&#39;}|s)=\sum _{a\epsilon A}\pi (a|s)p(s^{&#39;}|s,a)
\]</span> 同理，奖励函数也是如此： <span class="math display">\[
R_{\pi}(s)=\sum _{a\epsilon A}\pi (a|s)R(s,a)
\]</span></p>
<h3 id="mdp和mpmrp的区别">MDP和MP/MRP的区别</h3>
<p>MRP/MP（下图左）可以根据当前的状态，加上状态转移函数，直接得出下一个状态是什么；而MDP则多了一层决策函数，根据当前的状态，选出一个决策，然后再在这个决策的基础上，通过状态转移函数，得出下一步的状态。也就是说，智能体做出的决策会决定未来的状态转移</p>
<figure>
<img data-src="./EasyRL/截屏2023-09-05%2012.22.10.png" alt="截屏2023-09-05 12.22.10">
<figcaption aria-hidden="true">截屏2023-09-05 12.22.10</figcaption>
</figure>
<h3 id="mdp的value-function">MDP的value function</h3>
<p>MDP的state-value function定义： <span class="math display">\[
V_{\pi}(s)=E_{\pi}[G_t|s_t=s]
\]</span> 其中的期望取决于智能体采取的决策。</p>
<p>引入Q函数（Q-
function），也称为<strong>动作价值函数</strong>（action- value
function）：</p>
<ul>
<li><strong>在某一个状态，采取某一个动作a，可能得到的回报的一个期望</strong></li>
</ul>
<p><span class="math display">\[
Q_{\pi}(s,a)=E_{\pi}[G_t|s_t=s,a_t=a]
\]</span></p>
<p>PS：上面的动作价值函数的计算方法，和之前MRP求状态价值函数的算法一样，都是利用蒙特卡洛采样，采集到许多真实轨迹，然后求出这些真实轨迹的回报G，最后求均值。不同的是，之前MRP只有状态，没有动作；现在MDP使用了策略函数，需要输出一个动作，期望里面的是，当我们时间点t采取的某个动作，对其求期望，得到的其实是动作价值函数Q，最后还要根据策略进行加和。这也正是下面求和的理由。</p>
<p>这个动作价值函数其实也是基于智能体采取的某一个动作的，所以需要做一个加和：
<span class="math display">\[
V_{\pi}=\sum_{a\epsilon A}\pi (a|s)Q_{\pi}(s,a)
\]</span> 对Q函数的bellman equation进行推导：</p>
<p><img data-src="./EasyRL/截屏2023-09-05 14.01.38.png" alt="截屏2023-09-05 14.01.38" style="zoom:33%;"></p>
<h3 id="bellman-expectation-equation">bellman expectation equation</h3>
<p>将状态价值函数（V）和动作价值函数（Q）进行分解，可得到下式：</p>
<p><img data-src="./EasyRL/截屏2023-09-05 14.13.21.png" alt="截屏2023-09-05 14.13.21" style="zoom:33%;"></p>
<p>上式展示了动作价值函数之间的迭代关系。</p>
<h3 id="备份图">备份图</h3>
<p>备份图的核心：当前的价值是和未来的价值是线性相关的。</p>
<p>这个价值可以是动作价值Q，或者是状态价值V（如下图）</p>
<p><img data-src="./EasyRL/截屏2023-09-06 14.22.47.png" alt="截屏2023-09-06 14.22.47" style="zoom:33%;"></p>
<p>上图中，根结点代表的是当前状态、以及当前状态具有的价值；根结点下面的是动作结点，代表的是后面可能采取的一个动作；再往下是采取这个动作之后，状态发生改变，进入新的状态<span class="math inline">\(s^{&#39;}\)</span>。</p>
<h3 id="策略评估">策略评估</h3>
<p>策略评估又称为<strong>价值预测</strong>，也就是计算<span class="math inline">\(V\)</span>的过程。</p>
<p>PS：为何取这个名字，其意义是--评估我们选取的某一个策略能带来多少价值。所以也可以叫价值预测。</p>
<p>对于MDP，可以看做是有人在小船上划船，每一个状态必定会采取一个动作；对于MP/MRP，则是一个纸船在水里面飘。两者的区别在于前者是有智能体来做决策的。</p>
<p>对于MDP，选定一个策略，计算出奖励函数R，然后带入bellman方程里面不断进行迭代，直到<span class="math inline">\(V\)</span>收敛，我们便可得到当下的价值。</p>
<h3 id="预测控制">预测&amp;控制</h3>
<p>这其实是两类问题：</p>
<ul>
<li>预测：预测指的是，在给定一个MDP以及策略函数<span class="math inline">\(\pi\)</span>时，能够计算出所有状态的价值，也就是求出<span class="math inline">\(V\)</span></li>
<li>控制：控制则是指给定MDP，但不给定策略，需要计算出最佳价值函数<span class="math inline">\(V^{*}\)</span>以及最佳策略<span class="math inline">\(\pi ^{*}\)</span></li>
</ul>
<p>可以看出两者是递进的，要想解决控制问题，需要先解决预测问题。</p>
<h3 id="策略迭代">策略迭代</h3>
<p>策略迭代：首先我们拥有一个初始的策略<span class="math inline">\(\pi\)</span>，然后根据这个策略可以得到状态价值函数<span class="math inline">\(V_{\pi}\)</span>，然后根据Q函数的公式，通过极大化Q函数，来找到一个更优的策略<span class="math inline">\(\pi
^{&#39;}\)</span>，如此迭代下去，便能找到最佳的策略以及状态价值函数。</p>
<p><img data-src="./EasyRL/image-20230916091250670.png" alt="image-20230916091250670" style="zoom:33%;"></p>
<p>策略迭代是基于贪心策略的。</p>
<p>下面是策略迭代的步骤：</p>
<ul>
<li>初始化策略<span class="math inline">\(\pi\)</span>，通过贝尔曼方程，算出价值函数<span class="math inline">\(V_{\pi}\)</span></li>
</ul>
<p><img data-src="./EasyRL/image-20230919173023190.png" alt="image-20230919173023190" style="zoom:50%;"></p>
<ul>
<li>根据状态价值函数，利用动作价值函数的贝尔曼方程的推导，得到动作价值函数</li>
</ul>
<p><img data-src="./EasyRL/image-20230919172752528.png" alt="image-20230919172752528" style="zoom:50%;"></p>
<ul>
<li>最后对<span class="math inline">\(Q_{\pi}\)</span>使用arg
max操作符</li>
</ul>
<p><img data-src="./EasyRL/截屏2023-09-19 17.28.58.png" alt="截屏2023-09-19 17.28.58" style="zoom:50%;"></p>
<h3 id="价值迭代">价值迭代</h3>
<p>价值迭代使用的是贝尔曼方程，不断的对<span class="math inline">\(V\)</span>进行迭代，直到其收敛。这样我们得到的就是一个最优的价值函数了。</p>
<p>...</p>
<h1 id="表格型方法">表格型方法</h1>
<p>蒙特卡洛、Q学习和Sarsa都是表格型方法。</p>
<h2 id="model-based-model-free">model-based &amp; model-free</h2>
<p>这里进一步解释免模型和有模型。最大的特点从下图就可以看出了</p>
<p><img data-src="./EasyRL/image-20230916094420973.png" alt="image-20230916094420973" style="zoom:33%;"></p>
<ul>
<li>有模型</li>
</ul>
<p>model-based的条件是知道<strong>概率转移函数P以及奖励函数R</strong>，知道这个，我们就可以说这个MDP是已知的了。在知道P和R的条件下，我们可以直接通过策略迭代/价值迭代来求解这个MDP，而不需要跟环境交互啊进行探索或者利用。</p>
<ul>
<li>免模型</li>
</ul>
<p>model-free适用于我们生活中大多数场景：书中的情景，在野外看到一头熊，我们其实是不知道转移概率以及奖励函数的，这时就只能通过试错来进行学习了。</p>
<p>当<strong>模型很大或者模型未知</strong>的时候，我们不得不采用model-free来解决问题。</p>
<h2 id="q表格">Q表格</h2>
<p>假设Q表格是一张已经训练好的表格，那么他应该长下面这样：</p>
<p><img data-src="./EasyRL/image-20230916100807256.png" alt="image-20230916100807256" style="zoom:50%;"></p>
<p>这张图片表示，在当前的状态s下，采取动作a，能够获取多少的长期奖励。</p>
<p>至于长期奖励or短期奖励，这里有一个很生动的例子：闯红灯</p>
<ul>
<li>在我们日常开车中，闯一次红灯，需要罚款扣分，仅仅是时间快了一点，惩罚&gt;奖励。</li>
<li>假设对象是医院的救护车，那么闯红灯的奖励就大于它的惩罚了，送病人那自然是越快越好，所以奖励&gt;&gt;惩罚</li>
</ul>
<p>这里就可以看出，长期奖励是优于短期奖励的。但也不能一味的追求长期奖励，考虑买股票的情景，假设十年之后股票会迎来一次大涨价，那么肯定不能仅仅考虑长期价值（为了十年后的价值），也要考虑当下时间点附近的价值。因此回到了之前，引入了折扣因子<span class="math inline">\(\gamma\)</span></p>
<p>回到Q表格，智能体每走一步，更新一次Q表格，这种单步更新的方法称为：时序差分方法。</p>
<h2 id="免模型预测">免模型预测</h2>
<h3 id="蒙特卡洛策略评估">蒙特卡洛策略评估</h3>
<p>蒙特卡洛是基于采样的方法，也叫MC采样。具体操作是：选取策略<span class="math inline">\(\pi\)</span>，在真实世界中不断的进行采样，然后得到很多轨迹。最后计算出这些轨迹的回报，相加取均值，得到的就是<strong>采取策略<span class="math inline">\(\pi\)</span>时当前状态具有的价值</strong>。</p>
<p>这种方法有局限性，只能用于有终止的MDP。另外，这里还用到了大<strong>数定理</strong>：<strong>重复次数的实验的算术平均有很高的概率接近期望值</strong></p>
<p>在对蒙特卡洛的公式推导之前，先做一个增量均值的变换： <span class="math display">\[
\mu_t=\frac{1}{t}\sum_1^tx_i \\
=\frac{1}{t}(x_t + \sum_i^{t-1}x_i) \\
=\frac{1}{t}(x_t + t\mu_{t-1}-\mu_{t-1}) \\
=\mu_{t-1}+\frac{1}{t}(x_t-\mu_{t-1})
\]</span> 这样就得了当前均值和当前值以及上一时刻的均值的关系了：<span class="math inline">\(\mu_t=\mu_{t-1}+\frac{1}{t}(x_t-\mu_{t-1})\)</span></p>
<p>我们将蒙特克罗方法也写成这种方式，称为<strong>蒙特卡洛均值</strong>：</p>
<p><img data-src="./EasyRL/image-20230916114122709.png" alt="image-20230916114122709" style="zoom:50%;"></p>
<p>将前面的分数系数计作学习率：</p>
<p><img data-src="./EasyRL/image-20230916114219478.png" alt="image-20230916114219478" style="zoom:50%;"></p>
<p>对比动态规划方法，蒙特卡洛方法的优势在于：</p>
<ol type="1">
<li>Model-free</li>
<li>相比于动态规划，计算量小</li>
</ol>
<p>缺点：</p>
<ul>
<li>只能用于horizon已知的情况</li>
</ul>
<h3 id="时序差分">时序差分</h3>
<p>从巴普洛夫的条件反射实验讲起，经过铃声强化后，小狗认为铃声之后会带来价值（肉），于是小狗在听到铃声之后，就会流口水。人也是一样，在第一次看到熊、熊扑过来、人被熊咬伤...到下一次人再看见熊，会直接产生恐惧的感觉（这时还没有被咬伤，但已经被强化过了），甚至到后面人没有看到熊，但是看到了熊掌，也会产生恐惧。</p>
<p>上面就是一个one-step TD的过程。</p>
<p>下面再来介绍时序差分方法，其和蒙特卡洛很像，蒙特卡洛需要采样很多<strong>真实轨迹</strong>之后，对这些轨迹求<strong>真实回报</strong>，然后更新价值；而时序差分方法最小可以走一步（<strong>采样</strong>），然后计算<strong>估计回报</strong>，并且更新价值（<strong>自举</strong>）。</p>
<p>单步时序差分，TD(1)，每走一步，就用得到的估计回报，来更新价值，这个过程就是一次自举。</p>
<p><img data-src="./EasyRL/image-20230916140521653.png" alt="image-20230916140521653" style="zoom:50%;"></p>
<p>估计回报被称为<strong>时序差分目标（TD-
target）</strong>，它是由下一步得到的真实奖励以及对未来奖励的一个折扣。</p>
<p>PS： <span class="math display">\[
G_t=r_{t+1}+\gamma r_{t+2}+\gamma ^2r_{t+3}+... \\
G_t^1=r_{t+1}+\gamma G_{t+1}\approx r_{t+1}+\gamma V_{t+1}
\]</span> 时序差分方法有这些优点，使得它更加实用：</p>
<ol type="1">
<li>运用了MP性质，也就是后续状态只跟当前有关</li>
<li>可以使用在<strong>没有终止</strong>的环境下</li>
<li>可以在不完整的序列上进行学习</li>
<li>TD可以在线学习，可以每走几步更新一次，而蒙特卡洛则需要游戏结束的时候，再进行更新。</li>
</ol>
<p>当步数趋近于无穷的时候，TD就会退化成MC。</p>
<p><img data-src="./EasyRL/image-20230916141206633.png" alt="image-20230916141206633" style="zoom:50%;"></p>
<p>这个G就是估计回报，也是TD-target。</p>
<p>另外，TD运用了MP性质，所以在MDP下有很好的效率，而MC没有运用MP性质，只是运用了采样，因此在马尔可夫环境下运用TD还是比较好的，但是非马尔可夫环境，可以考虑MC。</p>
<h2 id="免模型控制">免模型控制</h2>
<p>在环境未知的时候（转移概率和奖励函数），无法使用策略/价值迭代方法来改进策略（或者说是动态规划的方法）。结合蒙特卡洛&amp;时序差分，可以得到<strong>广义策略迭代</strong>（GPI）。</p>
<p>这里解释一下什么是<strong>探索性开始</strong>（exploring
start）：以蒙塔卡洛为例，我们进行采样的时候，期望采样到的轨迹能够遍布整个空间，也就是尽可能采样到所有的轨迹（和大数定理是一个道理），这样我们取均值得到的回报就可以近似为当前状态的价值。这个条件就称为探索性开始。以下是原文中的一句话：<strong>探索性开始保证所有的状态和动作都在无限步的执行后能被采样到</strong>。</p>
<p>可以把Q函数看成一个Q表格，然后把采样得到的回报填入表格中，然后再依次选取不同的策略：Q表格大致如下</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">-</th>
<th style="text-align: center;"><span class="math inline">\(\pi_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\pi_2\)</span></th>
<th style="text-align: center;">...</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\((s_1,a_1,...)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(G_{11}\)</span></td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\((s_3,a_8,...
)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(G_{12}\)</span></td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
</tr>
<tr class="odd">
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
<td style="text-align: center;">...</td>
</tr>
<tr class="even">
<td style="text-align: center;">E</td>
<td style="text-align: center;"><span class="math inline">\(Q_{\pi_1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Q_{\pi_2}\)</span></td>
<td style="text-align: center;">...</td>
</tr>
</tbody>
</table>
<p>这也正是下面这个公式的体现： <span class="math display">\[
\pi(s)=arg max_aQ(s,a)
\]</span> 注：arg max操作符：当取策略<span class="math inline">\(\pi\)</span>的时候，能够使得动作价值函数Q取最大值。</p>
<p><span class="math inline">\(\epsilon\)</span>-贪心探索：有<span class="math inline">\(1-\epsilon\)</span>的概率会按照Q函数来采取动作，另外的概率采取的是随机动作，确保足够的探索。</p>
<p>在最开始的时候，我们并不知道哪一个动作比较好，所以刚开始的<span class="math inline">\(\epsilon\)</span>会比较大，随着时间的增大，<span class="math inline">\(\epsilon\)</span>会慢慢变小。</p>
<h3 id="sarsa同策略时序差分控制">Sarsa：同策略时序差分控制</h3>
<p>Sarsa算法跟简单，就是将原本的时序差分中的更新V的过程换成了更新Q的过程：</p>
<p><img data-src="./EasyRL/截屏2023-09-18 20.10.06.png" alt="截屏2023-09-18 20.10.06" style="zoom:50%;"></p>
<p>TD-traget，时序差分目标，意思就是我们想要逼近的那个目标值。我们这里使用的是one-step
TD的思想，所以叫one-step Sarsa，只需知道<span class="math inline">\(s_t,a_t,r_{t+1},s_{t+1},a_{t+1}\)</span>即可。</p>
<p>给其加上<span class="math inline">\(\lambda\)</span>得到了<span class="math inline">\(Sarsa(\lambda)\)</span>，看不太懂。</p>
<h3 id="q学习异策略时序差分控制">Q学习：异策略时序差分控制</h3>
<p>Sarsa其实还是用的时序差分的思想，直接通过上面的式子来更新策略。这样到最后Q收敛了，得到的是一个确定的策略（尽管我们可能是有一定的概率采取这个策略），这属于是<strong>同一个策略</strong>。</p>
<p>而Q学习有两个策略：</p>
<ul>
<li><span class="math inline">\(\pi\)</span>：目标策略，指的是我们需要去学习的策略。一般直接采取<strong>贪心策略</strong></li>
<li><span class="math inline">\(\mu\)</span>：行为策略，负责去探索环境，将采集到的轨迹投喂给<span class="math inline">\(\pi\)</span>，并且采集到的数据不需要<span class="math inline">\(a_{t+1}\)</span>。可以采取随机策略，但更好的选择是<span class="math inline">\(\epsilon\)</span>-贪心策略</li>
</ul>
<p><img data-src="./EasyRL/截屏2023-09-18 20.39.01.png" alt="截屏2023-09-18 20.39.01" style="zoom:50%;"></p>
<h1 id="策略梯度">策略梯度</h1>
<p>在model-free中，状态转移以及奖励都是由环境决定的，我们的agent可以和环境进行交互，但是能够改进的只有我们的策略本身。这一章中，我们可以就将智能体以及策略看成一个神经网络，然后输入我们的观测，得到动作作为输出。</p>
<p>假设参数为<span class="math inline">\(\theta\)</span>的策略为<span class="math inline">\(\pi _{\theta}\)</span>。</p>
<h2 id="策略梯度算法">策略梯度算法</h2>
<p>强化学习的三个组成：</p>
<ul>
<li>演员（actor）</li>
<li>环境</li>
<li>奖励函数</li>
</ul>
<p><img data-src="./EasyRL/截屏2023-09-20 12.37.58.png" alt="截屏2023-09-20 12.37.58" style="zoom:50%;"></p>
<p>演员其实就是之前的agent，更进一步的说，其实就是我们的策略函数。将策略函数看成一个网络，网络中有很多参数，将这些参数计作<span class="math inline">\(\theta\)</span>，可以对参数进行训练。</p>
<p>一般而言，我们并不会使用RNN来进行训练（尽管这可能更符合一般的逻辑，但那样会比较麻烦，RNN处理连续的图像可能会有相当大的计算量），反而使用的是类似CNN的网络，接受一张图片作为输入，有几个动作，就有几个输出神经元。（这可能并不适用于连续动作空间的问题）。</p>
<p>同理，我们可以讲环境也看作是一个神经网络，尽管它可能是一个rule-based的模型。环境接受actor的动作，然后输出state给actor，如此反复。知道到达环境的终止条件（例如打游戏时，所有的小怪都已经被消灭）。</p>
<p>在这个回合中，可以得到状态和动作组成的整个轨迹： <span class="math display">\[
\tau = \{s_1,a_1,s_2,a_2,...,s_t,a_t\}
\]</span> 在给定策略的参数<span class="math inline">\(\theta\)</span>后，我们便可以计算出这条轨迹发生的概率了：</p>
<p><img data-src="./EasyRL/截屏2023-09-20 12.54.33.png" alt="截屏2023-09-20 12.54.33" style="zoom: 50%;"></p>
<p>上面算出的这条轨迹的概率取决于环境以及智能体采取的动作。</p>
<p>而环境是我们无法控制的，所以只能通过改变智能体的动作，也就是策略，来得到更好的轨迹。（长期奖励最大）</p>
<p>至于奖励函数，以游戏为例子，当agent采取一个动作后，环境输出一个状态，这时我们就可以得到一个奖励r了，r也取决于我们采取的动作a。待到游戏结束后，我们将所有的r加到一起，就得到了轨迹<span class="math inline">\(\tau\)</span>的奖励：<span class="math inline">\(R(\tau)\)</span></p>
<p>在一个horizon结束之后，我们得到了轨迹的奖励，然后就可以来优化我们的策略参数<span class="math inline">\(\theta\)</span>了。</p>
<p>另外，虽然说轨迹的奖励是一个标量值，但是其实其还是一个随机变量，因为轨迹的产生是取决于我们的动作的，是有一定的概率产生这个轨迹，于是，对其求期望：</p>
<p><img data-src="./EasyRL/image-20230920130856256.png" alt="image-20230920130856256" style="zoom:50%;"></p>
<p>我们进一步说明这个轨迹的概率是什么回事，举例：假设<span class="math inline">\(\theta\)</span>对应的模型很强，能够做出很好的决策，那么若是有一回合agent很快就死掉了，那么这种概率是相当小的；相反，智能体能够很快的结束掉游戏，这是一种相当大的概率。</p>
<p>我们要最大化这个轨迹的期望奖励。选择使用<strong>梯度上升（gradient
ascent）</strong>的方法。</p>
<p>我们对期望求微分：</p>
<p><img data-src="./EasyRL/image-20230920140719345.png" alt="image-20230920140719345" style="zoom:50%;"></p>
<p>然后利用这个性质：</p>
<p><img data-src="./EasyRL/image-20230920140746494.png" alt="image-20230920140746494" style="zoom:50%;"></p>
<p>得到：</p>
<p><img data-src="./EasyRL/截屏2023-09-20 14.08.17.png" alt="截屏2023-09-20 14.08.17" style="zoom:50%;"></p>
<p>然后再做变换：</p>
<p><img data-src="./EasyRL/image-20230920140913045.png" alt="image-20230920140913045" style="zoom:50%;"></p>
<p>实际上上面这个最终的期望无法计算，所以我们选择使用采样的方式：</p>
<p><img data-src="./EasyRL/image-20230920142307309.png" alt="image-20230920142307309" style="zoom:50%;"></p>
<p>右半部分的计算方式：</p>
<p><img data-src="./EasyRL/image-20230920142729662.png" alt="image-20230920142729662" style="zoom:50%;"></p>
<p>更新梯度的方式为：</p>
<p><img data-src="./EasyRL/image-20230920144424148.png" alt="image-20230920144424148" style="zoom:50%;"></p>
<p>更新的意义是：假设我们在训练时，发现在状态<span class="math inline">\(s_t\)</span>后执行动作<span class="math inline">\(a_t\)</span>，然后得到的<span class="math inline">\(\tau\)</span>的奖励是正的，那么我们就会修改<span class="math inline">\(\pi
_\theta\)</span>的参数，调高这个概率；反之，就会调低这个概率。</p>
<p>在训练过程中，智能体会不断和环境进行交互，得到很多的状态-动作对，然后拿来训练。训练完之后，这些数据将会被丢弃，智能体继续和环境进行交互。。。</p>
<p>上述以梯度上升的方法来更新策略参数，正是我们之前CNN中用的updater。</p>
<p>然后最后就是损失函数（目标函数）的确定了。损失函数用的是最小化交叉熵。</p>
<h2 id="蒙塔卡洛策略梯度">蒙塔卡洛策略梯度</h2>
<p>也就是REINFORCE算法，REINFORCE算法用的是<strong>回合更新</strong>的方式（正如其名蒙特卡洛，每次更新单位是一个horizon）。</p>
<p>这个算法大致过程：在一个horizon内，获取每个步骤的reward，知道horizon结束。然后计算每个步骤的回报，带入到下面的公式中去，从而能够优化每一个动作。</p>
<p><img data-src="./EasyRL/截屏2023-09-20 20.45.10.png" alt="截屏2023-09-20 20.45.10" style="zoom:50%;"></p>
<p>从代码上来讲，我们完成一个回合后，从最后一个动作开始，算出其回报，然后向前递归，得到前一个动作的回报，以此类推，知道<span class="math inline">\(G_1\)</span>。</p>
<p><img data-src="./EasyRL/截屏2023-09-20 20.48.00.png" alt="截屏2023-09-20 20.48.00" style="zoom:50%;"></p>
<h1 id="近端策略优化">近端策略优化</h1>
<h2 id="重要性采样">重要性采样</h2>
<p>前言：上一章中提到的策略梯度上升，是对应的之前学习到的<strong>同策略</strong>。同策略有一个不好的点，当我们根据策略<span class="math inline">\(\pi _{\theta}\)</span>采集到大量轨迹之后，对<span class="math inline">\(\theta\)</span>进行更新之后，变成了<span class="math inline">\(\theta
^{&#39;}\)</span>，这时之前采集到的数据就不管用了，我们需要重新采集数据。也就是说，使用<strong>同策略</strong>的方法的时候，大部分时间我们是在采集大量的、不可复用的数据。</p>
<p>假设是<strong>异策略</strong>，有一个策略<span class="math inline">\(\theta\)</span>负责更新，另一个策略<span class="math inline">\(\theta
^{&#39;}\)</span>负责采集数据，和环境交互，那么就可以采集一次数据，多次进行更新。具体的方法就是<strong>重要性采样</strong>。</p>
<p>考虑这样的情况：我们需要从分布p采样x，然后求f(x)的期望，但是我们不能直接从分布p采样，只能从另一个分布q采样，于是可以做一下变换：</p>
<p><img data-src="./EasyRL/image-20230921093351256.png" alt="image-20230921093351256" style="zoom:50%;"></p>
<p>于是：</p>
<p><img data-src="./EasyRL/image-20230921093418352.png" alt="image-20230921093418352" style="zoom:50%;"></p>
<p>称<span class="math inline">\(\frac{p(x)}{q(x)}\)</span>为<strong>重要性权重</strong>。</p>
<p>上述过程就是<strong>重要性采样</strong>。</p>
<p>但是q分布的选取还是有限制的：</p>
<ul>
<li>p和q的差距不能太大，具体表现在方差上</li>
</ul>
<p>首先给出方差公式：<span class="math inline">\(Var[X]=E[X^2]-(E[X]^2)\)</span></p>
<p>然后看经过重要性采样两个分布的均值虽然相同，方差却有差异：</p>
<p><img data-src="./EasyRL/image-20230921094228980.png" alt="image-20230921094228980" style="zoom:50%;"></p>
<p>虽然我们是计算期望，并不计算方差。但是，假设q和p差距非常大，但是我们可以实现exploring
start，也就是能够采样到所有的x，那么期望其实还是一样的；但是exploring
start是理想情况，现实中我们可能只能采样到一部分，在这种方差较大的情况下，我们最终得到的期望可能差别也非常大。</p>
<figure>
<img data-src="./EasyRL/截屏2023-09-21%2009.49.50.png" alt="截屏2023-09-21 09.49.50">
<figcaption aria-hidden="true">截屏2023-09-21 09.49.50</figcaption>
</figure>
<p>如上图，按照原分布p来采样，得到的期望应该是负的；但若是按照q分布采样，在这种p、q差距非常大的情况下，假设采样次数少，全部采样到右边了，那么最终算出的期望就是正的了，这种问题想要解决只能通过增加采样次数来解决了，但是这是很麻烦的一件事。</p>
<p>回归到异策略中，<span class="math inline">\(\theta\)</span>就是p，<span class="math inline">\(\theta ^{&#39;}\)</span>就是q，于是：</p>
<p><img data-src="./EasyRL/image-20230921095638011.png" alt="image-20230921095638011" style="zoom:50%;"></p>
<p>在实际做策略梯度的时候，并不是对整个奖励都做一个加和，而是会单独算某一个状态动作对<span class="math inline">\((s_t,a_t)\)</span>，如下：</p>
<p><img data-src="./EasyRL/image-20230921100436205.png" alt="image-20230921100436205" style="zoom:50%;"></p>
<p><span class="math inline">\(A^{\theta}(s_t,a_t)\)</span>即是用累计奖励减去基线baseline，若是为正，就调高概率</p>
<p>经过重要性采样，换了分布，那么就在前面加上一个修正项<span class="math inline">\(\frac{p_{\theta}(s_t,a_t)}{p_{\theta
^{&#39;}}(s_t,a_t)}\)</span>：</p>
<figure>
<img data-src="./EasyRL/image-20230921101622477.png" alt="image-20230921101622477">
<figcaption aria-hidden="true">image-20230921101622477</figcaption>
</figure>
<p>上面用到了一个假设：假设两个策略的A是差不多的。</p>
<p>然后再做一个假设，两个策略看到<span class="math inline">\(s_t\)</span>的概率是差不多的：</p>
<figure>
<img data-src="./EasyRL/image-20230921102938686.png" alt="image-20230921102938686">
<figcaption aria-hidden="true">image-20230921102938686</figcaption>
</figure>
<p>参考一下下面的解释：</p>
<figure>
<img data-src="./EasyRL/image-20230921103152512.png" alt="image-20230921103152512">
<figcaption aria-hidden="true">image-20230921103152512</figcaption>
</figure>
<p>最终要优化的目标函数：？</p>
<figure>
<img data-src="./EasyRL/image-20230921103602015.png" alt="image-20230921103602015">
<figcaption aria-hidden="true">image-20230921103602015</figcaption>
</figure>
<h2 id="近端策略优化-1">近端策略优化</h2>
<p>也称<strong>PPO</strong>，PPO要解决的就是两个分布相差太大的问题</p>
<p>我们在训练的时候，给目标函数加了一个约束，称KL<strong>散度</strong>，这一项用来衡量两个策略的相似程度，我们希望两个策略尽可能相似，有点像正则化。</p>
<p>PPO是同策略算法，因为其行为策略和目标策略很相似。尽管PPO用到了重要性采样。</p>
<figure>
<img data-src="./EasyRL/image-20230921104133435.png" alt="image-20230921104133435">
<figcaption aria-hidden="true">image-20230921104133435</figcaption>
</figure>
<p>KL散度的输入是<span class="math inline">\(\theta\)</span>和<span class="math inline">\(\theta
^{&#39;}\)</span>，然后再代入一个状态s，得到两套动作作为输出，然后计算这两个动作的差距。我们计算的并不是参数之间的距离（<strong>参数距离</strong>），而是两个网络输出的结果，最后得到的行为上的差异（<strong>行为距离</strong>）</p>
<p>至于为什么不直接计算参数距离，是因为我们更关心的是行为距离。参数变化一点或者变化很多对行为的影响是不确定的。</p>
<p>PPO有两个变种如下：</p>
<ul>
<li>PPO惩罚</li>
<li>PPO裁剪</li>
</ul>
<h3 id="ppo--penalty">PPO- penalty</h3>
<p>具体做法就是，每次更新时，用前一个时刻的演员<span class="math inline">\(\theta
^k\)</span>去跟环境交互，然后得到数据，然后对当前的演员<span class="math inline">\(\theta\)</span>可以进行多次更新，想方设法最大化目标函数。</p>
<figure>
<img data-src="./EasyRL/image-20230921105753969.png" alt="image-20230921105753969">
<figcaption aria-hidden="true">image-20230921105753969</figcaption>
</figure>
<p>然后这个<span class="math inline">\(\beta\)</span>的设计也是有规则的：</p>
<ol type="1">
<li>首先设置一个可以接受的最大的KL散度，然后完成一次优化。然后用优化后的策略和之前的策略做一次KL散度，若是这个散度大于我们设置的max，那么代表惩罚力度不够，需要增大<span class="math inline">\(\beta\)</span></li>
<li>设置一个可以接受的最小的KL散度，完成一次优化。若是优化后的KL散度小于min，那么认为惩罚效果太强了，因此选择增大<span class="math inline">\(\beta\)</span></li>
</ol>
<h3 id="ppo-clip">PPO-clip</h3>
<p>POP-clip算法的目标函数是：</p>
<figure>
<img data-src="./EasyRL/image-20230921131336961.png" alt="image-20230921131336961">
<figcaption aria-hidden="true">image-20230921131336961</figcaption>
</figure>
<p>clip函数的意思是：</p>
<ul>
<li><p>若第一项小于第二项，输出第二项</p></li>
<li><p>若第一项大于第三项，输出第三项</p></li>
<li><p>若介于之间，则输出本身</p></li>
</ul>
<figure>
<img data-src="./EasyRL/image-20230921131538520.png" alt="image-20230921131538520">
<figcaption aria-hidden="true">image-20230921131538520</figcaption>
</figure>
<p>最终得到的目标函数的图如下：</p>
<ul>
<li>绿线是<span class="math inline">\(\frac{p_{\theta}}{p_{\theta
^k}}\)</span></li>
<li>蓝线是clip</li>
<li>红线是最终的结果</li>
</ul>
<h1 id="深度q网络">深度Q网络</h1>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/07/31/d2l/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/07/31/d2l/" class="post-title-link" itemprop="url">d2l</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-07-31 11:07:15" itemprop="dateCreated datePublished" datetime="2023-07-31T11:07:15+08:00">2023-07-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-27 15:58:34" itemprop="dateModified" datetime="2023-10-27T15:58:34+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/d2l/" itemprop="url" rel="index"><span itemprop="name">d2l</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>d2l</p>
<h1 id="经典qa">经典QA</h1>
<h2 id="问题1.怎么根据输入空间选择最优的深度或者宽度">问题1.怎么根据输入空间，选择最优的深度或者宽度</h2>
<p>假设问题背景：128 input，2 output</p>
<ol type="1">
<li>首先尝试线性回归模型，128输入2输出，不要隐藏层。</li>
<li>然后试试mlp（多层感知机）：128 input -&gt; 128/64/32/16/8 hide -&gt;
2
output。然后在此基础上挑出比较好的隐藏层个数，比如128和8不行，然后64/32/16效果都还不错。</li>
<li>再试试加一个隐藏层，比如128 -&gt; 64 -&gt; 16 -&gt; 2，或者: 128
-&gt; 32 -&gt; 8 -&gt; 2。多跑几轮。</li>
</ol>
<p>多调几次就有经验了。</p>
<h2 id="问题2.k折交叉验证的目的是确定超参数吗然后还要用这个超参数再训练一遍全数数据吗">问题2.k折交叉验证的目的是确定超参数吗？然后还要用这个超参数再训练一遍全数数据吗？</h2>
<p>有三种做法：</p>
<ul>
<li>先在train set上训练，然后再用valid set上进行k折交叉验证，来选去hyper
parameter，最后再在train set上训练w和b。</li>
<li>在train set上训练后，使用valid set进行k折验证，然后直接选hyper
parameter，不训练了，直接作测试。</li>
<li>最贵的一种做法：在k折验证后，得到k个模型，在测试一个样本的时候，k个模型每个模型都跑一遍结果，最后进行平均/投票。</li>
</ul>
<p>PS：测试集我们可能拿不到label。</p>
<h2 id="问题3.老师说的神经网络是一种语言意思是利用神经网络去对万事万物建模吧就是指的它理论上能拟合所有函数">问题3.老师说的神经网络是一种语言，意思是利用神经网络去对万事万物建模吧？就是指的它理论上能拟合所有函数？</h2>
<p>理论上来讲，只有一个隐藏层的、神经元足够多的mlp，就能够拟合所有的函数。但是，训练不出来，因此有了下面几种（原话：我知道mlp能拟合你，但是mlp训练不出来，所以我要做一个好的结构，来帮助你训练）：</p>
<ul>
<li>cnn：假设数据是有空间信息的</li>
<li>rnn：假设数据是有时序信息的</li>
<li>...</li>
</ul>
<p>我们引入先验，增加偏好，因此有了新的模型，试图帮出mlp去训练。</p>
<p>很多时候，我们都是先有一个想法/理由，然后就去做了，很多优秀的论文也是这样，刚开始有个想法，但大部分都是错的，只不过满满的做最后的效果还不错。</p>
<p>三种元素：</p>
<ul>
<li>艺术：无法解释，就是比较好</li>
<li>工程：能有一套详细的流程</li>
<li>科学：能够解释</li>
</ul>
<p>神经网络，我们希望他是科学，但做起来是工程，实际上其中百分之五十都是艺术。可能</p>
<p>可能若干年后有人能科学的解释dl，但是，蒸汽机发明之后，100年后才出现了热力学。</p>
<h2 id="问题4.如果训练是不平衡的是否要先考虑测试集是否也是不平衡的再去决定是否使用一个平衡的验证集">问题4.如果训练是不平衡的，是否要先考虑测试集是否也是不平衡的，再去决定是否使用一个平衡的验证集？</h2>
<p>周志华老师讲过，可以通过加权来使得正类负类平衡，比如银行卡贷款，10000人中，5个人没有还款。</p>
<p>在李沐老师这里听到了新的做法：</p>
<ul>
<li>如果采样的数据是独立同分布的，也就是说，现实世界中就是这样分布的，那么其实就直接训练就行了，做好90%的正类，另外10%的负类尽量做好</li>
<li>如果采样不是独立同分布，那么就需要加权了。</li>
</ul>
<p>这里其实也引入了人为的偏好，采样数据在真实世界中究竟是如何分布，这个很难去界定。</p>
<h2 id="问题5.老师为什么对16位浮点影响严重32位或者64位就好了吗那就是说所有通过fp16加速或者减小模型的方法都存在容易梯度爆炸或者消失的风险">问题5.老师，为什么对16位浮点影响严重？32位或者64位就好了吗？那就是说所有通过fp16加速或者减小模型的方法都存在容易梯度爆炸或者消失的风险？</h2>
<p>芯片大小一般是固定的，但是一个64位的浮点单元的面积是16位浮点单元的面积的4倍，因此16位浮点运算的速度也比64位浮点运算的速度快4倍。</p>
<p>另一方面，16位浮点更容易发生上溢或者下溢，所以加速/减小模型更容易出现梯度消失或者爆炸。</p>
<h2 id="问题6.这几个超参数得影响重要程度排序是怎样得核大小填充步幅">问题6.这几个超参数得影响重要程度排序是怎样得，核大小，填充，步幅</h2>
<p>卷积神经网络中有kernel_size、填充、步幅三个超参数，首先给出结论：<strong>核大小最重要</strong></p>
<p>整个CNN就是在训练核大小，所以这个是最重要的。</p>
<p>然后就是步幅和填充了。</p>
<ul>
<li>填充主要是为了让我们的输入和输出的形状保持一致</li>
<li>而步幅一般选1或者2，再往上就取决于模型的复杂度了。当步幅为1时，每次我们的输出会比输入小一个维度，也就是说是<strong>线性的</strong>；而当将我们的步幅调成2，相当于一次就把我们的输入砍了一半，也就是说是<strong>指数下降</strong>的。当我们的输入太大时，在某几层增大步幅合一使得我们的输出直接少一个量级。</li>
</ul>
<p>比如，在CNN中我们要做100层的网络，然后我们通过计算要除几次，最后就可以把这几个折半砍的层均匀的插在中间；其余的层都是通过填充使得输入和输出是一样的维度。</p>
<h1 id="环境">环境</h1>
<h2 id="安装环境">安装环境</h2>
<p>pip清华源：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
<p>使用ubuntu22.04后，添加源后，可以通过apt来安装具体版本的python了：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:deadsnakes/ppa</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt install python3.8</span><br><span class="line">sudo apt install python3.8-distutils</span><br></pre></td></tr></table></figure>
<p>安装好后，可以通过下面的指令来找到安装后的位置：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">which</span> python3.8</span><br></pre></td></tr></table></figure>
<p>然后由于aarch64使用conda有问题，所以就换了一种虚拟环境方案，使用的是：virtualenv+virtualenvwrapper。</p>
<p>操作就三个</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">chengyiqiu@chengyiqiu:~/Envs$ <span class="built_in">which</span> python3.8</span><br><span class="line">/usr/bin/python3.8</span><br><span class="line">chengyiqiu@chengyiqiu:~/Envs$ virtualenv -p /usr/bin/python3.8 d2l</span><br><span class="line">created virtual environment CPython3.8.17.final.0-64 <span class="keyword">in</span> 1184ms</span><br><span class="line">  creator CPython3Posix(dest=/home/chengyiqiu/Envs/d2l, clear=False, no_vcs_ignore=False, global=False)</span><br><span class="line">  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/chengyiqiu/.local/share/virtualenv)</span><br><span class="line">    added seed packages: pip==23.2.1, setuptools==68.0.0, wheel==0.41.0</span><br><span class="line">  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator</span><br><span class="line">chengyiqiu@chengyiqiu:~/Envs$ <span class="built_in">ls</span></span><br><span class="line">d2l  py38</span><br><span class="line">chengyiqiu@chengyiqiu:~/Envs$ <span class="built_in">source</span> ./d2l/bin/activate</span><br><span class="line">(d2l) chengyiqiu@chengyiqiu:~/Envs$</span><br></pre></td></tr></table></figure>
<p>发现使用pip装包时会报错：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">p.linux-aarch64-cpython-38/psutil/_psutil_common.o</span><br><span class="line">      psutil/_psutil_common.c:9:10: fatal error: Python.h: No such file or directory</span><br><span class="line">          9 | <span class="comment">#include &lt;Python.h&gt;</span></span><br><span class="line">            |          ^~~~~~~~~~</span><br><span class="line">      compilation terminated.</span><br><span class="line">      psutil could not be installed from sources. Perhaps Python header files are not installed. Try running:</span><br><span class="line">        sudo apt-get install gcc python3-dev</span><br><span class="line">      error: <span class="built_in">command</span> <span class="string">&#x27;/usr/bin/aarch64-linux-gnu-gcc&#x27;</span> failed with <span class="built_in">exit</span> code 1</span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">  ERROR: Failed building wheel <span class="keyword">for</span> psutil</span><br><span class="line">Failed to build psutil</span><br><span class="line">ERROR: Could not build wheels <span class="keyword">for</span> psutil, <span class="built_in">which</span> is required to install pyproject.toml-based projects</span><br></pre></td></tr></table></figure>
<p>然后尝试安装：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3.8-dev</span><br></pre></td></tr></table></figure>
<p>成功了！</p>
<p>因此，当所有步骤为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:deadsnakes/ppa</span><br><span class="line">sudo apt-get update</span><br><span class="line"><span class="comment"># 下次创建新环境直接从这儿开始</span></span><br><span class="line">sudo apt install python3.8</span><br><span class="line">sudo apt install python3.8-distutils</span><br><span class="line">sudo apt-get install python3.8-dev</span><br></pre></td></tr></table></figure>
<p>打包requirement.txt：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip list --format=freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure>
<h2 id="开swap">开swap</h2>
<p>首先要得到在哪个盘上开swap，输入df，然后最后有/的表示有充足的空间开swap：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">chengyiqiu@chengyiqiu:~/myswapfile$ <span class="built_in">df</span> -m</span><br><span class="line">Filesystem     1M-blocks  Used Available Use% Mounted on</span><br><span class="line">tmpfs                380     4       376   1% /run</span><br><span class="line">/dev/mmcblk0p2    116950 11578    100565  11% /</span><br><span class="line">tmpfs               1896     0      1896   0% /dev/shm</span><br><span class="line">tmpfs                  5     0         5   0% /run/lock</span><br><span class="line">/dev/mmcblk0p1       253   149       104  60% /boot/firmware</span><br><span class="line">tmpfs                380     1       380   1% /run/user/1000</span><br></pre></td></tr></table></figure>
<p>然后选择mmcblk0p2：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> myswapfile</span><br><span class="line"><span class="built_in">cd</span> myswapfile/</span><br><span class="line">sudo <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/mmcblk0p2 of=swapfile bs=1G count=4</span><br><span class="line">sudo <span class="built_in">chmod</span> 600 swapfile</span><br><span class="line">sudo mkswap swapfile</span><br><span class="line">sudo swapon swapfile</span><br><span class="line">free -m</span><br><span class="line"></span><br><span class="line">               total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:            3790         494        1081           3        2213        3098</span><br><span class="line">Swap:           4095           0        4095</span><br></pre></td></tr></table></figure>
<p>在服务器上（2G memory）经历过一次pip
torch的时候被kill掉，原因就是爆内存了（OOM），这时可以通过开swap来解决。</p>
<p>做毕设的时候使用的python的后端框架flask，在读取大文件csv数据集时，也是因为OOM导致python进程被莫名其妙的杀掉了，应该也可以采取开swap的方法。</p>
<h2 id="htop">htop</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">以下是CPU度量指标的颜色编码。</span><br><span class="line"></span><br><span class="line">蓝色：显示低优先级进程使用的CPU的百分比。</span><br><span class="line"></span><br><span class="line">绿色：显示普通用户拥有的进程使用的CPU的百分比。</span><br><span class="line"></span><br><span class="line">红色：显示系统进程使用的CPU的百分比。</span><br><span class="line"></span><br><span class="line">青色：显示Steal时间使用的CPU的百分比。</span><br><span class="line"></span><br><span class="line">以下是内存度量指标的颜色编码。</span><br><span class="line"></span><br><span class="line">绿色：显示已使用内存的百分比。</span><br><span class="line"></span><br><span class="line">蓝色：显示已使用缓冲区的百分比。</span><br><span class="line"></span><br><span class="line">橙色：显示已使用缓存的百分比。</span><br><span class="line"></span><br><span class="line">以下是SWAP度量指标的颜色编码。</span><br><span class="line"></span><br><span class="line">红色：显示已使用SWAP内存的百分比。</span><br></pre></td></tr></table></figure>
<h1 id="线性神经网络">线性神经网络</h1>
<h2 id="线性回归">线性回归</h2>
<p>线性回归严格来说是一种<strong>仿射变换（affine
transformation）</strong>：将特征通过加权（乘以参数w）然后再进行线性变换，最后通过偏置项（b）进行平移。</p>
<p>对于一个特定的样本，线性回归可表示为：<img data-src="./d2l/截屏2023-07-31%2020.43.26.png" alt="截屏2023-07-31 20.43.26"></p>
<p>写成向量的形式就是（向量和向量之间的点积）：</p>
<figure>
<img data-src="./d2l/截屏2023-07-31%2020.44.01.png" alt="截屏2023-07-31 20.44.01">
<figcaption aria-hidden="true">截屏2023-07-31 20.44.01</figcaption>
</figure>
<p>dl中读入的数据集一般都是矩阵，很多样本的集合，所以可以直接写成矩阵的形式。那么就是写成向量和矩阵的乘法形式：</p>
<figure>
<img data-src="./d2l/截屏2023-07-31%2020.45.18.png" alt="截屏2023-07-31 20.45.18">
<figcaption aria-hidden="true">截屏2023-07-31 20.45.18</figcaption>
</figure>
<p>线性回归模型比较特殊，因为其有<strong>解析解</strong>，能通过数学的方法求出解的表达式：</p>
<figure>
<img data-src="./d2l/截屏2023-07-31%2021.14.07.png" alt="截屏2023-07-31 21.14.07">
<figcaption aria-hidden="true">截屏2023-07-31 21.14.07</figcaption>
</figure>
<p>这是一个模型的优化思路，但绝大部分模型没有解析解（就算有，通过数学来求得解析解可能可行，但计算量特别大）。于是我们在没有解析解的情况下，可以通过从大量数据中，使用<strong>梯度下降（gradient
descent）</strong>，得到<strong>数值解</strong>。</p>
<p>从整个数据集中随机取出一个batch
size大小的数据，然后求loss，最后再反向传播更新参数，过程如下：</p>
<ul>
<li>(1)初始化模型参数的值，如随机初始化;</li>
<li>(2)从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。对于平方损失和仿射变换，我们可以明确地写成如下形式:</li>
</ul>
<figure>
<img data-src="./d2l/截屏2023-07-31%2021.18.59.png" alt="截屏2023-07-31 21.18.59">
<figcaption aria-hidden="true">截屏2023-07-31 21.18.59</figcaption>
</figure>
<p>线性回归可以看作为单层神经网络，因为输入层不进行计算，整个网络的计算神经元只有一个，一层，所以称为单层神经网络。该网络的特征纬度为d，标签维度为1。</p>
<figure>
<img data-src="./d2l/截屏2023-07-31%2023.38.10.png" alt="截屏2023-07-31 23.38.10">
<figcaption aria-hidden="true">截屏2023-07-31 23.38.10</figcaption>
</figure>
<p>DL启发于神经学，但更多的灵感 源自数学、统计、计算机。</p>
<figure>
<img data-src="./d2l/截屏2023-07-31%2023.44.44.png" alt="截屏2023-07-31 23.44.44">
<figcaption aria-hidden="true">截屏2023-07-31 23.44.44</figcaption>
</figure>
<p>线性回归从0开始中，有一段代码是手动生成的迭代器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        batch_indices = torch.tensor(</span><br><span class="line">            indices[i: <span class="built_in">min</span>(i + batch_size, num_examples)])</span><br><span class="line">        <span class="built_in">print</span>(batch_indices) <span class="comment"># 从数据集中选取了一组batch size大小的index</span></span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices], labels[batch_indices] <span class="comment"># tensor可以采取这种读的方式，tensor里面套tensor类型的index</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">    <span class="built_in">print</span>(X, <span class="string">&#x27;\n&#x27;</span>, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>这种方式实现的迭代器能使用，但是由于是随机读取一个batch
size大小的数据，会用到很多次随机读取内存，这样有悖于<strong>局部性原理</strong>，时间较长性能较差。后续用到的框架中的迭代器就没有这个问题，</p>
<p>下面使用的代码，是利用torch中的normal函数来生成原始参数，原始参数服从正态分布，均值为0标准差为0.01，可以指定数据的维度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(<span class="number">199</span>, <span class="number">222</span>, <span class="number">123</span>, <span class="number">101</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(w)</span><br></pre></td></tr></table></figure>
<p>线性回归的简洁实现中，有这么一段代码，里面有一个*，没见过：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_array</span>(<span class="params">data_arrays, batch_size, is_train=<span class="literal">True</span></span>):  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;</span></span><br><span class="line">    dataset = data.TensorDataset(*data_arrays)</span><br><span class="line">    <span class="keyword">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train) <span class="comment"># shuffle洗纸牌，表示随机打乱</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">data_iter = load_array((features, labels), batch_size)</span><br><span class="line"></span><br><span class="line"><span class="built_in">next</span>(<span class="built_in">iter</span>(data_iter))</span><br></pre></td></tr></table></figure>
<p>这个*<strong>不能去掉</strong>，他的意义是：<strong>括号中的一个星号，表示对list解开入参，即把列表元素分别当作参数传入</strong></p>
<p>下面是一个简单的例子，输出是10：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b, c, d</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b + c + d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">arr = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(add(*arr))</span><br></pre></td></tr></table></figure>
<h2 id="softmax回归">softmax回归</h2>
<p>回归可以用来预测连续值，而分类问题也可以转化为回归问题，下面的图就可以看出，分类问题就是多了几个输出的结点。</p>
<p>回归到具体分类问题上：一张照片四个像素，可能是猫、狗、鸡。也就是：4个特征，3个标签。四个特征好量化，可以直接写成向量形式；但是标签怎么转变为数据呢，很容易就能想到[1,
2,
3]的形式，但是这样编码是有递增的自然顺序，但是显示数据中的标签并没有自然顺序，因此，采用<strong>独热编码（one
hot encoding）</strong>的形式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">猫：[1, 0, 0]</span><br><span class="line">狗：[0, 1, 0]</span><br><span class="line">鸡：[0, 0, 1]</span><br></pre></td></tr></table></figure>
<h1 id="多层感知机">多层感知机</h1>
<h2 id="感知机">感知机</h2>
<p>下面是一个4层的感知机，中间有三个隐藏层，神经元的个数分别为：5，3，2。特征维度为4，标签维度为2。</p>
<p>可以看到从输入到第一层隐藏层，是增加了1的，然后是逐层递减。也可以直接开始递减。</p>
<p>为什么要这样做，里面是有工程经验的：<strong>深度学习本质上是一个压缩信息量的过程（回顾周志华老师的机器学习的课程，信息量是在逐层递减），隐藏层有三层，神经元的个数在递减，代表着数据中的信息量也是在递减的，最终到输出层。</strong>我们可以选择：</p>
<ul>
<li>只用一个隐藏层，但神经元个数非常多，如128，256<strong>（宽度学习doge）</strong>。</li>
<li>像下图一样神经元逐渐递减，每层都学一点东西。</li>
</ul>
<p>但是层数一定不能太深，并且层与层之间的神经元个数也不能衰减太快，不然整个网络可能<strong>坍塌</strong>，丢失掉重要的信息。</p>
<figure>
<img data-src="./d2l/截屏2023-08-01%2021.53.34.png" alt="截屏2023-08-01 20.53.22">
<figcaption aria-hidden="true">截屏2023-08-01 20.53.22</figcaption>
</figure>
<p>至于最后为什么我们选择的是深度学习而不是宽度学习（浅度学习），原因就是<strong>浅度学习并不好做</strong>：</p>
<ul>
<li>从人的直观上来讲，很难一口吃个胖子，学东西都是慢慢学，所以我们的网络每层都学一点东西，最后模型收敛。</li>
<li>从计算机的角度，只用一个隐藏层就将所有信息学到，这样难度很大，很难计算出来，也很难去调度所有的神经元应该怎么学（毕竟是黑盒）。</li>
</ul>
<h2 id="激活函数">激活函数</h2>
<p>激活函数的存在使得我们的mlp不再是仿射变化套娃仿射变换，当我们使用非线性的激活函数时，我们的模型就不会退化为仿射变换了。</p>
<ul>
<li>只有隐藏层才会加激活函数，输出层不会加激活函数</li>
<li>箭头-&gt;神经元+激活函数，这属于一个隐藏层</li>
<li>箭头-&gt;输出结点，输入输出层</li>
</ul>
<p>我们的模型长这样：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2012.52.27.png" alt="截屏2023-08-04 12.52.27">
<figcaption aria-hidden="true">截屏2023-08-04 12.52.27</figcaption>
</figure>
<p>从下面这样：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2012.51.36.png" alt="截屏2023-08-04 12.51.36">
<figcaption aria-hidden="true">截屏2023-08-04 12.51.36</figcaption>
</figure>
<p>变成了：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2012.51.59.png" alt="截屏2023-08-04 12.51.59">
<figcaption aria-hidden="true">截屏2023-08-04 12.51.59</figcaption>
</figure>
<h3 id="relu">ReLU</h3>
<p>激活函数的意义在于将线性变为非线性，钟爱<strong>ReLU函数</strong>的很大一个原因是：<strong>简单</strong>。像其他两个函数里面都要做至少一次指数运算。<strong>而在CPU上，做一次指数运算的时间可以做十万次乘法运算！代价非常昂贵！</strong>而GPU中有相应的运算单元，比CPU就好很多了。</p>
<p>ReLU的函数图如下：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2012.58.14.png" alt="截屏2023-08-04 12.58.14">
<figcaption aria-hidden="true">截屏2023-08-04 12.58.14</figcaption>
</figure>
<p>可以看到ReLU在0点不可导，我们默认使用0点的倒数为0（其实介于0和1之间都可以，对于这种边界的不可导点）但是，现实中不会出现输入为0的情况，有一句谚语：<strong>如果微妙的边界条件很重要，我们很可能是在研究数学而非工程</strong>。</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2013.01.52.png" alt="截屏2023-08-04 13.01.52">
<figcaption aria-hidden="true">截屏2023-08-04 13.01.52</figcaption>
</figure>
<p>ReLU还有一些变体：即使参数是负的，某些信息仍然可以通过</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2013.03.06.png" alt="截屏2023-08-04 13.03.06">
<figcaption aria-hidden="true">截屏2023-08-04 13.03.06</figcaption>
</figure>
<h3 id="sigmoid">sigmoid</h3>
<p>表达式： <span class="math display">\[
sigmoid(x)=\frac{1}{1+e^{-x}}
\]</span> 图：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2013.07.18.png" alt="截屏2023-08-04 13.07.18">
<figcaption aria-hidden="true">截屏2023-08-04 13.07.18</figcaption>
</figure>
<figure>
<img data-src="./d2l/截屏2023-08-04%2012.51.36-1125646.png" alt="截屏2023-08-04 12.51.36">
<figcaption aria-hidden="true">截屏2023-08-04 12.51.36</figcaption>
</figure>
<p>sigmoid有一个特性是：求导之后刚好可以表达成正例*反例 <span class="math display">\[
\frac{d}{dx}sigmoid(x)=sigmoid(x)*(1-sigmoid(x))
\]</span> 导数图像：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2013.12.16.png" alt="截屏2023-08-04 13.12.16">
<figcaption aria-hidden="true">截屏2023-08-04 13.12.16</figcaption>
</figure>
<h3 id="tanh">tanh</h3>
<p>表达式： <span class="math display">\[
tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}}
\]</span> 图：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2013.13.56.png" alt="截屏2023-08-04 13.13.56">
<figcaption aria-hidden="true">截屏2023-08-04 13.13.56</figcaption>
</figure>
<p>导数： <span class="math display">\[
\frac{d}{dx}tanh(x)=1-tanh^2(x)
\]</span></p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2013.14.59.png" alt="截屏2023-08-04 13.14.59">
<figcaption aria-hidden="true">截屏2023-08-04 13.14.59</figcaption>
</figure>
<h2 id="模型选择欠拟合过拟合">模型选择、欠拟合、过拟合</h2>
<p>用于对抗过拟合的技术叫做<strong>正则化</strong>。</p>
<h3 id="统计学习理论">统计学习理论</h3>
<p>一般情况我们假设我们抽取的数据是服从独立同分布的，也就是说2、3样本存在的相关性并不比2、200000两个样本的相关性强（和索引、抽取顺序无关）。但是这种假设很容易就被推翻，很容易找到假设失效的情况。</p>
<p>如果我们根据从加州大学旧金山分校医学中心的患者数据训练死亡风险预测模型，
并将其应用于马萨诸塞州综合医院的患者数据，结果会怎么样？
这两个数据的分布可能不完全一样<strong>（可能有空间相关）</strong>。
此外，抽样过程<strong>可能与时间有关</strong>。
比如当我们对微博的主题进行分类时，
新闻周期会使得正在讨论的话题产生时间依赖性，从而违反独立性假设。</p>
<h3 id="模型复杂性">模型复杂性</h3>
<p><strong>对于一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号（label），都存在一个模型来对它进行完美分类</strong></p>
<p>可以计算出线性分类器的VC维：</p>
<figure>
<img data-src="./d2l/截屏2023-08-04%2015.12.36.png" alt="截屏2023-08-04 15.12.36">
<figcaption aria-hidden="true">截屏2023-08-04 15.12.36</figcaption>
</figure>
<p>模型容量和数据大小的关系如下：</p>
<ul>
<li>模型容量很低（比较简单），但是数据集比较大时，其实是学不到什么东西的，所以是<strong>欠拟合</strong></li>
<li>模型容量很高（神经元多，复杂），但是数据集比较小的时候，就很容易把噪声学进去，也就是容易<strong>过拟合</strong>。</li>
</ul>
<p>一般第二种情况比较常见，也就是很容易过拟合：比如给一组线性的数据，然后放入三四层的感知机里面去训练，很容易就把噪声当作数据的规律了，导致过拟合。</p>
<figure>
<img data-src="./d2l/截屏2023-08-02%2014.46.35.png" alt="截屏2023-08-02 14.46.35">
<figcaption aria-hidden="true">截屏2023-08-02 14.46.35</figcaption>
</figure>
<p>模型容量还可以定义为：拟合各种函数的能力。</p>
<p>下面对于同样的数据集，左边的模型比较简单，因此只学到了线性；而右边的模型比较复杂，学成了一个非常复杂的函数。</p>
<p>但事实上，这些数据服从的是一个二次函数的分布，</p>
<p>因此，从数据集的大小上我们能够感受到数据的复杂与否，然后再选择合适的模型来训练。</p>
<figure>
<img data-src="./d2l/截屏2023-08-02%2014.50.41.png" alt="截屏2023-08-02 14.50.41">
<figcaption aria-hidden="true">截屏2023-08-02 14.50.41</figcaption>
</figure>
<figure>
<img data-src="./d2l/截屏2023-08-03%2009.27.21.png" alt="截屏2023-08-03 09.27.21">
<figcaption aria-hidden="true">截屏2023-08-03 09.27.21</figcaption>
</figure>
<p>最后是书中的经验，哪些因素会影响模型泛化：</p>
<ol type="1">
<li>可调整参数的数量。<strong>当可调整参数的数量（有时称为<em>自由度</em>）很大时，模型往往更容易过拟合</strong>。</li>
<li>参数采用的值。<strong>当权重的取值范围较大时，模型可能更容易过拟合</strong>。</li>
<li>训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。<strong>PS：也就是说还是得根据数据来选择模型</strong></li>
</ol>
<h3 id="验证集">验证集</h3>
<p>神经网络中的w和b是在train
set上训练出来的，而神经网络层数、神经元个数则是我们指定的超参数（这些东西对我们的模型容量有影响）。调整超参数有助于我们得到更适合我们数据的模型。</p>
<p>但是train set是用来调整参数，test
set是用来测试训练出来的模型，都不好直接拿来调整超参数。因此，在数据集上再次划分一块出来，作为验证集，用来调整超参数。</p>
<p>因此，将我们的数据分成三份，
除了训练和测试数据集之外，还增加一个<em>验证数据集</em>（validation
dataset）， 也叫<em>验证集</em>（validation set）</p>
<h3 id="欠拟合和过拟合">欠拟合和过拟合</h3>
<p>下面是原书中的观点，在现实训练中的过拟合和欠拟合。</p>
<p>当我们比较训练和验证误差时，我们要注意两种常见的情况。
首先，我们要注意这样的情况：训练误差和验证误差都很严重，
但它们之间仅有一点差距。
如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足），
无法捕获试图学习的模式。
此外，由于我们的训练和验证误差之间的<em>泛化误差</em>很小，
我们有理由相信可以用一个更复杂的模型降低训练误差。
这种现象被称为<em>欠拟合</em>（underfitting）。</p>
<p>另一方面，当我们的训练误差明显低于验证误差时要小心，
这表明严重的<em>过拟合</em>（overfitting）。
注意，<em>过拟合</em>并不总是一件坏事。 特别是在深度学习领域，众所周知，
最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。
最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。</p>
<h2 id="权重衰减">权重衰减</h2>
<h3 id="范数">范数</h3>
<p>一般使用L2范数来约束w，作为特征向量的惩罚。在原本的loss上，加上L2范数
<span class="math display">\[
L(w,b)+\frac{\lambda}{2}||w||^2
\]</span> 当<span class="math inline">\(\lambda=0\)</span>时，恢复成了原来的损失函数；当$&gt;<span class="math inline">\(0时，就会对w进行惩罚：\)</span>$
w&lt;-(1-n)w-_{}x<sup>{i}(w</sup>Tx<sup>{(i)}+b-y</sup>{(i)}) $$
表现出来就是：如果w变大太大了，那么L2范数就会把往小了拉。</p>
<p>至于L1范数，二者有不同的用途：</p>
<ul>
<li>L2范数对权重向量的大分量施加了巨大的惩罚。因此学习算法倾向于“<strong>在大量特征上均匀分布权重的模型</strong>”。</li>
<li>L1范数会导致模型将权重集中在一小部分特征上，
而将其他权重清除为零（<strong>特征选择</strong>）</li>
</ul>
<h2 id="暂退法dropout">暂退法（Dropout）</h2>
<h3 id="过拟合">过拟合</h3>
<p>我们还是从线性模型出发。当样本很少、特征很多的时候，我们多跑几轮epoch，很可能就会过拟合；相反，
当特征数很少，而样本足够多时，这时就并不容易过拟合了。但是其代价是：只会关注样本的某几个特征，而不会关注这些特征之间的联系。</p>
<p>而神经网络就相反了，神经网络并不关注单个的特征，而是关注特征与特征之间的联系，举个例子：“神经网络可能推断“尼日利亚”和“西联汇款”一起出现在电子邮件中表示垃圾邮件，
但单独出现则不表示垃圾邮件。”但是正是由于这个，当我们有过多的样本时，就很容哦过拟合（特征之间明明没有关系，但是模型会误认为噪声是某种特种之间的关系，尤其是当阶数变高时）</p>
<h3 id="稳健性">稳健性</h3>
<p>一个好的模型应该具有以下特点：</p>
<ul>
<li>模型简单，换言之就是模型的维度不应该太高</li>
<li>最终的模型应该比较平滑，也就是说对于样本有一定噪声的情况下能给出同样的输出。</li>
</ul>
<p>上面两点可以归结成模型的稳定性。</p>
<p>暂退法可以增加模型的稳健性，从下面两个方面：</p>
<ul>
<li>在中间的隐藏层与层之间，加入噪声。这样从输入输出的角度来看，模型会比较平滑。</li>
<li>忽略隐藏层中的某些神经元节点</li>
</ul>
<figure>
<img data-src="./d2l/截屏2023-08-07%2013.13.49.png" alt="截屏2023-08-07 13.13.49">
<figcaption aria-hidden="true">截屏2023-08-07 13.13.49</figcaption>
</figure>
<p>如上，毕晓普的方法就是给隐藏层加入噪声；而标准的dropout则是丢弃某些神经元的结点，如下：</p>
<figure>
<img data-src="./d2l/截屏2023-08-07%2013.15.35.png" alt="截屏2023-08-07 13.15.35">
<figcaption aria-hidden="true">截屏2023-08-07 13.15.35</figcaption>
</figure>
<h2 id="前向传播反向传播计算图">前向传播、反向传播、计算图</h2>
<h3 id="前向传播">前向传播</h3>
<p>定义：<strong>从输入层，到输出层，计算和存储神经网络中每层的结果</strong>。</p>
<p>首先是输入到第一个隐藏层： <span class="math display">\[
z=w_1x \\
h_1=\phi(z)
\]</span> 然后就是隐藏层到输出层 <span class="math display">\[
o=W_2h \\
L=l(o,y)
\]</span> 再加上L2范数 <span class="math display">\[
s=\frac{\lambda}{2}(||W_1||^2+||W_2||^2) \\
J=L+s
\]</span> J是最后的目标函数</p>
<figure>
<img data-src="./d2l/截屏2023-08-07%2015.04.26.png" alt="截屏2023-08-07 15.04.26">
<figcaption aria-hidden="true">截屏2023-08-07 15.04.26</figcaption>
</figure>
<h3 id="反向传播">反向传播</h3>
<p>反向传播就是从结果开始，满满的向前计算偏导数，最后利用链式法则复合到一起，然后得出对参数的梯度。</p>
<p>模型稳定性和模型初始化</p>
<h2 id="数值稳定性和模型初始化">数值稳定性和模型初始化</h2>
<h3 id="梯度爆炸消失">梯度爆炸/消失</h3>
<p>参数的初值选取，以及后续激活函数的选定，都对我们模型的训练会造成很大的影响：</p>
<ul>
<li>参数更新过大，矩阵累乘后会造成梯度爆炸</li>
<li>参数更新过小，会造成梯度消失</li>
</ul>
<p>还有激活函数，如sigmoid函数，它符合神经学的认知，但是真正放在训练中：</p>
<figure>
<img data-src="./d2l/截屏2023-08-07%2019.47.37.png" alt="截屏2023-08-07 19.47.37">
<figcaption aria-hidden="true">截屏2023-08-07 19.47.37</figcaption>
</figure>
<p>当输入过大的时候，sigmoid函数的导数基本为0了，整个的梯度就消失了。</p>
<p>所以现在领域内主要是选择ReLU函数的变体来作为激活函数。</p>
<h3 id="打破对称性">打破对称性</h3>
<p>对称性指的是：一个网络中的神经元具有相同的输入、初值权重、激活函数，那么这两个神经元在后续的训练中会保持完全相同的行为，他们的输出完全相同。换句话来说，<strong>一个神经元和两个神经元没什么区别</strong>。</p>
<p>因此，我们在初始化参数的时候，一定要避免这种情况。</p>
<p>在初始化的时候选择让参数服从一个均值为0方差0.01的正态分布，这样在一定程度上能得到一组较好的参数。</p>
<p>在实际编码时，可以直接选择<strong>Xavier初始化</strong>。</p>
<h2 id="环境和分布偏移">环境和分布偏移</h2>
<p>有一句很好的话：<strong>有时模型的部署本身就是扰乱数据分布的催化剂</strong></p>
<p>举个很贴切的例子：假设我们训练了一个贷款申请人违约风险模型，用来预测谁将偿还贷款或违约。
这个模型发现申请人的鞋子与违约风险相关（穿牛津鞋申请人会偿还，穿运动鞋申请人会违约）。
此后，这个模型可能倾向于向所有穿着牛津鞋的申请人发放贷款，并拒绝所有穿着运动鞋的申请人。<strong>不久，所有的申请者都会穿牛津鞋，而信用度却没有相应的提高。</strong></p>
<p>上面的例子中，很容易看到：当我们的模型部署后，竟然让数据的分布发生了变化。</p>
<h3 id="协变量偏移">协变量偏移</h3>
<p>定义：虽然输入的分布可能随时间而改变，
但标签函数（即条件分布𝑃(𝑦∣𝐱)）没有改变。
统计学家称之为<em>协变量偏移</em>（covariate shift）</p>
<p>协变量指的就是特征。</p>
<p>有点抽象，拿一个具体问题举例：</p>
<figure>
<img data-src="./d2l/截屏2023-08-08%2015.53.23.png" alt="截屏2023-08-08 15.53.23">
<figcaption aria-hidden="true">截屏2023-08-08 15.53.23</figcaption>
</figure>
<p>训练集是真实的照片，而测试集是卡通照片，对于这种训练集没有这个feature，而测试集有这个feature，可以称为协变量偏移，如果没有办法来适应这个，那么显然，模型会失去应有的效果。</p>
<h3 id="标签偏移">标签偏移</h3>
<p>标签偏移刚好和协变量偏移相反。</p>
<h3 id="概念偏移">概念偏移</h3>
<p>定义：<strong>当标签的定义发生变化时，就会出现这种问题。</strong></p>
<p>听着很奇怪，但举个例子：精神疾病的诊断标准、所谓的时髦、以及工作头衔等等，都是概念偏移的日常映射。随着时间的推移，这些概念的定义可能会发生偏移。</p>
<h1 id="cnn">CNN</h1>
<p>上一章节所描述的感知机貌似能解决很多问题，例如处理表格类型的数据这种特征数目不是很多的数据集。</p>
<p>但是，假如将我们的输入换成一张1200w*1200w像素的图片，那么按照之前softmax回归的处理思路。将照片的像素平铺成一个一位向量，那么我们就有1万亿个feature，然后第一层隐藏层的神经元个数也为1万亿的话，那么第一层的w就会爆炸，这样训练需要大量的GPU资源，以及人力成本。</p>
<p>因此可以看到，MLP在对于这种图片的处理基本是没什么效果的，因此我们引入<strong>卷积神经网络CNN</strong>。</p>
<h2 id="从mlp到cnn">从MLP到CNN</h2>
<p>卷积本来是在DSP中使用的，FFT中使用，但是由于卷积的两种特性，使得它被运用到DL中，并产生了CNN：</p>
<ul>
<li>平移不变性：<strong>不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应</strong></li>
<li>局部性：<strong>神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。</strong></li>
</ul>
<h2 id="互相关运算">互相关运算</h2>
<p>其实不应该叫卷积运算，学过DSP里面，卷积的的运算中前面写的是符号，而我们深度学习中，使用的卷积前面的W的索引是正着来的，而数学中的卷积应该是翻着来的，严格的来讲，DL里的卷积应该叫<strong>互相关运算</strong></p>
<figure>
<img data-src="./d2l/截屏2023-08-09%2010.25.42.png" alt="截屏2023-08-09 10.25.42">
<figcaption aria-hidden="true">截屏2023-08-09 10.25.42</figcaption>
</figure>
<p>假设输入是 <span class="math inline">\(n_h*n_w\)</span>，然后kernel是<span class="math inline">\(k_h*k_w\)</span>，那么输出就为： <span class="math display">\[
(n_h-k_h+1)\times(n_w-k_w+1)
\]</span>
下面我们按照书上的内容，手动写一下卷积层，以及对核函数进行一个简单的学习</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_device</span>():</span><br><span class="line">    <span class="keyword">return</span> torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span> * ((y_hat - y) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, X, Y, epoch, lr</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        Y_hat = net.forward(X)</span><br><span class="line">        l = loss(y_hat=Y_hat, y=Y)</span><br><span class="line">        net.zero_grad()</span><br><span class="line">        l.<span class="built_in">sum</span>().backward()</span><br><span class="line">        net.weight.data[:] -= lr * net.weight.grad</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l.<span class="built_in">sum</span>():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d</span>(<span class="params">X, K</span>):  <span class="comment"># @save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot;</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>), device=get_device())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = torch.ones((<span class="number">6</span>, <span class="number">8</span>), device=get_device())</span><br><span class="line">X[:, <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">K = torch.tensor([[<span class="number">1.0</span>, -<span class="number">1.0</span>]], device=get_device())</span><br><span class="line">Y = corr2d(X, K)</span><br><span class="line">net = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">2</span>), bias=<span class="literal">False</span>, device=get_device())</span><br><span class="line">X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">Y = Y.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">7</span>))</span><br><span class="line">lr = <span class="number">3e-2</span></span><br><span class="line">epoch = <span class="number">20</span></span><br><span class="line">train(net, X, Y, epoch, lr)</span><br><span class="line"><span class="built_in">print</span>(net.weight.data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tensor([[[[ <span class="number">0.9750</span>, -<span class="number">0.9750</span>]]]], device=<span class="string">&#x27;mps:0&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>上面的代码中，我们的net、X、Y、weight、bias都是放在Mac的GPU上的，实际训练也是使用的GPU。</p>
<h2 id="填充和步幅">填充和步幅</h2>
<p>上面几节讲的CNN中，经过和核函数运算后，我们的输入不断减小，这时有两种情况：</p>
<ol type="1">
<li>当我们的输入非常大时，这时可以将我们的网络做的很深，但是仅仅靠核函数带来的线性衰减，我们的信息压缩的非常慢。</li>
<li>当我们的输入维度很小时，我们靠着线性衰减，我们可能做不了几层，无法把我们的网络做深。</li>
</ol>
<p>这时候可以对我们的输入做一个填充，并且在和核函数进行运算时，调整我们的步幅。</p>
<h3 id="填充">填充</h3>
<p>通常会将我们的填充设置为核函数的维度减一，比如我们是3*3的核函数，那么可以将我们的填充设置为2，这样的话，我们的输入和输出的维度就是一样的了。</p>
<p>下面的例子中的核函数是大小是2*2的，所以就算填充是1，我们的输入输出维度并没有保持一致。</p>
<p>通常情况我们的卷积核的大小会设置为奇数，好处是：保持空间维度的同时，我们可以在顶部和底部填充相同数量的行</p>
<h3 id="截屏2023-08-09-20.54.35步幅"><img data-src="./d2l/截屏2023-08-09%2020.54.35.png" alt="截屏2023-08-09 20.54.35">步幅</h3>
<p>步幅就是当我们在计算卷积的时候，for
loop遍历的步长。一般我们的步幅是1，这样我们的输入和输出之间的关系就是一个线性的衰减了，但为了解决我们刚开始说的输入过大的这种情况，我们可以将步幅设置为2，这样我们的输出相对于输入就会减半，直接从一个线性衰减变成了指数衰减。</p>
<figure>
<img data-src="./d2l/截屏2023-08-09%2021.00.15.png" alt="截屏2023-08-09 21.00.15">
<figcaption aria-hidden="true">截屏2023-08-09 21.00.15</figcaption>
</figure>
<h2 id="多输入输出通道">多输入输出通道</h2>
<p>上一节中我们的输入就是一个二维的矩阵，或者说是三维张量，但是现实中我们输入的图片并只是二维张量，例如RGB，每个像素还有红黄蓝三个值可以调，这使得不同程度的红黄蓝比例能够表示各种复杂的颜色。我们说RGB图片有三个通道，当RGB图片作为输入时，我们的输入就是一个<span class="math inline">\(3\times h\times w\)</span>的三维张量。</p>
<h3 id="多输入通道">多输入通道</h3>
<p>当我们的原始输入是一个RGB图像时，我们的输入就有3个通道，肯定不能用一个卷积核来处理这三个通道，因此，我们需要三个卷积核，做三次互相关运算，然后最终加在一起。</p>
<figure>
<img data-src="./d2l/截屏2023-08-12%2019.49.13.png" alt="截屏2023-08-12 19.49.13">
<figcaption aria-hidden="true">截屏2023-08-12 19.49.13</figcaption>
</figure>
<p>上面第一个是第一个卷积层，输入是2通道，所以卷积核也是两个，最后的输出将两个通道的内容合并在了一起，因此输出只有一个通道。</p>
<p>PS：这里每个通道输入和核函数做互相关运算之后，所有通道的结果加在一起了，两个思考：</p>
<ul>
<li>每个通道输出的结果需不需要乘一个系数，然后再相加到一起？答案是不需要，因为系数可以融进核函数里面，效果是一样的，不需要多此一举</li>
<li>为什么非要用加法操作将每个通道的结果融合在一起？
<ul>
<li>其一是好算，加法操作比乘法等操作耗时短，卷积层的训练速度加快，这是站在训练的角度。</li>
<li>其二是，每个通道的输出结果其实是一个模式（pattern），把这些模式加在一起能够得出更复杂的模式，<strong>至于乘法运算能不能也有很好的效果，就不得而知了</strong></li>
</ul></li>
</ul>
<h3 id="多输出通道">多输出通道</h3>
<p>上面有了多输入通道，但是我们的输出还是只是一个二维张量，这样如果作为下一层的输入那么就只有1维了，通道数降低了。</p>
<p>现实中，通道数多的话，能够学习的模式也就多，所以我们希望输出的通道维数也尽可能不要减少，因为神经网络要做很多层可能，如何增加输出通道呢，也很简单：上面有两个卷积核，也就是两个通道，我们可以设置很多卷积核，比如设计100个卷积核，然后分层，每层2个卷积核，一共50层，整个的卷积核的维度就是：<span class="math inline">\(50\times 2\times
2\times2\)</span>，前面这个50，代表的就是我们的输出通道数有50个。下面是某层有多个输出通道，卷积核<span class="math inline">\(2\times3\times1\times1\)</span></p>
<figure>
<img data-src="./d2l/截屏2023-08-12%2020.13.27.png" alt="截屏2023-08-12 20.13.27">
<figcaption aria-hidden="true">截屏2023-08-12 20.13.27</figcaption>
</figure>
<h3 id="times1卷积核"><span class="math inline">\(1\times1\)</span>卷积核</h3>
<p>上图就是<span class="math inline">\(1\times1\)</span>的卷积核。这样的卷积核一次只能看一个像素，也就是说失去了其空间能力。</p>
<p>我们之前了解到，从MLP到CNN，就是增加了空间性，所以我们
可以认为：如果某层的卷积核都是<span class="math inline">\(1\times1\)</span>的话，那么可视作全连接层，其作用就是融合特征。</p>
<h2 id="汇聚层">汇聚层</h2>
<p>汇聚层的目的：</p>
<ul>
<li>模式融合</li>
<li>降低卷积层对空间信息的敏感性， 增加对平移不变性的支持</li>
</ul>
<p>我们的卷积层通常是<span class="math inline">\(3\times3\)</span>的，，对空间（这里指的是几个像素的偏移）十分敏感，但是，我们希望达到的效果是：在右边能识别出照片里的一只猫，在左边（换个环境）也同样能识别出。</p>
<p>另外，在最后一层中，我们希望能够直接识别出图像中有一只猫，而不是一些局部的纹理、毛色等信息。所以，需要对学到的模式进行汇聚。</p>
<p>汇聚层有最大汇聚层（max）和平均 汇聚层，最大汇聚层如下；</p>
<figure>
<img data-src="./d2l/截屏2023-08-14%2012.33.03.png" alt="截屏2023-08-14 12.33.03">
<figcaption aria-hidden="true">截屏2023-08-14 12.33.03</figcaption>
</figure>
<p>这里的汇聚层的大小是<span class="math inline">\(2\times2\)</span>的，可以理解成允许物体向右边偏移一个像素；若是换成<span class="math inline">\(3\times3\)</span>的话，可以理解成允许左右偏移一个像素。</p>
<h2 id="lenet">LeNet</h2>
<figure>
<img data-src="./d2l/截屏2023-08-14%2014.30.43.png" alt="截屏2023-08-14 14.30.43">
<figcaption aria-hidden="true">截屏2023-08-14 14.30.43</figcaption>
</figure>
<p>上面是完整的架构，下面是网络的定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>用的是sigmoid激活函数，下面是输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.469, train acc 0.823, test acc 0.813</span><br><span class="line">26794.6 examples/sec on cuda:0</span><br></pre></td></tr></table></figure>
<p>然后将激活函数换成ReLU，结果是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.531, train acc 0.808, test acc 0.767</span><br><span class="line">27731.5 examples/sec on cuda:0</span><br></pre></td></tr></table></figure>
<p>好像差不太多，然后把学习率从1e-2上调到1e-1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.318, train acc 0.882, test acc 0.868</span><br><span class="line">27809.8 examples/sec on cuda:0</span><br></pre></td></tr></table></figure>
<p>满意离开。</p>
<h1 id="现代卷积神经网络">现代卷积神经网络</h1>
<p><img data-src="./d2l/截屏2023-08-15%2013.28.57.png"></p>
<p>上图横坐标是训练难度，纵坐标是精度。</p>
<h2 id="alexnet">AlexNet</h2>
<figure>
<img data-src="./d2l/截屏2023-08-14%2020.16.24.png" alt="截屏2023-08-14 20.16.24">
<figcaption aria-hidden="true">截屏2023-08-14 20.16.24</figcaption>
</figure>
<p>上图左为LeNet，右为AlexNet，，可以看到其实AlexNet大致上就是一个更大更肥的LeNet，有几个细节：</p>
<ul>
<li>激活函数从sigmoid换成了ReLU</li>
<li>输入变成3通道了</li>
<li>采用了Dropout</li>
<li>双GPU</li>
</ul>
<p>下面是网络的代码形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    <span class="comment"># 这里使用一个11*11的更大窗口来捕捉对象。</span></span><br><span class="line">    <span class="comment"># 同时，步幅为4，以减少输出的高度和宽度。</span></span><br><span class="line">    <span class="comment"># 另外，输出通道的数目远大于LeNet</span></span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 使用三个连续的卷积层和较小的卷积窗口。</span></span><br><span class="line">    <span class="comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span></span><br><span class="line">    <span class="comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span></span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    <span class="comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span></span><br><span class="line">    nn.Linear(<span class="number">6400</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h2 id="vgg">VGG</h2>
<p>AlexNet在当时的提升是非常大的，但是卷积层设计的非常奇怪，没有提供通用的模版，给人一种感觉“我这样设置网络效果就很好”。</p>
<p>于是出现了VGG。</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2012.23.50.png" alt="截屏2023-08-15 12.23.50">
<figcaption aria-hidden="true">截屏2023-08-15 12.23.50</figcaption>
</figure>
<p>与AlexNet不同的是，VGG用的卷积核都是<span class="math inline">\(3\times3\)</span>的，而不是<span class="math inline">\(11\times11\)</span>的，更小的窗口，带来更深的网络。（从结果上来讲，这样的设计，最后模型的精度确实高很多）。</p>
<p>最原始的VGG：</p>
<ul>
<li>一个VGG快包含若干个卷积层（<span class="math inline">\(3\times3\)</span>的卷积核，padding为1保证输入输出size一样，汇聚层的汇聚窗口为<span class="math inline">\(2\times2\)</span>，stride为2，这样使得整个VGG块的输入到输出减半）</li>
</ul>
<p>然后可以根据设备的计算量，选择使用几个VGG块。</p>
<h2 id="nin">NiN</h2>
<p>NiN块的出现在于使用<span class="math inline">\(1\times1\)</span>的卷积层来替换最后的全连接层的作用。</p>
<p>全连接层相比于卷积层，有更多的参数个数，这带来的计算量开销和显存开销是非常大的。</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2013.02.06.png" alt="截屏2023-08-15 13.02.06">
<figcaption aria-hidden="true">截屏2023-08-15 13.02.06</figcaption>
</figure>
<p>所以NiN的想法就是去掉全连接层：</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2013.03.11.png" alt="截屏2023-08-15 13.03.11">
<figcaption aria-hidden="true">截屏2023-08-15 13.03.11</figcaption>
</figure>
<h2 id="googlenet">GoogLeNet</h2>
<p>。。。用“忙里”砸出来的，暂时没什么好看的，其核心就是用下面的Inception块：</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2017.15.54.png" alt="截屏2023-08-15 17.15.54">
<figcaption aria-hidden="true">截屏2023-08-15 17.15.54</figcaption>
</figure>
<p>整个网络的结构如下：</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2017.16.19.png" alt="截屏2023-08-15 17.16.19">
<figcaption aria-hidden="true">截屏2023-08-15 17.16.19</figcaption>
</figure>
<p>后续有些改进也就是改进的Inception块，比如把<span class="math inline">\(5\times5\)</span>的卷积核改成<span class="math inline">\(3\times3\)</span>，然后把<span class="math inline">\(3\times3\)</span>换成2个<span class="math inline">\(1\times7\)</span>。总之就是条蚕调出来的，至于能不能用，为什么，没有很多的说法，复现也不是很容易。</p>
<h2 id="batch-normalization">batch normalization</h2>
<p>批量正则化，他的出现是试图解决这个问题：随着模型的变深，当我们进行backward更新梯度时，靠近输出端的w可以很快的更新，这也就导致上层可以很快的收敛；相反，靠近数据的输入端，由于梯度一直累乘累乘（链式法则求导），所以下面的梯度就更新的很慢，并且，对于不同的batch（这些数据是随机抽取的，可能有很大的不同，在数据分布上），上层的权重能够很快的适应，但是下层，靠近数据输入端的并不能很快适应。越往下，越需要一种方法来解决这个。</p>
<p>批量正则化在干这样一件事，往我们的数据（输入或者输出）中增加噪声，以此来控制我们模型的复杂性。</p>
<ul>
<li>在MLP中，将batch normalization层放在仿射变换和激活函数之间</li>
<li>在CNN中，将其放在卷积层和激活函数之间</li>
</ul>
<p>值得注意的是，batch
normalization并不一定是正确的，仅仅是现在很多人使用，原因是：精度不一定提升，但是模型的收敛速度很快。</p>
<h2 id="resnet">ResNet</h2>
<p>整个神经网络其实就是在学习、找到一个合适的函数，或者说学习到一种模式，来解决问题。我们之前了解到的网络可能会出现下图中左边的那种情况：</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2019.51.56.png" alt="截屏2023-08-15 19.51.56">
<figcaption aria-hidden="true">截屏2023-08-15 19.51.56</figcaption>
</figure>
<p>训练过程中离最优解越来越远了。但我们理想的效果反而是右图。残差块可以解决这个：</p>
<figure>
<img data-src="./d2l/截屏2023-08-15%2019.56.14.png" alt="截屏2023-08-15 19.56.14">
<figcaption aria-hidden="true">截屏2023-08-15 19.56.14</figcaption>
</figure>
<p>可以看到相较于前面的网络，残差块加上了一个前向反馈，这样不管中间有没有学到东西，至少之前学到的x是能够保留的。</p>
<p>另外，残差块就是将乘法转换成了加法，在反向传播求导的过程中，能够加快训练速度。</p>
<h1 id="代码训练--mlpcnn">代码训练--MLP+CNN</h1>
<p>这里对前面学到的一些知识用代码复现一下，加深理解，避免遗忘。</p>
<h2 id="线性回归-1">线性回归</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">true_w = torch.Tensor([<span class="number">2</span>, - <span class="number">3.4</span>])</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">10000</span>, <span class="built_in">len</span>(true_w)))</span><br><span class="line">Y = torch.matmul(X, true_w) + true_b  <span class="comment"># x是一个矩阵，w是一个列向量，最后乘出来得到一个列向量</span></span><br><span class="line">Y += torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, Y.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    num = <span class="built_in">len</span>(features)</span><br><span class="line">    indexes = <span class="built_in">list</span>(<span class="built_in">range</span>(num))</span><br><span class="line">    random.shuffle(indexes)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num, batch_size):</span><br><span class="line">        batch_indexes = torch.tensor(indexes[i: <span class="built_in">min</span>((i + batch_size, num))])</span><br><span class="line">        <span class="keyword">yield</span> features[batch_indexes], labels[batch_indexes]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pred_w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=true_w.shape, requires_grad=<span class="literal">True</span>)</span><br><span class="line">pred_b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epoch = <span class="number">5</span></span><br><span class="line">batch = <span class="number">30</span></span><br><span class="line">losses = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> data_iter(batch_size=batch, features=X, labels=Y):</span><br><span class="line">        l = <span class="number">0.5</span> * (torch.matmul(x, pred_w) + pred_b - y) ** <span class="number">2</span></span><br><span class="line">        l.<span class="built_in">sum</span>().backward()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> [pred_w, pred_b]:</span><br><span class="line">                param -= lr * param.grad / batch</span><br><span class="line">                param.grad.zero_()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 每一个epoch结束后，测试所有数据的loss</span></span><br><span class="line">        train_l = <span class="number">0.5</span> * (torch.matmul(X, pred_w) + pred_b - Y) ** <span class="number">2</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;<span class="built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br><span class="line">        losses.append(<span class="built_in">float</span>(train_l.mean()))</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, epoch + <span class="number">1</span>), losses)</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img data-src="./d2l/截屏2023-08-17%2013.23.07.png" alt="截屏2023-08-17 13.23.07">
<figcaption aria-hidden="true">截屏2023-08-17 13.23.07</figcaption>
</figure>
<h2 id="softmax线性回归">softmax线性回归</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> d2l.torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">0</span></span><br><span class="line">trans = transforms.ToTensor()  <span class="comment"># 以tensor的形式存下来</span></span><br><span class="line">dev = torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line">minist_train = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;./data&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=trans,  <span class="comment"># 将下下来的图片以tensor的形式读进内存</span></span><br><span class="line">    download=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">minist_test = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;./data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    transform=trans,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">train_iter = data.DataLoader(minist_train, batch_size, num_workers=num_workers, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_iter = data.DataLoader(minist_test, batch_size)</span><br><span class="line"></span><br><span class="line">num_inputs = <span class="number">1</span> * <span class="number">28</span> * <span class="number">28</span></span><br><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line">w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class="literal">True</span>, device=dev)</span><br><span class="line">b = torch.zeros(size=(num_outputs,), requires_grad=<span class="literal">True</span>, device=dev)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">X</span>):</span><br><span class="line">    X_exp = torch.exp(X)</span><br><span class="line">    fen_mu = X_exp.<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> X_exp / fen_mu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">X</span>):</span><br><span class="line">    <span class="keyword">return</span> softmax(torch.matmul(X.reshape(-<span class="number">1</span>, w.shape[<span class="number">0</span>]), w) + b)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> -torch.log(y_hat[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape) &gt; <span class="number">0</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        y_hat = y_hat.argmax(axis=<span class="number">1</span>)  <span class="comment"># 取每行的最大值作为预测概率</span></span><br><span class="line">    cmp = y_hat.<span class="built_in">type</span>(y.dtype) == y  <span class="comment"># 将y_hat转成y同样的数据类型，然后比较得到bool类型，分类问题都可以这样做</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(cmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy</span>(<span class="params">net, data_iter</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        如果模型是继承自torch.nn.Module的话，那么会自动求梯度，设置成评估模式的意思就是不要求梯度了</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="string">&quot;&quot;&quot;设置累加器，需要累加的有：正确预测数，预测总数&quot;&quot;&quot;</span></span><br><span class="line">    metric = d2l.Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        x, y = x.to(dev), y.to(dev)</span><br><span class="line">        metric.add(accuracy(net(x), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">net, data_iter, loss, updater, lr, params</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.train()  <span class="comment"># 累计梯度</span></span><br><span class="line">    metric = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        x, y = x.to(dev), y.to(dev)</span><br><span class="line">        y_hat = net(x)</span><br><span class="line">        l = loss(y_hat, y)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            如果采用的是torch的Optimizer，那么下面这样处理</span></span><br><span class="line"><span class="string">            1. 梯度清零</span></span><br><span class="line"><span class="string">            2. 反向传播</span></span><br><span class="line"><span class="string">            3. 自动更新参数</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            updater.step()</span><br><span class="line">            metric.add(</span><br><span class="line">                <span class="built_in">float</span>(l) * <span class="built_in">len</span>(y),</span><br><span class="line">                accuracy(y_hat, y),</span><br><span class="line">                y.size().numel(),</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot;如果自己手写，那么l出来就是一个向量&quot;&quot;&quot;</span></span><br><span class="line">            l.<span class="built_in">sum</span>().backward()</span><br><span class="line">            updater(lr, x.shape[<span class="number">0</span>], *params)</span><br><span class="line">            metric.add(</span><br><span class="line">                <span class="built_in">float</span>(l.<span class="built_in">sum</span>()),</span><br><span class="line">                accuracy(y_hat, y),</span><br><span class="line">                y.numel()</span><br><span class="line">            )</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :returns loss/n, acc/ n</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">2</span>], metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, test_iter, loss, num_epoch, updater, lr, params</span>):</span><br><span class="line">    train_acc_list, train_loss_list, test_acc_list = [], [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">        train_metrics = train_epoch(</span><br><span class="line">            net=net,</span><br><span class="line">            data_iter=train_iter,</span><br><span class="line">            loss=loss, updater=updater,</span><br><span class="line">            lr=lr,</span><br><span class="line">            params=params</span><br><span class="line">        )</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter)</span><br><span class="line">        train_acc_list.append(train_metrics[<span class="number">1</span>])</span><br><span class="line">        train_loss_list.append(train_metrics[<span class="number">0</span>])</span><br><span class="line">        test_acc_list.append(test_acc)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, rain loss: <span class="subst">&#123;train_metrics[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span>, train acc: <span class="subst">&#123;train_metrics[<span class="number">1</span>]:<span class="number">.2</span>f&#125;</span>, test acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> train_acc_list, train_loss_list, test_acc_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updater</span>(<span class="params">lr, batch, *params</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;在我们手动实现的优化器里面，已经将梯度每次清零了&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param -= lr * param.grad / batch</span><br><span class="line">            param.grad.zero_()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">epoch = <span class="number">100</span></span><br><span class="line">lr = <span class="number">1e-1</span></span><br><span class="line">train_acc_list, train_loss_list, test_acc_list = train(</span><br><span class="line">    net=net,</span><br><span class="line">    lr=lr,</span><br><span class="line">    num_epoch=epoch,</span><br><span class="line">    params=(w, b),</span><br><span class="line">    train_iter=train_iter,</span><br><span class="line">    test_iter=test_iter,</span><br><span class="line">    loss=cross_entropy,</span><br><span class="line">    updater=updater</span><br><span class="line">)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(epoch), train_acc_list, label=<span class="string">&quot;train acc&quot;</span>, color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(epoch), train_loss_list, label=<span class="string">&quot;train loss&quot;</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(epoch), test_acc_list, label=<span class="string">&quot;test acc&quot;</span>, color=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;train/evaluate&quot;</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img data-src="./d2l/截屏2023-08-18%2009.15.49.png" alt="截屏2023-08-18 09.15.49">
<figcaption aria-hidden="true">截屏2023-08-18 09.15.49</figcaption>
</figure>
<h2 id="mlp">MLP</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> d2l.torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">minist_train = torchvision.datasets.FashionMNIST(</span><br><span class="line">    download=<span class="literal">False</span>,</span><br><span class="line">    transform=torchvision.transforms.ToTensor(),</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    root=<span class="string">&quot;./data&quot;</span></span><br><span class="line">)</span><br><span class="line">minist_test = torchvision.datasets.FashionMNIST(</span><br><span class="line">    download=<span class="literal">False</span>,</span><br><span class="line">    transform=torchvision.transforms.ToTensor(),</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    root=<span class="string">&quot;./data&quot;</span></span><br><span class="line">)</span><br><span class="line">dev = torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line">train_iter = torch.utils.data.DataLoader(minist_train, batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(minist_test, batch_size)</span><br><span class="line"></span><br><span class="line">num_input, num_hiddens, num_output = <span class="number">1</span> * <span class="number">28</span> * <span class="number">28</span>, <span class="number">256</span>, <span class="number">10</span></span><br><span class="line">w1 = nn.Parameter(torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_input, num_hiddens), device=dev, requires_grad=<span class="literal">True</span>))</span><br><span class="line">b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class="literal">True</span>, device=dev))</span><br><span class="line">w2 = nn.Parameter(torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_hiddens, num_output), device=dev, requires_grad=<span class="literal">True</span>))</span><br><span class="line">b2 = nn.Parameter(torch.zeros(num_output, requires_grad=<span class="literal">True</span>, device=dev))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ReLU</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">max</span>(x, torch.zeros(x.shape, device=dev))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">x</span>):</span><br><span class="line">    x = x.reshape(-<span class="number">1</span>, num_input)</span><br><span class="line">    h = ReLU(x @ w1 + b1)</span><br><span class="line">    o = h @ w2 + b2</span><br><span class="line">    <span class="keyword">return</span> o</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss(reduction=<span class="string">&quot;none&quot;</span>)</span><br><span class="line">num_epoch, lr = <span class="number">20</span>, <span class="number">1e-2</span></span><br><span class="line">updater = torch.optim.SGD(params=(w1, b1, w2, b2), lr=lr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">acc</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape) &gt; <span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    tmp = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(tmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch</span>(<span class="params">net, data_iter, loss, updater</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, torch.nn.Module):</span><br><span class="line">        net.train()</span><br><span class="line">    accumulator = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        x, y = x.to(dev), y.to(dev)</span><br><span class="line">        y_hat = net(x)</span><br><span class="line">        l = loss(y_hat, y)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(updater, torch.optim.Optimizer):</span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            l.mean().backward()</span><br><span class="line">            updater.step()</span><br><span class="line">            accumulator.add(</span><br><span class="line">                <span class="built_in">float</span>(l.<span class="built_in">sum</span>()),</span><br><span class="line">                acc(y_hat, y),</span><br><span class="line">                y.size().numel()</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;hahaha&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> accumulator[<span class="number">0</span>] / accumulator[<span class="number">2</span>], accumulator[<span class="number">1</span>] / accumulator[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_loss_list, train_acc_list, test_acc_list, test_loss_list = [], [], [], []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, test_iter, loss, num_epoch, updater</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">        train_loss, train_acc = train_epoch(net, train_iter, loss, updater)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">            net.<span class="built_in">eval</span>()</span><br><span class="line">        ctr = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> test_iter:</span><br><span class="line">            x, y = x.to(dev), y.to(dev)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            ctr.add(</span><br><span class="line">                <span class="built_in">float</span>(loss(y_hat, y).<span class="built_in">sum</span>()),</span><br><span class="line">                acc(y_hat, y),</span><br><span class="line">                y.numel()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        test_acc = ctr[<span class="number">1</span>] / ctr[<span class="number">2</span>]</span><br><span class="line">        test_loss = ctr[<span class="number">0</span>] / ctr[<span class="number">2</span>]</span><br><span class="line">        train_loss_list.append(train_loss)</span><br><span class="line">        train_acc_list.append(train_acc)</span><br><span class="line">        test_acc_list.append(test_acc)</span><br><span class="line">        test_loss_list.append(test_loss)</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;epoch: <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, test acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>, test loss: <span class="subst">&#123;test_loss:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train(net, train_iter, test_iter, loss, num_epoch, updater)</span><br><span class="line"><span class="comment"># plt.plot(range(num_epoch), train_acc_list, label=&quot;train acc&quot;, color=&quot;red&quot;)</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(num_epoch), train_loss_list, label=<span class="string">&quot;train loss&quot;</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line"><span class="comment"># plt.plot(range(num_epoch), test_acc_list, label=&quot;test acc&quot;, color=&quot;blue&quot;)</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(num_epoch), test_loss_list, label=<span class="string">&quot;test loss&quot;</span>, color=<span class="string">&quot;pink&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;train/evaluate&quot;</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="./d2l/截屏2023-08-18%2010.46.47.png" alt="截屏2023-08-18 10.46.47">
<figcaption aria-hidden="true">截屏2023-08-18 10.46.47</figcaption>
</figure>
<p>跑了20轮，看曲线的走势，test loss快要上升了，可能快过拟合了。</p>
<p>然后试试m1pro的mps和cuda哪个快点：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">timer = d2l.Timer()</span><br><span class="line">train(net, train_iter, test_iter, loss, num_epoch, updater)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;time: <span class="subst">&#123;timer.stop():<span class="number">.2</span>f&#125;</span> sec&quot;</span>)</span><br><span class="line"></span><br><span class="line">m1pro: time: <span class="number">47.91</span> sec</span><br><span class="line">mx150: 模型太大了，直接爆显存。。。</span><br></pre></td></tr></table></figure>
<p>跑了100轮，看会不会overfitting：</p>
<figure>
<img data-src="./d2l/截屏2023-08-18%2011.18.28.png" alt="截屏2023-08-18 11.18.28">
<figcaption aria-hidden="true">截屏2023-08-18 11.18.28</figcaption>
</figure>
<p>貌似也并没有，只是越到后面，梯度越小了，近乎消失了。看样子训练20轮是比较好的了就，从20到100，test
acc上升了3个点。</p>
<h2 id="lenet-1">LeNet</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> d2l.torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line">batch = <span class="number">512</span></span><br><span class="line">minist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                                 download=<span class="literal">False</span>)</span><br><span class="line">minist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                                download=<span class="literal">False</span>)</span><br><span class="line">train_iter = data.DataLoader(minist_train, batch_size=batch, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_iter = data.DataLoader(minist_test, batch_size=batch)</span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.ReLU(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.ReLU(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">acc</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape) &gt; <span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    tmp = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(tmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_loss_list, test_loss_list = [], []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, test_iter, epoch, lr, device</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    net.to(device)</span><br><span class="line">    updater = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    accumulator_train = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            updater.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                accumulator_train.add(</span><br><span class="line">                    l * x.shape[<span class="number">0</span>],</span><br><span class="line">                    acc(y_hat, y),</span><br><span class="line">                    x.shape[<span class="number">0</span>]</span><br><span class="line">                )</span><br><span class="line">        train_acc = accumulator_train[<span class="number">1</span>] / accumulator_train[<span class="number">2</span>]</span><br><span class="line">        train_loss = accumulator_train[<span class="number">0</span>] / accumulator_train[<span class="number">2</span>]</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        accumulator_test = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> test_iter:</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            accumulator_test.add(</span><br><span class="line">                l * x.shape[<span class="number">0</span>],</span><br><span class="line">                acc(y_hat, y),</span><br><span class="line">                x.shape[<span class="number">0</span>]</span><br><span class="line">            )</span><br><span class="line">        test_acc = accumulator_test[<span class="number">1</span>] / accumulator_test[<span class="number">2</span>]</span><br><span class="line">        test_loss = accumulator_test[<span class="number">0</span>] / accumulator_test[<span class="number">2</span>]</span><br><span class="line">        test_loss_list.append(test_loss)</span><br><span class="line">        train_loss_list.append(train_loss)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, test_acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>, test_loss: <span class="subst">&#123;test_loss:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, epoch = <span class="number">1e-2</span>, <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    train(net, train_iter, test_iter, epoch, lr, device)</span><br><span class="line">    <span class="comment"># plt.plot(range(num_epoch), train_acc_list, label=&quot;train acc&quot;, color=&quot;red&quot;)</span></span><br><span class="line">    plt.plot(<span class="built_in">range</span>(epoch), train_loss_list, label=<span class="string">&quot;train loss&quot;</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">    <span class="comment"># plt.plot(range(num_epoch), test_acc_list, label=&quot;test acc&quot;, color=&quot;blue&quot;)</span></span><br><span class="line">    plt.plot(<span class="built_in">range</span>(epoch), test_loss_list, label=<span class="string">&quot;test loss&quot;</span>, color=<span class="string">&quot;pink&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;train/evaluate&quot;</span>)</span><br><span class="line">    plt.ylim(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img data-src="./d2l/截屏2023-08-18%2013.14.40.png" alt="截屏2023-08-18 13.14.40">
<figcaption aria-hidden="true">截屏2023-08-18 13.14.40</figcaption>
</figure>
<p>貌似有点过拟合了，试着加上L2权重衰减：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">updater = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)</span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> net.parameters():</span><br><span class="line">    l += wd * <span class="number">0.5</span> * p.<span class="built_in">pow</span>(<span class="number">2.0</span>).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<figure>
<img data-src="./d2l/截屏2023-08-18%2013.27.50.png" alt="截屏2023-08-18 13.27.50">
<figcaption aria-hidden="true">截屏2023-08-18 13.27.50</figcaption>
</figure>
<p>还是很抖动，降低学习率、增大batch试试。</p>
<figure>
<img data-src="./d2l/截屏2023-08-18%2013.32.46.png" alt="截屏2023-08-18 13.32.46">
<figcaption aria-hidden="true">截屏2023-08-18 13.32.46</figcaption>
</figure>
<p>曲线确实平滑了点。</p>
<p>然后lr调到4e-3</p>
<figure>
<img data-src="./d2l/截屏2023-08-18%2013.39.03.png" alt="截屏2023-08-18 13.39.03">
<figcaption aria-hidden="true">截屏2023-08-18 13.39.03</figcaption>
</figure>
<p>学习率1e-3</p>
<figure>
<img data-src="./d2l/截屏2023-08-18%2013.45.47.png" alt="截屏2023-08-18 13.45.47">
<figcaption aria-hidden="true">截屏2023-08-18 13.45.47</figcaption>
</figure>
<h2 id="alexnet-1">AlexNet</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> d2l.torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">batch = <span class="number">256</span></span><br><span class="line">trans = [transforms.ToTensor()]</span><br><span class="line">trans.insert(<span class="number">0</span>, transforms.Resize(<span class="number">224</span>))</span><br><span class="line">trans = transforms.Compose(trans)</span><br><span class="line">train_iter = data.DataLoader(</span><br><span class="line">    torchvision.datasets.FashionMNIST(<span class="string">&quot;./data&quot;</span>, <span class="literal">True</span>, transform=trans),</span><br><span class="line">    batch, <span class="literal">True</span>)</span><br><span class="line">test_iter = data.DataLoader(</span><br><span class="line">    torchvision.datasets.FashionMNIST(<span class="string">&quot;./data&quot;</span>, <span class="literal">False</span>, transform=trans),</span><br><span class="line">    batch, <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">6400</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epoch = <span class="number">10</span></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_iter, test_iter, epoch, lr, device</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    updater = torch.optim.SGD(params=net.parameters(), lr=lr)</span><br><span class="line">    accumulator_train = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    net = net.to(device)</span><br><span class="line">    train_acc_l, train_loss_l, test_acc_l, test_loss_l = [], [], [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            x = x.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            updater.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape) &gt; <span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">                    y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">                tmp = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">                tmp = tmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>()</span><br><span class="line">                accumulator_train.add(</span><br><span class="line">                    tmp,</span><br><span class="line">                    <span class="built_in">float</span>(l) * x.shape[<span class="number">0</span>],</span><br><span class="line">                    x.shape[<span class="number">0</span>]</span><br><span class="line">                )</span><br><span class="line">        train_acc = accumulator_train[<span class="number">0</span>] / accumulator_train[<span class="number">2</span>]</span><br><span class="line">        train_loss = accumulator_train[<span class="number">1</span>] / accumulator_train[<span class="number">2</span>]</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        accumulator_test = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> test_iter:</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">            tmp = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">            tmp = tmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>()</span><br><span class="line">            accumulator_test.add(</span><br><span class="line">                <span class="built_in">float</span>(tmp),</span><br><span class="line">                <span class="built_in">float</span>(l) * x.shape[<span class="number">0</span>],</span><br><span class="line">                x.shape[<span class="number">0</span>],</span><br><span class="line">            )</span><br><span class="line">        test_acc = accumulator_test[<span class="number">0</span>] / accumulator_test[<span class="number">2</span>]</span><br><span class="line">        test_loss = accumulator_test[<span class="number">1</span>] / accumulator_test[<span class="number">2</span>]</span><br><span class="line">        train_acc_l.append(train_acc)</span><br><span class="line">        train_loss_l.append(train_loss)</span><br><span class="line">        test_acc_l.append(test_acc)</span><br><span class="line">        test_loss_l.append(test_loss)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, test_acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>, test_loss: <span class="subst">&#123;test_loss:<span class="number">.2</span>f&#125;</span>, train_acc:<span class="subst">&#123;train_acc:<span class="number">.2</span>f&#125;</span>, &quot;</span></span><br><span class="line">              <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> train_acc_l, train_loss_l, test_acc_l, test_loss_l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t = d2l.Timer()</span><br><span class="line">    train_acc_l, train_loss_l, test_acc_l, test_loss_l = train(net, train_iter, test_iter, epoch, lr, device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;time: <span class="subst">&#123;t.stop():<span class="number">.2</span>f&#125;</span> sec&quot;</span>)</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(epoch), train_acc_l, label=<span class="string">&quot;train acc&quot;</span>, color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(epoch), train_loss_l, label=<span class="string">&quot;train loss&quot;</span>, color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(epoch), test_acc_l, label=<span class="string">&quot;test acc&quot;</span>, color=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(epoch), test_loss_l, label=<span class="string">&quot;test loss&quot;</span>, color=<span class="string">&quot;pink&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;epoch&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;train/evaluate&quot;</span>)</span><br><span class="line">    plt.ylim(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>跑了有点久，这大概就是本地机器的极限了，AlexNet</p>
<h2 id="resnet-1">ResNet</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[9]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> d2l.torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 读取数据集</span></span><br><span class="line"><span class="comment"># 读取Fashion minist数据集，将分辨率Resize得更大点，</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[5]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># resize 图片</span></span><br><span class="line">trans = [torchvision.transforms.ToTensor()]</span><br><span class="line">trans.insert(<span class="number">0</span>, torchvision.transforms.Resize(<span class="number">128</span>))</span><br><span class="line">trans = torchvision.transforms.Compose(trans)</span><br><span class="line"></span><br><span class="line">minist_train = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=trans)</span><br><span class="line">minist_test = torchvision.datasets.FashionMNIST(root=<span class="string">&quot;./data&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=trans)</span><br><span class="line"></span><br><span class="line">batch = <span class="number">256</span></span><br><span class="line">train_iter = data.DataLoader(dataset=minist_train, batch_size=batch, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_iter = data.DataLoader(dataset=minist_test, batch_size=batch, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="built_in">print</span>(x.shape, y.shape)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 构造Residual模块</span></span><br><span class="line"><span class="comment"># 一个residual模块应该包含下面几个部分：</span></span><br><span class="line"><span class="comment"># - 3*3 conv</span></span><br><span class="line"><span class="comment"># - bn</span></span><br><span class="line"><span class="comment"># - relu</span></span><br><span class="line"><span class="comment"># - 3*3 conv</span></span><br><span class="line"><span class="comment"># - bn</span></span><br><span class="line"><span class="comment"># - 输出部分和x同时作为加法器的输入，x可以通过1*1的conv变换通道</span></span><br><span class="line"><span class="comment"># - relu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[14]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, output_channels, use_1_1conv=<span class="literal">False</span>, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                               padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=output_channels, out_channels=output_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1_1conv:  <span class="comment">#用1*1的卷积核给X做变换</span></span><br><span class="line">            self.conv3 = nn.Conv2d(in_channels=input_channels, out_channels=output_channels, kernel_size=<span class="number">1</span>,</span><br><span class="line">                                   stride=stride)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(output_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(output_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y + X)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t = Residual(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">X = torch.rand((<span class="number">4</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line">t(X).shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 构造ResNet块</span></span><br><span class="line"><span class="comment"># 有了residual模块，我们就可以构造自己的resnet block了，可以在其中添加若干个residual</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[39]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet_block</span>(<span class="params">in_channel, out_channel, num_residual, is_first=<span class="literal">False</span></span>):</span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residual):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> is_first == <span class="literal">False</span>:</span><br><span class="line">            blk.append(</span><br><span class="line">                Residual(in_channel, out_channel, use_1_1conv=<span class="literal">True</span>, stride=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(Residual(out_channel, out_channel))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 构造ResNet</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[31]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">kernel=3, padding=1</span></span><br><span class="line"><span class="string">kernel=7, padding=3</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">都不会改变矩阵的形状，经过该网络后，是stride把高宽减半了</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">b1 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line">X = torch.rand(<span class="number">4</span>, <span class="number">1</span>, <span class="number">16</span>, <span class="number">16</span>)</span><br><span class="line">b1(X).shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[41]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">b2 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, is_first=<span class="literal">True</span>))</span><br><span class="line">b3 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">b4 = nn.Sequential(*resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">b5 = nn.Sequential(*resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[42]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    b1, b2, b3, b4, b5,</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[46]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span> layer input shape: <span class="subst">&#123;X.shape&#125;</span>&quot;</span>)</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">&#x27;output shape:\t&#x27;</span>, X.shape)</span><br><span class="line"></span><br><span class="line">net.parameters()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 开始训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[71]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">acc</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;返回预测正确的类数&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape) &gt; <span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        y_hat = y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    res = y_hat.<span class="built_in">type</span>(y.dtype) == y</span><br><span class="line">    res = res.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(res)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def init_weight(m):</span></span><br><span class="line">    <span class="comment">#     nn.init.xavier_uniform_(m.weight)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">        nn.init.xavier_uniform_(m.weight)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TTList</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num</span>):</span><br><span class="line">        self.ttl = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">            self.ttl.append([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">push</span>(<span class="params">self, elements</span>):</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> elements:</span><br><span class="line">            self.ttl[i].append(e)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">train_iter, test_iter, net, lr, epoch, device</span>):</span><br><span class="line">    net = net.to(device)</span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    updater = torch.optim.SGD(net.parameters(), lr)</span><br><span class="line">    ttl = TTList(<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        net.train()</span><br><span class="line">        accumulator_train = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            x = x.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            updater.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                accumulator_train.add(acc(y_hat, y), <span class="built_in">float</span>(l) * x.shape[<span class="number">0</span>], x.shape[<span class="number">0</span>])</span><br><span class="line">        train_acc = accumulator_train[<span class="number">0</span>] / accumulator_train[<span class="number">2</span>]</span><br><span class="line">        train_loss = accumulator_train[<span class="number">1</span>] / accumulator_train[<span class="number">2</span>]</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        accumulator_test = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> test_iter:</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            y_hat = net(x)</span><br><span class="line">            accumulator_test.add(acc(y_hat, y), <span class="built_in">float</span>(loss(y_hat, y)) * x.shape[<span class="number">0</span>], x.shape[<span class="number">0</span>])</span><br><span class="line">        test_acc = accumulator_test[<span class="number">0</span>] / accumulator_test[<span class="number">2</span>]</span><br><span class="line">        test_loss = accumulator_test[<span class="number">1</span>] / accumulator_test[<span class="number">2</span>]</span><br><span class="line">        ttl.push([train_acc, train_loss, test_acc, test_loss])</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;epoch <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>\ntrain acc: <span class="subst">&#123;train_acc:<span class="number">.2</span>f&#125;</span>, train loss: <span class="subst">&#123;train_loss:<span class="number">.2</span>f&#125;</span>\ntest acc: <span class="subst">&#123;test_acc:<span class="number">.2</span>f&#125;</span>, test_loss: <span class="subst">&#123;test_loss:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> ttl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># In[72]:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">epoch = <span class="number">20</span></span><br><span class="line">batch = <span class="number">256</span></span><br><span class="line">device = torch.device(<span class="string">&quot;mps&quot;</span>)</span><br><span class="line">train(train_iter, test_iter, net, lr, epoch, device)</span><br></pre></td></tr></table></figure>
<p>跑了一轮就有很好的效果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epoch 1</span><br><span class="line">train acc: 0.81, train loss: 0.58</span><br><span class="line">test acc: 0.81, test_loss: 0.50</span><br></pre></td></tr></table></figure>
<p>CV首选！</p>
<h1 id="rnn">RNN</h1>
<p>之前从MLP学到CNN，CNN的特点是很适合处理空间信息，能够捕捉到像素级别的特征。对于CNN的数据集，我们假设数据是服从独立同分布的，但是，现实生活中很多东西并不都是独立的：</p>
<ul>
<li>电影中的视频帧</li>
<li>一篇作文的每一个字</li>
<li>人的脑信号</li>
<li>在网上发言评论</li>
<li>...</li>
</ul>
<p>CNN并不能处理这样的数据，所以这时设计出了RNN：<strong>循环神经网络</strong></p>
<h2 id="序列模型">序列模型</h2>
<h3 id="自回归模型">自回归模型</h3>
<p>有两种自回归模型：</p>
<ul>
<li>自回归模型：假设当前的x只和过去的<span class="math inline">\(\tau\)</span>个变量有关，于是我们可以根据过去<span class="math inline">\(\tau\)</span>个变量，训练出一个MLP或者NN，这样有个好处是每次我们的输入都是固定个数的，都是<span class="math inline">\(\tau\)</span>个</li>
<li>隐变量自回归模型：隐变量模型是在当前引入了一个隐变量，当前的输入和隐变量h以及前一时刻的x有关，可以用下图表示</li>
</ul>
<figure>
<img data-src="./d2l/截屏2023-08-16%2013.35.41.png" alt="截屏2023-08-16 13.35.41">
<figcaption aria-hidden="true">截屏2023-08-16 13.35.41</figcaption>
</figure>
<p>马尔可夫模型就是根据前<span class="math inline">\(\tau\)</span>个数据进行估计。如果<span class="math inline">\(\tau=1\)</span>我们就得到一个一阶的马尔可夫模型。</p>
<h2 id="语言模型">语言模型</h2>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">chengyiqiu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>

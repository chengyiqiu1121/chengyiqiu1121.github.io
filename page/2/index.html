<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width":280,"display":"post","offset":10,"onmobile":true},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":true},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="chengyiqiu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="chengyiqiu"
      src="/images/pig.gif">
  <p class="site-author-name" itemprop="name">chengyiqiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/chengyiqiu1121" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chengyiqiu1121" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/08/DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/08/DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/" class="post-title-link" itemprop="url">DATAELIXIR:Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-08 12:46:25" itemprop="dateCreated datePublished" datetime="2024-04-08T12:46:25+08:00">2024-04-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-09 23:41:07" itemprop="dateModified" datetime="2024-04-09T23:41:07+08:00">2024-04-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>AAAI 2024</p>
<p>还没有release code</p>
<figure>
<img data-src="./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240408124759179.png" alt="image-20240408124759179">
<figcaption aria-hidden="true">image-20240408124759179</figcaption>
</figure>
<p>本文提出了一种数据消毒方法，也是使用扩散模型来消除触发器特征，重构良性特征。</p>
<h1 id="方法">方法</h1>
<h2 id="威胁模型">威胁模型</h2>
<p>本文处于防御者的视角，对于攻击者的目标标签、投毒率等不可访问。</p>
<p>防御者：</p>
<ul>
<li>假设防御者可以访问和当前任务类似分布的预训练扩散模型。</li>
<li>训练扩散模型的数据集是干净的</li>
</ul>
<h2 id="候选集合构建">候选集合构建</h2>
<p><img data-src="./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240408144318778.png" alt="image-20240408144318778">、</p>
<p>本文采取的方法是，对于某张图片，进行n轮前向&amp;反向过程，每一轮的最后m次反向，收集重构的图片，作为候选集合，若是候选集合中的标签发生了变化，证明图片很可能被投毒。
<span class="math display">\[
C_{(x_i,y_i)}=\{(x_j,y_j)\}^{n\times m}_{j=1}
\]</span></p>
<h2 id="异常样本识别">异常样本识别</h2>
<p>对于每一个候选集合，都有一个转换系数<span class="math inline">\(\eta\)</span>，表示第二高的标签的计数，若是超过了阈值<span class="math inline">\(\tau\)</span>，那么代表这个样本可能是毒化样本。</p>
<p>进一步，对于一个良性的样本，其候选集合的分布应该是单值的，也就是全部是一个标签；对于异常样本，则是双值，分布上表现为两个波峰，这代表着样本标签从目标标签到正常标签的转换（触发器特征被逐步模糊）。</p>
<p>更具体的，作者将整个数据集划分为三部分：良性、毒化、可疑</p>
<figure>
<img data-src="./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240408150224608.png" alt="image-20240408150224608">
<figcaption aria-hidden="true">image-20240408150224608</figcaption>
</figure>
<ol type="1">
<li>若是在整个扩散模型的评估过程中，数据的标签都没发生偏移，代表样本是良性的，归类为<span class="math inline">\(B\)</span>​；</li>
<li>若是数据的标签发生偏移，从目标标签转移为真实标签<span class="math inline">\(y_g\)</span>，代表这是毒化数据，归类为<span class="math inline">\(P\)</span>​，选取经过扩散模型净化后的样本，加入到清洗后的数据集中。</li>
<li>造成第三种情况的有两种可能性：
<ol type="1">
<li>在后期迭代之前，可能无法有效地消除中毒图像上的触发特征，导致标签表现出从目标标签到真实标签的转换时已经在迭代的末期。</li>
<li>样本上的良性标签特征在通过扩散模型时被摧毁了。</li>
</ol></li>
</ol>
<h2 id="目标标签检测">目标标签检测</h2>
<p>直觉：在<span class="math inline">\(P\cup
S\)</span>中，标签为目标标签的样本和标签正常的样本之间的分布是有差异的。</p>
<p>构造一个集合： <span class="math display">\[
C_y=\bigcup_{(x_i,y_i)\in P\cup S}\{C_{(x_i,y_i)}|y_i=y\}
\]</span>
这样后，将集合分为几个小集合，另外一个直觉：含有目标标签的集合的分布比正常的分布混乱的多。</p>
<p>因此，计算这几个分布的KL散度，和正常样本集合对应标签的分布之间的差别，就能判断出<span class="math inline">\(y_t\)</span>了。</p>
<h2 id="净化数据集">净化数据集</h2>
<p>对于<span class="math inline">\(B\)</span>中的数据，都是良性数据，可以直接加入净化数据集；</p>
<p>对于<span class="math inline">\(P\)</span>​中的数据，若是其标签为目标标签，修改其标签为正常标签后，即可加入到正常数据集；</p>
<p>对于<span class="math inline">\(C_y\)</span>的其余部分，若是经过扩散模型前后的输入输出图片有显著不同，考虑这种情况：扩散模型将触发器移除掉了，而不是毁掉了良性特征，通过下面的式子判断二者之间的距离：</p>
<figure>
<img data-src="./DATAELIXIR-Purifying-Poisoned-Dataset-to-Mitigate-Backdoor-Attacks-via-Diffusion-Models/image-20240409205545430.png" alt="image-20240409205545430">
<figcaption aria-hidden="true">image-20240409205545430</figcaption>
</figure>
<p><span class="math inline">\(M\)</span>选取的是受害者模型，计算出这个距离后，选取前80%，作为良性数据。</p>
<p>对于在<span class="math inline">\(S\)</span>中具有目标标签的样本，本文选择使用干净的数据集（<span class="math inline">\(B\)</span>，纠正了标签的<span class="math inline">\(P\)</span>，通过距离判断的<span class="math inline">\(P\cup S\)</span>），训练出干净模型<span class="math inline">\(M^{&#39;}\)</span>，来判断剩下的样本的正确标签。</p>
<p>由于<span class="math inline">\(M^{&#39;}\)</span>训练时没有学习触发器的特征，所以能够通过样本中的原始标签特征来做判断，而不是触发器特征。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/03/python-package-tutorials/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/03/python-package-tutorials/" class="post-title-link" itemprop="url">python-package-tutorials</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-03 15:49:05" itemprop="dateCreated datePublished" datetime="2024-04-03T15:49:05+08:00">2024-04-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-25 14:59:31" itemprop="dateModified" datetime="2024-04-25T14:59:31+08:00">2024-04-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>教程，来自官网、blog等。</p>
<h1 id="hydra">Hydra</h1>
<h2 id="get-start">get start</h2>
<p>读取配置文件的一个包，可以读取制指定文件夹下的制定配置文件，安装方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install hydra-core</span><br></pre></td></tr></table></figure>
<p>这会安装<code>hydra, omegacong</code>等。</p>
<p>创建folder
<code>conf</code>，在里面创建我们的配置文件<code>config.yaml</code>:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">known_host:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="number">120.76</span><span class="number">.43</span><span class="number">.27</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">62222</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">chengyiqiu</span></span><br><span class="line">  <span class="attr">pwd:</span> <span class="string">secert</span></span><br></pre></td></tr></table></figure>
<p>运行下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hydra</span><br><span class="line"><span class="keyword">from</span> omegaconf <span class="keyword">import</span> DictConfig, OmegaConf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;./conf&#x27;</span>, config_name=<span class="string">&#x27;config&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">cfg: DictConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br><span class="line">    <span class="keyword">if</span> cfg.known_host.port == <span class="number">62222</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test()</span><br></pre></td></tr></table></figure>
<p>若是将cgf返回，得到的是None，但是可以在<code>test()</code>内部对cfg的内部进行判定。</p>
<p>也可以访问上级目录：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;..&#x27;</span>, config_name=<span class="string">&#x27;test&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_</span>(<span class="params">cfg: DictConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br></pre></td></tr></table></figure>
<p>也可以将config转变成Object，但是不能超过这个函数的生命周期，否则会变成<code>None</code>，在生命周期内部，可以将config进行传参，只要没超出生命周期即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;..&#x27;</span>, config_name=<span class="string">&#x27;test&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_</span>(<span class="params">cfg: DictConfig</span>):</span><br><span class="line">    <span class="comment">#  ---------lifetime start ---------</span></span><br><span class="line">    cfg = OmegaConf.to_object(cfg)  <span class="comment"># object</span></span><br><span class="line">    train(cfg)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="comment">#  ---------lifetime over ---------</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cfg = test_()  <span class="comment"># None</span></span><br><span class="line">    <span class="built_in">print</span>(cfg)</span><br></pre></td></tr></table></figure>
<h2 id="重载">重载</h2>
<p>可以通过命令行传入参数来重载配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ python get_start.py known_host.port=8888</span><br><span class="line">known_host:</span><br><span class="line">  host: 120.76.43.27</span><br><span class="line">  port: 8888</span><br><span class="line">  user: chengyiqiu</span><br><span class="line">  pwd: secert</span><br><span class="line"></span><br><span class="line">not ok</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;./conf&#x27;</span>, config_name=<span class="string">&#x27;config&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">cfg: DictConfig</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br><span class="line">    <span class="keyword">if</span> cfg.known_host.port == <span class="number">62222</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;not ok&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>
<p>此举动不会更改原始的yaml中的参数配置，但是当进程运行结束后，会创建日志，重载的配置：</p>
<figure>
<img data-src="./python-package-tutorials/image-20240403165108222.png" alt="image-20240403165108222">
<figcaption aria-hidden="true">image-20240403165108222</figcaption>
</figure>
<figure>
<img data-src="./python-package-tutorials/image-20240403165118016.png" alt="image-20240403165118016">
<figcaption aria-hidden="true">image-20240403165118016</figcaption>
</figure>
<h2 id="封装">封装</h2>
<p>若是想要在多个配置文件中进行选择，可以用对配置文件做进一步封装，如下目录树：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ tree ./</span><br><span class="line">./</span><br><span class="line">├── conf</span><br><span class="line">│   └── config.yaml</span><br><span class="line">├── get_start.py</span><br><span class="line">└── host</span><br><span class="line">    ├── config.yaml</span><br><span class="line">    └── user</span><br><span class="line">        ├── user1.yaml</span><br><span class="line">        └── user2.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>config.yaml</code>中的内容：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">defaults:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">user:</span> <span class="string">user1</span></span><br></pre></td></tr></table></figure>
<p><code>user1.yaml</code>中的内容：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">user:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">chengyiqiu</span></span><br><span class="line">  <span class="attr">password:</span> <span class="number">1234</span></span><br><span class="line">  <span class="attr">ipv4:</span> <span class="number">120.76</span><span class="number">.43</span><span class="number">.27</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">62222</span></span><br></pre></td></tr></table></figure>
<p>Code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@hydra.main(<span class="params">version_base=<span class="literal">None</span>, config_path=<span class="string">&#x27;./host&#x27;</span>, config_name=<span class="string">&#x27;config&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_default_config</span>(<span class="params">cfg: DictConfig</span>):</span><br><span class="line">    <span class="built_in">print</span>(OmegaConf.to_yaml(cfg))</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test_default_config()</span><br></pre></td></tr></table></figure>
<p>能够定向到<code>user1.yaml</code>，同样的方式，也可以使用重载来重新选择对应的配置文件；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ python get_start.py user=user2</span><br><span class="line">user:</span><br><span class="line">  user:</span><br><span class="line">    username: qcy</span><br><span class="line">    password: 12</span><br><span class="line">    port: 1</span><br><span class="line">    ipv4: 1.1.1.1</span><br></pre></td></tr></table></figure>
<p>也可以重载新的配置文件中的参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(tutorials) chengyiqiu@chengyiqiu:~/code/tutorials/Hydra$ python get_start.py user=user2 user.user.port=1111</span><br><span class="line">user:</span><br><span class="line">  user:</span><br><span class="line">    username: qcy</span><br><span class="line">    password: 12</span><br><span class="line">    port: 1111</span><br><span class="line">    ipv4: 1.1.1.1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="pytorch_lighting">pytorch_lighting</h1>
<h2 id="train">train</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyLightningModule</span>(L.LightningModule):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.model = model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch</span>):</span><br><span class="line">        x, y = batch</span><br><span class="line">        y_p = self.forward(x)</span><br><span class="line">        loss = torch.nn.functional.cross_entropy(y_p, y)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">        optimizer = torch.optim.SGD(self.model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    device = <span class="string">&quot;cuda:0&quot;</span></span><br><span class="line">    net = ResNet18(num_classes=<span class="number">10</span>).to(device)</span><br><span class="line">    batch, nw = <span class="number">32</span>, <span class="number">2</span></span><br><span class="line">    mask_path = <span class="string">&#x27;../resource/badnet/trigger_image.png&#x27;</span></span><br><span class="line">    trigger_path = <span class="string">&#x27;../resource/badnet/trigger_image_grid.png&#x27;</span></span><br><span class="line">    train_dataset, test_dataset = prepare_poisoning_dataset(ratio=<span class="number">1e-1</span>, mask_path=mask_path, trigger_path=trigger_path)</span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        dataset=train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch, num_workers=nw</span><br><span class="line">    )</span><br><span class="line">    test_loader = DataLoader(</span><br><span class="line">        dataset=test_dataset, shuffle=<span class="literal">True</span>, batch_size=batch, num_workers=nw</span><br><span class="line">    )</span><br><span class="line">    model = MyLightningModule(model=net)</span><br><span class="line">    trainer = L.Trainer(max_epochs=<span class="number">100</span>, devices=[<span class="number">0</span>])</span><br><span class="line">    trainer.fit(model=model, train_dataloaders=train_loader)</span><br></pre></td></tr></table></figure>
<p>继承<code>L.LightningModule</code>，重写4个方法即可训练。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/01/readme-server/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/01/readme-server/" class="post-title-link" itemprop="url">readme_server</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-01 13:20:12" itemprop="dateCreated datePublished" datetime="2024-04-01T13:20:12+08:00">2024-04-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-05 13:23:13" itemprop="dateModified" datetime="2024-05-05T13:23:13+08:00">2024-05-05</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          Here's something encrypted, password is required to continue reading.
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2024/04/01/readme-server/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/30/follow-who/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/30/follow-who/" class="post-title-link" itemprop="url">follow_who</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-30 18:57:18 / Modified: 19:02:16" itemprop="dateCreated datePublished" datetime="2024-03-30T18:57:18+08:00">2024-03-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本文记录有哪些需要关注的课题组，以便后续跟进:)</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 19%">
<col style="width: 17%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">姓名</th>
<th style="text-align: center;">单位</th>
<th style="text-align: center;">研究方向</th>
<th>链接</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">吴保元</td>
<td style="text-align: center;">香港中文大学（深圳）</td>
<td style="text-align: center;">后门攻击，对抗攻击</td>
<td><a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=JNTG1KoAAAAJ&amp;hl=zh-CN">‪Baoyuan
Wu‬ - ‪Google 学术搜索‬</a></td>
</tr>
<tr class="even">
<td style="text-align: center;">王骞</td>
<td style="text-align: center;">武汉大学</td>
<td style="text-align: center;">对抗攻击</td>
<td><a target="_blank" rel="noopener" href="http://nisplab.whu.edu.cn/people.html">NIS&amp;P Lab
(whu.edu.cn)</a></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td></td>
</tr>
</tbody>
</table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/29/Denoising-Diffusion-Probabilistic-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/29/Denoising-Diffusion-Probabilistic-Models/" class="post-title-link" itemprop="url">Denoising_Diffusion_Probabilistic_Models</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-29 11:33:53" itemprop="dateCreated datePublished" datetime="2024-03-29T11:33:53+08:00">2024-03-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-09 11:58:02" itemprop="dateModified" datetime="2024-05-09T11:58:02+08:00">2024-05-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>DDPM，于Stable
Diffusion之前，后续关于Diffusion的文章基本都会引用这篇。</p>
<p>NIPS 2020</p>
<p>摘要：我们使用扩散概率模型展示了高质量的图像合成结果，这是一种受非平衡热力学考虑启发的潜在变量模型。我们最好的结果是通过对加权变分界进行训练获得的，该边界是根据扩散概率模型和与朗之万动力学的去噪分数匹配之间的新联系设计的，我们的模型自然承认渐进式有损解压缩方案，可以解释为自回归解码的泛化。在无条件
CIFAR10 数据集上，我们获得了 9.46 的 Inception 分数和 3.17 的最新 FID
分数。在 256x256 LSUN 上，我们获得了类似于 ProgressiveGAN
的样本质量。</p>
<h1 id="介绍">介绍</h1>
<p>本文提出的方法是建立在<a href="%5BDeep%20Unsupervised%20Learning%20using%20Nonequilibrium%20Thermodynamics%20(mlr.press)%5D(https://proceedings.mlr.press/v37/sohl-dickstein15.html)">扩散概率模型</a>上的，扩散概率模型提出了这种“先摧毁数据的分布，然后通过机器学习来重构这个分布，从而学习这个重构的过程”。扩散模型是一个参数化的马尔可夫过程，通过一个变分推导，在有限时间内来生成出符合数据分布的样本。马尔可夫链的转变过程（学习过程）是通过逆向扩散过程（前向过程）。</p>
<p>论文中提到了朗之动力学，这篇<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/562654949">博客</a>介绍了朗之动力学和扩散模型之间的关系。</p>
<h1 id="背景">背景</h1>
<p>还是对扩散概率模型进行介绍：</p>
<p>大体上，扩散模型分为正向过程<span class="math inline">\(q(.)\)</span>和反向过程<span class="math inline">\(p_\theta(.)\)</span>，正向过程比较简单，就是不断往原来的分布上加噪声，直到分布被摧毁，反向过程的则是重构这个过程。</p>
<p>反向过程的初始条件为： <span class="math display">\[
p(x_T)=\mathcal N(x_T;0,I)
\]</span>
最开始这个噪声的分布是均值0方差1的正态分布，然后通过下面的公式进行迭代：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329121950148.png" alt="image-20240329121950148" style="zoom:33%;"></p>
<p>整个反向过程可以合并起来写成下面的公式：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329122324323.png" alt="image-20240329122324323" style="zoom:33%;"></p>
<p>正向过程：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329133247082.png" alt="image-20240329133247082">
<figcaption aria-hidden="true">image-20240329133247082</figcaption>
</figure>
<p><span class="math inline">\(\alpha_2,...,\beta_t\)</span>​表示方差调度器，可以在训练中学习，也可以固定。这里作者直接将他们作为超参数固定了。</p>
<p>给定<span class="math inline">\(\alpha_t=1-\beta_t\)</span>，正向过程可以写成下面的形式：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329134045273.png" alt="image-20240329134045273" style="zoom:33%;"></p>
<p>也可以换一种形式写出来：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329143400805.png" alt="image-20240329143400805" style="zoom: 33%;"></p>
<p>通过负对数似然来对随机噪声进行优化：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329134406665.png" alt="image-20240329134406665" style="zoom:33%;"></p>
<p>通过改进，将<span class="math inline">\(L\)</span>写成下面公式的形式：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329135716143.png" alt="image-20240329135716143" style="zoom:33%;"></p>
<p>这样在计算上比较简单，计算两个噪声的KL散度，之前的公式则是需要通过求解高方差蒙特卡洛估计。</p>
<p>使用KL散度将<span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>和前向过程的后验进行比较，在<span class="math inline">\(x_0\)</span>已知的情况下：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329141610974.png" alt="image-20240329141610974" style="zoom:33%;"></p>
<hr>
<p>发现很多公式不理解，于是找博客、视频解说。</p>
<h1 id="算法部分">算法部分</h1>
<p>首先，看看DDPM的算法，<strong>训练过程</strong>：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329203458307.png" alt="image-20240329203458307" style="zoom:50%;"></p>
<p>line 2表示从我们的数据中采样一张真实样本<span class="math inline">\(x_0\)</span>；</p>
<p>line 3表示得到当前训练的step，这个后面会feed给噪声预测器中去；</p>
<p>line 5则是对噪声预测器做优化：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240329204358315.png" alt="image-20240329204358315" style="zoom:50%;"></p>
<p><strong>采样过程</strong>：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240330095440136.png" alt="image-20240330095440136" style="zoom:50%;"></p>
<p>line 1：从正态分布中采样一个杂讯，作为原始输入<span class="math inline">\(x_T\)</span></p>
<p>line 2：进入循环，有T次</p>
<p>line 3: 从正态分布中采样一个杂讯，作为后面的约束</p>
<p>line 4: 开始对上一步的输出进行去噪处理：</p>
<h1 id="原理解析">原理解析</h1>
<p>反向过程的流程：</p>
<ul>
<li>一共有T个step，每一步都会将上一步输出的噪声减少一部分，直到最后得到一张清晰的图片。</li>
</ul>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240331102006299.png" alt="image-20240331102006299" style="zoom:50%;"></p>
<p>其原理很巧妙：</p>
<p><strong>The sculpture is already complete within the marble block,
before I start my work. It is already there, I just have to chisel away
the superfluous material. - Michelangelo</strong></p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240331102055942.png" alt="image-20240331102055942" style="zoom:50%;"></p>
<p>denoise在不同的step产生的noice是不一样的，当step比较大的时候，denoice会产生一个比较大的噪声，然后消除掉这个噪声，如下图所示：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240331102249170.png" alt="image-20240331102249170" style="zoom:50%;"></p>
<p>denoice并不是一个e2e的模型：</p>
<p>为什么不训练一个e2e的模型，直接输出一张带有杂讯的猫？</p>
<ul>
<li>生成噪声比较简单，若是生成一张图，计算量比较大。</li>
<li>直接生成一张带杂讯的猫相当于model已经可以进行绘画了</li>
</ul>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240331102413862.png" alt="image-20240331102413862">
<figcaption aria-hidden="true">image-20240331102413862</figcaption>
</figure>
<p>denoice的训练：</p>
<p>ground truth的来源是正向过程添加的高斯噪声。</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240331102651258.png" alt="image-20240331102651258" style="zoom: 50%;"></p>
<p>正向过程：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240331102859501.png" alt="image-20240331102859501" style="zoom:50%;"></p>
<h1 id="数学原理">数学原理</h1>
<ol type="1">
<li><p>用极大似然估计来衡量原始分布和生成模型分布之间的距离</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240506184243810.png" alt="image-20240506184243810">
<figcaption aria-hidden="true">image-20240506184243810</figcaption>
</figure>
<p>从极大似然估计到KL散度</p></li>
<li><p>DM中的<span class="math inline">\(P_\theta(x)\)</span>很难计算，VAE是这样计算的：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240506184845417.png" alt="image-20240506184845417">
<figcaption aria-hidden="true">image-20240506184845417</figcaption>
</figure>
<p>​ <img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240506185251821.png" alt="image-20240506185251821"></p></li>
<li><p>DDPM中计算<span class="math inline">\(P_\theta(x)\)</span>​</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240506185546697.png" alt="image-20240506185546697">
<figcaption aria-hidden="true">image-20240506185546697</figcaption>
</figure></li>
<li><p>DDPM最大化某一个分布：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240506191041158.png" alt="image-20240506191041158">
<figcaption aria-hidden="true">image-20240506191041158</figcaption>
</figure></li>
</ol>
<h1 id="重推">重推</h1>
<p>首先先看演算法，算法中的部分已经用到了推导的结论了。</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507121118865.png" alt="image-20240507121118865">
<figcaption aria-hidden="true">image-20240507121118865</figcaption>
</figure>
<p><span class="math inline">\(q(.)\)</span>是现实世界所有图片的总体，从现实世界中取出一张真实图片，为<span class="math inline">\(x_0\)</span></p>
<p>t是从一个均匀分布中随机取出来的。</p>
<p>noice predictor的输入是<span class="math inline">\(x_t\)</span>和<span class="math inline">\(t\)</span>，输出是预测的noice。</p>
<p>这里有一个关键点，noice
predictor的内部是怎样的，<strong>怎么根据<span class="math inline">\(x_t\)</span>和<span class="math inline">\(t\)</span>算出noice的。</strong></p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507121441471.png" alt="image-20240507121441471">
<figcaption aria-hidden="true">image-20240507121441471</figcaption>
</figure>
<p>sample的过程就是infer的过程。</p>
<p>sample的关键是：<strong>为什么<span class="math inline">\(x_t\)</span>减去的predict
noice前要加系数，大括号的外面为何要加系数，最后为什么要加上这一个杂讯？</strong></p>
<p>所有的疑问可以从后面的数学推导得到答案。</p>
<h2 id="扩散一步到位">扩散：一步到位</h2>
<p>理想中的扩散过程应该是一步一步往图像上加噪声，直到图片变成高斯噪声。</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507121845776.png" alt="image-20240507121845776">
<figcaption aria-hidden="true">image-20240507121845776</figcaption>
</figure>
<p>但是实际上，添加噪声是一步到位的。</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507121914396.png" alt="image-20240507121914396">
<figcaption aria-hidden="true">image-20240507121914396</figcaption>
</figure>
<p>推导一下这个过程： <span class="math display">\[
\begin{flalign}
&amp;x_1=\sqrt \alpha_1 x_0+\sqrt{1-\alpha_1}\epsilon_1 \\
&amp;x_2=\sqrt \alpha_2 x_1+\sqrt{1-\alpha_2}\epsilon_2 \\
=&amp;\sqrt \alpha_2(\sqrt \alpha_1
x_0+\sqrt{1-\alpha_1}\epsilon_1)+\sqrt{1-\alpha_2}\epsilon_2 \\
=&amp;\sqrt{\alpha_2\alpha_1}x_0+\sqrt{\alpha_2(1-\alpha_1)}\epsilon_1+\sqrt{1-\alpha_2}\epsilon_2
\\
=&amp;\sqrt{\alpha_2\alpha_1}x_0+\sqrt{1-\alpha_2\alpha_1}\epsilon_3&amp;
\end{flalign}
\]</span> 从(5)-&gt;(6)的原因是：由于<span class="math inline">\(\epsilon\sim\mathcal N(0,1)\)</span>，<span class="math inline">\(\epsilon_2,
\epsilon_2\)</span>是独立的，正态分布的公式，(5)后面两个噪声： <span class="math display">\[
\begin{flalign}
&amp;\epsilon_1^{&#39;}\sim \mathcal N(0,\alpha_2-\alpha_1\alpha_2) \\
&amp;\epsilon_2^{&#39;}\sim \mathcal N(0,1-\alpha_2)
\end{flalign}
\]</span> 由于正态分布的可加性，所以我们可以直接将这两项合并： <span class="math display">\[
\epsilon_3^{&#39;}\sim \mathcal N(0, 1-\alpha_1\alpha_2)
\]</span> 于是可以将系数提出来，直接从标准正态分布中采样即可。</p>
<p>为了便于书写，将：<span class="math inline">\(\alpha_1\alpha_2...\alpha_t=\bar
\alpha_t\)</span></p>
<h2 id="生成模型的目标">生成模型的目标</h2>
<p>生成模型的目标：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507131919505.png" alt="image-20240507131919505">
<figcaption aria-hidden="true">image-20240507131919505</figcaption>
</figure>
<p>通过NN生成的分布和真实世界的分布一样，将概率分布展开，更容易理解。
<span class="math display">\[
P_\theta(x)=\int_zP_\theta(x|z)P(z)dz
\]</span> 目标就是最大化从<span class="math inline">\(P_{data}\)</span>中sample出的m个样本的概率<span class="math inline">\(P_\theta\)</span>的乘积。</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507132546801.png" alt="image-20240507132546801">
<figcaption aria-hidden="true">image-20240507132546801</figcaption>
</figure>
<p>这里补充KL散度的定义，也就是信息论中的相对熵： <span class="math display">\[
D_{KL}(P\Vert Q)=\int p(x)\ln(\frac{p(x)}{q(x)})dx
\]</span>
因此，上述推导的结论是：要想两个分布相近，通过极大似然估计，推导出的结果是最小化两个分布的KL散度。</p>
<h2 id="vae计算p_theta的方法">VAE计算<span class="math inline">\(P_\theta\)</span>的方法</h2>
<p>上面说到<span class="math inline">\(P_\theta(x)=\int_zP(z)P_\theta(x\vert
z)dz\)</span>，我们讨论的是生成模型的通用形式，从手上的初始分布中采样一个<span class="math inline">\(z\)</span>​，这个概率是已知的。</p>
<p>VAE中的做法是：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507135141891.png" alt="image-20240507135141891">
<figcaption aria-hidden="true">image-20240507135141891</figcaption>
</figure>
<p>输入是x，通过一个encoder，得到latent z。</p>
<p>也就是说，要得到<span class="math inline">\(\theta^*\)</span>，就要计算出：在假定x已知的情况下，从z的分布<span class="math inline">\(q()\)</span>中采样，求出<span class="math inline">\(\log(\frac{q(x\vert z)}{P(z\vert
x)})\)</span>的期望的最大值。</p>
<h2 id="ddpm计算p_theta">DDPM计算<span class="math inline">\(P_\theta\)</span></h2>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507135648112.png" alt="image-20240507135648112">
<figcaption aria-hidden="true">image-20240507135648112</figcaption>
</figure>
<p>和VAE的推导比较类似，得到的结论也有相似的结构。</p>
<p>怎么最大化这个期望，这篇paper专门进行推导的，我们直接看结论。</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507140315856.png" alt="image-20240507140315856">
<figcaption aria-hidden="true">image-20240507140315856</figcaption>
</figure>
<p>目标的下界是：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507140542568.png" alt="image-20240507140542568">
<figcaption aria-hidden="true">image-20240507140542568</figcaption>
</figure>
<ol type="1">
<li><p>第二项是常数，可以不用管（<span class="math inline">\(q(x_T\vert
x_0)\)</span>是扩散过程，人为控制；<span class="math inline">\(P(x_T)\)</span>是从正态分布中采样一个初始的噪声，也是人为控制，没有<span class="math inline">\(\theta\)</span>）。</p></li>
<li><p>第三项中，<span class="math inline">\(P_\theta(x_{t-1}\vert
x_t)\)</span>是逆扩散过程，是由神经网络决定的，而<span class="math inline">\(q(x_{t-1}\vert x_t,x_0)\)</span>： <span class="math display">\[
\begin{flalign}
&amp;q(x_{t-1}\vert x_t,x_0) \\
=&amp;\frac{q(x_{t-1},x_t,x_0)}{q(x_t,x_0)} \\
=&amp;\frac{q(x_0)q(x_{t-1}\vert x_0)q(x_t\vert
x_{t-1})}{q(x_0)q(x_t\vert x_0)} \\
=&amp;\frac{q(x_{t-1}\vert x_0)q(x_t\vert x_{t-1})}{q(x_t\vert
x_0)}&amp;
\end{flalign}
\]</span>
这三项都是可以计算的高斯分布，另一篇paper中推导了这个算式最后得到的是一个什么样的分布：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507141837908.png" alt="image-20240507141837908">
<figcaption aria-hidden="true">image-20240507141837908</figcaption>
</figure>
<p>得到了这个分布的均值和方差：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507142029958.png" alt="image-20240507142029958">
<figcaption aria-hidden="true">image-20240507142029958</figcaption>
</figure>
<p>那么怎么最小化这两个分布的KL散度： <span class="math display">\[
KL(p,q)=\log
\frac{\sigma_2}{\sigma_1}+\frac{\sigma_1^2}{\sigma_2^2}+\frac{(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}
\]</span>
不用直接带入，根据实验，直接最小化这两个分布的均值的距离即可。</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507142708377.png" alt="image-20240507142708377">
<figcaption aria-hidden="true">image-20240507142708377</figcaption>
</figure></li>
<li><p>第一项参考别人的博客，是这样解释的：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507204854473.png" alt="image-20240507204854473">
<figcaption aria-hidden="true">image-20240507204854473</figcaption>
</figure></li>
</ol>
<p>最后，<span class="math inline">\(q(x_{t-1}\vert
x_t,x_0)\)</span>分布的均值，就是diffusion model输出的结果（<span class="math inline">\(x_t\)</span>减去predicted noice）：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507205224196.png" alt="image-20240507205224196">
<figcaption aria-hidden="true">image-20240507205224196</figcaption>
</figure>
<p>将<span class="math inline">\(x_0\)</span>换成<span class="math inline">\(x_t\)</span>，得到的就是DDPM演算法中的sample的式子：</p>
<figure>
<img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507205458379.png" alt="image-20240507205458379">
<figcaption aria-hidden="true">image-20240507205458379</figcaption>
</figure>
<h2 id="总结ddpm">总结DDPM</h2>
<ol type="1">
<li><p>DDPM的出发点和大多数生成模型一样，目标是使得预测的数据分布<span class="math inline">\(P_\theta\)</span>和真实世界的数据分布<span class="math inline">\(P_{data}\)</span>​一致，以此出发，通过极大似然估计，发现其实等价于最小化两个分布<span class="math inline">\(P_\theta\)</span>和<span class="math inline">\(P_{data}\)</span>​之间的KL。</p>
<p>然后有一个比较直觉的式子： <span class="math display">\[
P_\theta(x\vert z)\propto \exp (-\Vert G(z)-x\Vert_2)
\]</span> 此时目标变成了最大化<span class="math inline">\(P_\theta(x)\)</span></p></li>
<li><p>问题在于如何计算<span class="math inline">\(P_\theta\)</span>：
<span class="math display">\[
P_\theta(x)=\int_z q(z\vert x)p(x)dz
\]</span>
可以写成上面的形式，用VAE的推导，取对数，得到下界，用来近似<span class="math inline">\(P_\theta(x)\ge E_{q(z\vert
x)}(\frac{P(x,z)}{q(z\vert x)})\)</span>。</p>
<p>对于DDPM，用同样的方法，可以推导出相似的结构，<span class="math inline">\(P_\theta(x)\ge
E_{q(x_1:x_t|x_0)}(\frac{P(x_0:x_t)}{q(x_1:x_t\vert x_0)})\)</span>​</p>
<p>对于不等号右边的部分，通过大量推导得到下面的式子：</p>
<p><img data-src="./Denoising-Diffusion-Probabilistic-Models/image-20240507140542568.png" alt="image-20240507140542568" style="zoom:33%;"></p>
<p>此时问题变成了最小化第三个KL项了，也就是说那两个分布的均值越接近越好。</p></li>
</ol>
<h1 id="参考">参考</h1>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/530602852">DDPM解读（一）|
数学基础，扩散与逆扩散过程和训练推理方法 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://speech.ee.ntu.edu.tw/~hylee/ml/ml2023-course-data/DDPM%20(v7).pdf">PowerPoint
簡報 (ntu.edu.tw)</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/25/Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/25/Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/" class="post-title-link" itemprop="url">Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-25 16:09:31" itemprop="dateCreated datePublished" datetime="2024-03-25T16:09:31+08:00">2024-03-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-03-26 15:14:20" itemprop="dateModified" datetime="2024-03-26T15:14:20+08:00">2024-03-26</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>为了一门水课汇报而看的论文:(</p>
<p>深度强化学习的<strong>低样本效率</strong>和<strong>奖励函数设计</strong>的困难阻碍了其在实际应用中的使用，</p>
<p>两个问题：</p>
<ul>
<li>低样本效率导致的问题是：智能体需要与环境进行大量的交互才能学习到一个有效的策略。（例如在没有信号灯的交叉口穿越或在密集交通中进行无保护的左转。）</li>
<li>奖励函数的设计：设计不当的奖励函数可能会导致智能体错误地利用奖励函数并坚持意外的行为，这样下来调参比较费时间。尽管可以使用一些技术（如逆强化学习）从人类驾驶数据中学习奖励函数，但通常假设奖励函数的某些结构（例如，不同手工制作特征的线性组合），这在实践中可能不成立。</li>
</ul>
<p>本文提出了一个新颖的框架，将人类先验知识整合到DRL中，以提高样本效率并节省设计复杂奖励函数的努力。三个部分：专家演示、策略推导和强化学习</p>
<ul>
<li>专家演示：人类专家展示了他们执行任务的过程，他们的行为被存储为状态-动作对。</li>
<li>策略推导：通过行为克隆和依赖于演示数据的不确定性估计，推导出模仿专家策略。</li>
<li>强化学习：模仿专家策略被用来指导DRL智能体的学习，通过规范DRL智能体策略和模仿专家策略之间的KL散度。</li>
</ul>
<h1 id="相关工作">相关工作</h1>
<h2 id="先验知识">先验知识</h2>
<p>利用人类先验知识进行学习并不是首次提出，前人的一些工作：</p>
<ul>
<li>提出了在基于RL的控制系统中添加一个安全检查模块，以防止不安全的探索并加速训练。</li>
<li>提出了一种实时人类指导为基础的学习方法，允许人类专家实时介入训练过程并提供指导，从而使智能体能够从人类指导和自我探索中学习。</li>
</ul>
<h2 id="专家演示">专家演示</h2>
<ul>
<li>使用专家演示通过模仿（监督）学习预训练策略，以将策略初始化为合理的性能水平，然后应用RL以获得更好的策略</li>
<li>将专家演示添加到经验回放缓冲区中，用于离线RL算法，并从专家演示和智能体交互中采样经验以更新策略</li>
<li>……</li>
</ul>
<h1 id="背景知识">背景知识</h1>
<h2 id="行为克隆">行为克隆</h2>
<p>因为专家策略不能直接访问，因此大多数使用的方法是通过模仿学习来学习专家演示，来对专家策略进行近似。</p>
<p>专家演示即为一个数据集<span class="math inline">\(D^E:\{\tau_i\}\)</span>，<span class="math inline">\(\tau_i\)</span>是专家演示的每一条轨迹，由状态-动作对组成，模拟专家策略用<span class="math inline">\(\pi ^E\)</span>表示，用下式进行优化：</p>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326133327321.png" alt="image-20240326133327321">
<figcaption aria-hidden="true">image-20240326133327321</figcaption>
</figure>
<p>在通常的行为克隆中，专家策略是一个参数化神经网络<span class="math inline">\(\theta\)</span>，网络的输入是一个状态向量，输出则是一个动作:
<span class="math display">\[
a_t=\pi_\theta(s)
\]</span> 优化路径为：</p>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326134743328.png" alt="image-20240326134743328">
<figcaption aria-hidden="true">image-20240326134743328</figcaption>
</figure>
<p>但是这种方法得到的是确定性策略，但是需要得到的是一个动作分布，来规范RL的策略。</p>
<h2 id="策略不确定性">策略不确定性</h2>
<p>策略不确定性是指：对于同一个状态，输出的动作并不唯一。内在原因其实是因为对于一个人类专家，面对同一个状态也可能会产生多种可行的动作。</p>
<p>因此，本文作者采取参数概率分布的形式来输出动作，而不是一个确定的动作。假设动作服从高斯分布，然后通过下式来优化策略：</p>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326140653445.png" alt="image-20240326140653445">
<figcaption aria-hidden="true">image-20240326140653445</figcaption>
</figure>
<h2 id="模型不确定性">模型不确定性</h2>
<p>模型不确定性是指：策略的预测均值和方差对于不在训练数据集中的数据仍然是不确定和不可靠的。它源于在状态空间的某些区域缺乏训练数据，并且量化了模型对其动作输出的置信度。估计这种不确定性对于我们提出的方法中的模仿专家策略至关重要，因为RL智能体经常会遇到不在演示数据集中的状态，因此需要对分布外状态的置信度进行量化。</p>
<p>本文使用多个网络M（采用随机策略），使用不同的随机初始化参数和训练数据来进行训练，将最终的均值和方差来进行混合：</p>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326141630523.png" alt="image-20240326141630523">
<figcaption aria-hidden="true">image-20240326141630523</figcaption>
</figure>
<p>这种策略类似于集成学习。</p>
<h1 id="深度强化学习与模仿专家先验">深度强化学习与模仿专家先验</h1>
<h2 id="框架">框架</h2>
<p>整体框架如下：</p>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326142544542.png" alt="image-20240326142544542">
<figcaption aria-hidden="true">image-20240326142544542</figcaption>
</figure>
<p>策略推倒部分，加入了策略不确定性和模型不确定性，需要单独说明下。</p>
<p>当专家策略的方差比较小，证明策略对输出比较自信，这时直接采取专家策略，避免不必要的探索；当专家策略的方差很大时，其均值就不是很合理，这种情况下，应该在接近专家策略的情况下，进行更多的探索，以探索到更好的策略。</p>
<h2 id="演员评论家算法">演员评论家算法</h2>
<p>本文提出的演员-评论家算法是一种结合了模仿学习（Imitation
Learning）和强化学习（Reinforcement Learning,
RL）的方法，用于提高自动驾驶智能体的学习效率。该算法包含两个主要部分：演员（Actor）和评论家（Critic）。演员负责生成动作，而评论家负责评估动作的价值。</p>
<p>算法中包含以下网络：</p>
<ul>
<li>两个Q函数网络<span class="math inline">\(Q_{\Phi_1}\)</span>和<span class="math inline">\(Q_{\Phi_2}\)</span>，用于评估状态-动作对的价值。</li>
<li>一个价值函数网络<span class="math inline">\(V_\psi\)</span>，用于评估状态的价值。</li>
<li>一个策略网<span class="math inline">\(\pi_\theta\)</span>，用于生成动作。</li>
</ul>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326151252860.png" alt="image-20240326151252860">
<figcaption aria-hidden="true">image-20240326151252860</figcaption>
</figure>
<figure>
<img data-src="./Efficient-Deep-Reinforcement-Learning-with-Imitative-Expert-Priors-for-Autonomous-Driving/image-20240326151317752.png" alt="image-20240326151317752">
<figcaption aria-hidden="true">image-20240326151317752</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/24/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/24/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/" class="post-title-link" itemprop="url">High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-03-24 14:16:00 / Modified: 14:22:31" itemprop="dateCreated datePublished" datetime="2024-03-24T14:16:00+08:00">2024-03-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>CVPR 2022, stable diffusion</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/24/Neural-Network-Diffusion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/24/Neural-Network-Diffusion/" class="post-title-link" itemprop="url">Neural_Network_Diffusion</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-24 10:53:40" itemprop="dateCreated datePublished" datetime="2024-03-24T10:53:40+08:00">2024-03-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-16 18:25:31" itemprop="dateModified" datetime="2024-04-16T18:25:31+08:00">2024-04-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Under ICLR 2024 double-blind review</p>
<p>使用一个自动编码器，来提取训练模型参数中的隐藏表征，然后扩散模型根据这些隐藏参数表征，合成一些随机噪声，输出一些新的表征给自动编码器的解码器部分，输出就是神经网络的参数。</p>
<h1 id="神经网络扩散">神经网络扩散</h1>
<h2 id="初步了解扩散模型">初步了解扩散模型</h2>
<p>扩散模型分为两个过程，前向过程和反向过程：</p>
<ul>
<li><p>前向过程是对原始图像不断添加高斯噪声（由<span class="math inline">\(\beta\)</span>约束），经过<span class="math inline">\(T\)</span>步后，得到一个随机高斯噪声（<span class="math inline">\(T\to \infty\)</span>​时，最后得到的一定是噪声）</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240324121348853.png" alt="image-20240324121348853">
<figcaption aria-hidden="true">image-20240324121348853</figcaption>
</figure>
<ul>
<li><span class="math inline">\(q(.)\)</span>：前向过程</li>
<li><span class="math inline">\(N(.)\)</span>：高斯噪声</li>
<li><span class="math inline">\(\beta\)</span>：约束</li>
<li><span class="math inline">\(I\)</span>：单位矩阵</li>
</ul></li>
<li><p>反向过程是前向过程反过来，期望通过选连一个去噪网络（denoising
network），移除掉<span class="math inline">\(x_T\)</span>上的噪声，直到恢复出原始图像来。</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240324121522824.png" alt="image-20240324121522824">
<figcaption aria-hidden="true">image-20240324121522824</figcaption>
</figure>
<ul>
<li><span class="math inline">\(p_\theta (.)\)</span>：反向过程，<span class="math inline">\(\theta\)</span>是可学习的参数</li>
<li><span class="math inline">\(\mu _\theta (.)\)</span>：通过<span class="math inline">\(\theta\)</span>估计的高斯噪声的均值</li>
<li><span class="math inline">\(\sum _\theta (.)\)</span>：通过<span class="math inline">\(\theta\)</span>​估计的高斯噪声的方差</li>
</ul></li>
<li><p>去噪网络的优化：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240324121845235.png" alt="image-20240324121845235">
<figcaption aria-hidden="true">image-20240324121845235</figcaption>
</figure>
<p><span class="math inline">\(D_{KL}(.\vert \vert
.)\)</span>是通过KL散度来计算两个分布之间的差距。</p></li>
</ul>
<p>扩散模型的可行之处在于：能够通过反向过程找到一个去噪网络，将原始的高斯分布转化成最终期望得到的分布。</p>
<h2 id="整体架构">整体架构</h2>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240324124652683.png" alt="image-20240324124652683">
<figcaption aria-hidden="true">image-20240324124652683</figcaption>
</figure>
<h2 id="参数自动编码器">参数自动编码器</h2>
<p>首先收集k个训练性能良好的模型，其参数可以表示为：<span class="math inline">\(S=[s_1,...,s_K]\)</span>，将这些参数展开平铺成向量：<span class="math inline">\(V=[v_1,...v_K]\)</span>，然后通过编码器来提取参数潜在的特征：
<span class="math display">\[
Z=[z_1,...,z_K]=f_{encoder}(V,\sigma)
\]</span> 然后将提取出的潜在参数特征<span class="math inline">\(Z\)</span>输入到解码器中生成重构后的参数： <span class="math display">\[
V^{&#39;}=[v_1^{&#39;},...,v_K^{&#39;}]=f_{decoder}(Z,\rho)
\]</span> 其中<span class="math inline">\(\sigma,\rho\)</span>是参数。</p>
<p>优化路径是最小化MSE： <span class="math display">\[
L_{MSE}=\frac{1}{K}\sum _1^K\Vert v _k-v_k^{&#39;}\Vert^2
\]</span></p>
<h2 id="参数生成">参数生成</h2>
<p>若是直接采取将参数<span class="math inline">\(V\)</span>输入到编码器，然后解码器输出重构后的参数<span class="math inline">\(V_{&#39;}\)</span>，这样会导致过大的存储开销，尤其是当<span class="math inline">\(V\)</span>的维度比较高的时候。</p>
<p>因此，作者采用DDPM中的优化过程来优化去噪网络； <img data-src="./Neural-Network-Diffusion/image-20240324133345603.png" alt="image-20240324133345603"></p>
<ul>
<li><span class="math inline">\(\epsilon\)</span>：高斯噪声</li>
<li><span class="math inline">\(\theta\)</span>：去噪网络的参数</li>
<li><span class="math inline">\(\epsilon
_\theta\)</span>：去噪网络生成的噪声</li>
<li><span class="math inline">\(t\)</span>：每一轮</li>
<li><span class="math inline">\(\bar \alpha
_t\)</span>：每一轮的噪声强度</li>
</ul>
<h1 id="实验">实验</h1>
<h2 id="设置">设置</h2>
<ol type="1">
<li><p><strong>数据集</strong></p>
<p>MNIST (LeCun et al., 1998), CIFAR-10/100 (Krizhevsky et al., 2009),
ImageNet-1K. (Deng et al., 2009), STL-10 (Coates et al., 2011), Flowers
(Nilsback &amp; Zisserman, 2008), Pets (Parkhi et al., 2012), F-101
(Bossard et al., 2014)</p></li>
<li><p><strong>架构</strong></p>
<p>最开始是在比较小的模型上实验的，这些模型由卷积层、池化层、全连接层组成：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240328153848280.png" alt="image-20240328153848280">
<figcaption aria-hidden="true">image-20240328153848280</figcaption>
</figure>
<p>使用的卷积层是2D卷积，参考的是DDPM（采用的U-net，生成高质量图片，用的2D-conv），但是效果并不好，可能的原因是图片像素和参数不能一概处理，因此换成了1D-conv，对比结果如下：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240328162902109.png" alt="image-20240328162902109">
<figcaption aria-hidden="true">image-20240328162902109</figcaption>
</figure>
<p>在更换卷积层的时候，作者也考虑了下直接将卷积层更换为FC，二者效果差不多，但是1D-conv的存储开销低于FC，因此还是选取了1D-conv：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240328163035736.png" alt="image-20240328163035736">
<figcaption aria-hidden="true">image-20240328163035736</figcaption>
</figure>
<p>此外，还做了消融实验，找到了一个参数<span class="math inline">\(K=200\)</span>使得模型的性能最优。</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240328165743211.png" alt="image-20240328165743211">
<figcaption aria-hidden="true">image-20240328165743211</figcaption>
</figure>
<p>作者是在扩大模型架构的时候发现了存储开销特别大的问题，灵感来于stable
diffusion，作者采用了一个自动编码器来提取潜在特征，以此来对模型的参数进行降维。</p></li>
<li><p><strong>准备训练数据</strong></p>
<p>准备了200个独立的高性能参数来训练DiffNet，对于架构简单，参数少的模型，直接从头开始训练；对于架构复杂的，则是在预训练模型的基础上来进行的。</p></li>
<li><p><strong>训练细节</strong></p>
<p>首先把自动编码器训练2000轮，然后将潜在特征和解码器的参数都保存起来。</p>
<p>然后训练扩散模型来生成表征，扩散模型的结构式基于1D-conv的U-Net，</p></li>
<li><p><strong>推断阶段</strong></p>
<p>将100个噪声输入到扩散模型中去，生成了100个模型，选取其中在训练数据集上性能最好的网络。整个的性能图如下：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240328181545590.png" alt="image-20240328181545590">
<figcaption aria-hidden="true">image-20240328181545590</figcaption>
</figure></li>
</ol>
<h2 id="代码阅读">代码阅读</h2>
<h3 id="准备训练数据">准备训练数据</h3>
<p>作者通过训练一个ResNet18来得到编码器的训练数据。，也就是下图中的参数输入部分：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240402122657089.png" alt="image-20240402122657089">
<figcaption aria-hidden="true">image-20240402122657089</figcaption>
</figure>
<p>代码部分在<code>tsak_training.py</code>中，核心部分是这个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># override the abstract method in base_task.py, you obtain the model data for generation</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_for_data</span>(<span class="params">self</span>):</span><br></pre></td></tr></table></figure>
<p>训练一共有400轮：</p>
<ol type="1">
<li><p>首先将ResNet18训练200轮，将其参数保存下来:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i == (epoch - <span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 在第199的时候保存模型</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;saving the model&quot;</span>)</span><br><span class="line">    torch.save(net, os.path.join(tmp_path, <span class="string">&quot;whole_model.pth&quot;</span>))</span><br><span class="line">    <span class="comment"># 将不需要训练的层进行固定（取消梯度），后续训练只训练需要训练的层train_layer</span></span><br><span class="line">    fix_partial_model(train_layer, net)</span><br><span class="line">    parameters = []</span><br></pre></td></tr></table></figure></li>
<li><p>在200轮后的训练中，只训练需要需要训练的层，其他的层的参数被冻结了，每过10轮，都会将训练的层的参数保存下来，存储到临时文件夹中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i &gt;= epoch:</span><br><span class="line">    <span class="comment"># 在接下来的训练中，每训练一轮，都会将需要保存的层的参数保存下来，存储到一个列表中</span></span><br><span class="line">    parameters.append(state_part(train_layer, net))</span><br><span class="line">    save_model_accs.append(acc)</span><br><span class="line">    <span class="comment"># 当列表的长度等于10时，或者到达训练结束的时候，将参数保存在硬盘上的临时文件夹中。</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(parameters) == <span class="number">10</span> <span class="keyword">or</span> i == all_epoch - <span class="number">1</span>:</span><br><span class="line">        torch.save(parameters, os.path.join(tmp_path, <span class="string">&quot;p_data_&#123;&#125;.pt&quot;</span>.<span class="built_in">format</span>(i)))</span><br><span class="line">        <span class="comment"># 初始化列表</span></span><br><span class="line">        parameters = []</span><br></pre></td></tr></table></figure></li>
<li><p>最后得到了一个最重要的数据<code>data.pt</code>，里面存储了整个模型<code>whole_model.pth</code>，编码器需要的训练数据<code>pdata</code>，可以将<code>data.pt</code>
load一下：</p>
<figure>
<img data-src="./Neural-Network-Diffusion/image-20240402124224411.png" alt="image-20240402124224411">
<figcaption aria-hidden="true">image-20240402124224411</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">   &#123;<span class="string">&#x27;pdata&#x27;</span>: tensor([[<span class="number">0.3967</span>, <span class="number">0.3701</span>, <span class="number">0.3879</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0885</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3967</span>, <span class="number">0.3701</span>, <span class="number">0.3879</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0885</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3967</span>, <span class="number">0.3701</span>, <span class="number">0.3878</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0885</span>, <span class="number">0.0762</span>],</span><br><span class="line">           ...,</span><br><span class="line">           [<span class="number">0.3975</span>, <span class="number">0.3710</span>, <span class="number">0.3888</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3975</span>, <span class="number">0.3710</span>, <span class="number">0.3888</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3975</span>, <span class="number">0.3710</span>, <span class="number">0.3888</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>]]), <span class="string">&#x27;mean&#x27;</span>: tensor([<span class="number">0.3973</span>, <span class="number">0.3707</span>, <span class="number">0.3885</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>]), <span class="string">&#x27;std&#x27;</span>: tensor([<span class="number">4.2733e-04</span>, <span class="number">4.3796e-04</span>, <span class="number">4.7875e-04</span>,  ..., <span class="number">2.7116e-05</span>, <span class="number">8.1900e-06</span>,</span><br><span class="line">           <span class="number">2.2222e-05</span>]), <span class="string">&#x27;model&#x27;</span>: ResNet(</span><br><span class="line">     (conv1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">     (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">     (layer1): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (layer2): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential(</span><br><span class="line">           (<span class="number">0</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">           (<span class="number">1</span>): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         )</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (layer3): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential(</span><br><span class="line">           (<span class="number">0</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">           (<span class="number">1</span>): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         )</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (layer4): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential(</span><br><span class="line">           (<span class="number">0</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">           (<span class="number">1</span>): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         )</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (linear): Linear(in_features=<span class="number">512</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">   ), <span class="string">&#x27;train_layer&#x27;</span>: [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>], <span class="string">&#x27;performance&#x27;</span>: [<span class="number">71.79</span>, <span class="number">71.78</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.84</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.77</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.82</span>, <span class="number">71.81</span>, <span class="number">71.85</span>, <span class="number">71.89</span>, <span class="number">71.8</span>, <span class="number">71.82</span>, <span class="number">71.85</span>, <span class="number">71.78</span>, <span class="number">71.86</span>, <span class="number">71.87</span>, <span class="number">71.87</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.87</span>, <span class="number">71.82</span>, <span class="number">71.87</span>, <span class="number">71.86</span>, <span class="number">71.86</span>, <span class="number">71.87</span>, <span class="number">71.85</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.86</span>, <span class="number">71.83</span>, <span class="number">71.83</span>, <span class="number">71.93</span>, <span class="number">71.91</span>, <span class="number">71.84</span>, <span class="number">71.8</span>, <span class="number">71.88</span>, <span class="number">71.84</span>, <span class="number">71.78</span>, <span class="number">71.81</span>, <span class="number">71.82</span>, <span class="number">71.8</span>, <span class="number">71.84</span>, <span class="number">71.83</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.89</span>, <span class="number">71.75</span>, <span class="number">71.84</span>, <span class="number">71.78</span>, <span class="number">71.82</span>, <span class="number">71.9</span>, <span class="number">71.86</span>, <span class="number">71.89</span>, <span class="number">71.81</span>, <span class="number">71.8</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.82</span>, <span class="number">71.84</span>, <span class="number">71.76</span>, <span class="number">71.83</span>, <span class="number">71.82</span>, <span class="number">71.87</span>, <span class="number">71.86</span>, <span class="number">71.83</span>, <span class="number">71.87</span>, <span class="number">71.84</span>, <span class="number">71.81</span>, <span class="number">71.85</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.76</span>, <span class="number">71.85</span>, <span class="number">71.78</span>, <span class="number">71.75</span>, <span class="number">71.86</span>, <span class="number">71.88</span>, <span class="number">71.83</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.86</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.9</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.88</span>, <span class="number">71.86</span>, <span class="number">71.82</span>, <span class="number">71.82</span>, <span class="number">71.84</span>, <span class="number">71.84</span>, <span class="number">71.82</span>, <span class="number">71.89</span>, <span class="number">71.79</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.8</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.83</span>, <span class="number">71.84</span>, <span class="number">71.89</span>, <span class="number">71.87</span>, <span class="number">71.86</span>, <span class="number">71.8</span>, <span class="number">71.84</span>, <span class="number">71.83</span>, <span class="number">71.79</span>, <span class="number">71.84</span>, <span class="number">71.9</span>, <span class="number">71.85</span>, <span class="number">71.86</span>, <span class="number">71.88</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.78</span>, <span class="number">71.83</span>, <span class="number">71.87</span>, <span class="number">71.89</span>, <span class="number">71.81</span>, <span class="number">71.86</span>, <span class="number">71.77</span>, <span class="number">71.84</span>, <span class="number">71.92</span>, <span class="number">71.82</span>, <span class="number">71.81</span>, <span class="number">71.8</span>, <span class="number">71.78</span>, <span class="number">71.85</span>, <span class="number">71.89</span>, <span class="number">71.81</span>, <span class="number">71.75</span>, <span class="number">71.8</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.88</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.8</span>, <span class="number">71.95</span>, <span class="number">71.85</span>, <span class="number">71.87</span>, <span class="number">71.83</span>, <span class="number">71.87</span>, <span class="number">71.84</span>, <span class="number">71.82</span>, <span class="number">71.87</span>, <span class="number">71.8</span>, <span class="number">71.86</span>, <span class="number">71.81</span>, <span class="number">71.89</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.81</span>, <span class="number">71.87</span>, <span class="number">71.83</span>, <span class="number">71.82</span>, <span class="number">71.88</span>, <span class="number">71.85</span>, <span class="number">71.84</span>, <span class="number">71.79</span>, <span class="number">71.84</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.81</span>, <span class="number">71.87</span>, <span class="number">71.83</span>, <span class="number">71.88</span>, <span class="number">71.84</span>, <span class="number">71.85</span>, <span class="number">71.81</span>, <span class="number">71.81</span>, <span class="number">71.76</span>, <span class="number">71.89</span>, <span class="number">71.86</span>], <span class="string">&#x27;cfg&#x27;</span>: &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;classification&#x27;</span>, <span class="string">&#x27;data&#x27;</span>: &#123;<span class="string">&#x27;data_root&#x27;</span>: <span class="string">&#x27;data/cifar100&#x27;</span>, <span class="string">&#x27;dataset&#x27;</span>: <span class="string">&#x27;cifar100&#x27;</span>, <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">2048</span>, <span class="string">&#x27;num_workers&#x27;</span>: <span class="number">8</span>&#125;, <span class="string">&#x27;model&#x27;</span>: &#123;<span class="string">&#x27;_target_&#x27;</span>: <span class="string">&#x27;models.resnet.ResNet18&#x27;</span>, <span class="string">&#x27;num_classes&#x27;</span>: <span class="number">100</span>&#125;, <span class="string">&#x27;optimizer&#x27;</span>: &#123;<span class="string">&#x27;_target_&#x27;</span>: <span class="string">&#x27;torch.optim.SGD&#x27;</span>, <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0.0005</span>&#125;, <span class="string">&#x27;lr_scheduler&#x27;</span>: &#123;<span class="string">&#x27;_target_&#x27;</span>: <span class="string">&#x27;torch.optim.lr_scheduler.MultiStepLR&#x27;</span>, <span class="string">&#x27;milestones&#x27;</span>: [<span class="number">60</span>, <span class="number">120</span>, <span class="number">160</span>, <span class="number">200</span>], <span class="string">&#x27;gamma&#x27;</span>: <span class="number">0.2</span>&#125;, <span class="string">&#x27;epoch&#x27;</span>: <span class="number">200</span>, <span class="string">&#x27;save_num_model&#x27;</span>: <span class="number">200</span>, <span class="string">&#x27;train_layer&#x27;</span>: [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>], <span class="string">&#x27;param&#x27;</span>: &#123;<span class="string">&#x27;data_root&#x27;</span>: <span class="string">&#x27;param_data/cifar100/data.pt&#x27;</span>, <span class="string">&#x27;k&#x27;</span>: <span class="number">200</span>, <span class="string">&#x27;num_workers&#x27;</span>: <span class="number">4</span>&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">### 训练扩散模型</span></span><br><span class="line"></span><br><span class="line">代码`train_p_diff.py`，有两种模式，可以在`base.yaml`中选择是训练或者是测试扩散模型。</span><br><span class="line"></span><br><span class="line">项目作者将代码封装的比较好，核心代码在`core`文件夹里面。</span><br><span class="line"></span><br><span class="line"><span class="comment">## 实验结果</span></span><br><span class="line"></span><br><span class="line">再次梳理一下这篇论文对应的实验的思路：数据集设置为CIFAR10，网络为ResNet18</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 在CIFAR10上训练ResNet18，将得到的模型保存下来，在test_data上进行测试，得到acc：</span><br><span class="line"></span><br><span class="line">   ```shell</span><br><span class="line">   /home/chengyiqiu/miniconda3/envs/pdiff/<span class="built_in">bin</span>/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">   <span class="number">10.0</span>  <span class="comment"># 这是随机初始化ResNet的acc，十类瞎猜理论上是1/10</span></span><br><span class="line">   <span class="number">86.034</span>  <span class="comment"># 这是加载了保存的state_dict后的ResNet18的准确率，良好</span></span><br><span class="line">   </span><br><span class="line">   Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></li>
<li><p>将训练好的ResNet18，选取train-layer，只训练这些层，其他的层的参数冻结(require
grad =
false)，然后训练200个epoch，将train-layer的参数收集起来，假设模型的train-layer的长度是5120，那么收集到的数据的shape就是：(200,
5120)，通过这些数据训练一个扩散模型。</p></li>
<li><p>用训练好的扩散模型生成参数，输入的噪声的维度是(200,
latent_shape)，得到200个生成的train-layer的参数，将其加入到第二步中最开始训练好的ResNet18中，替换对应层的参数，并进行测试，下面是测试结果:</p>
<p>这是不替换对应层参数的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model = partial_reverse_tomodel(param, model, train_layer).to(param.device)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/outputs/cifar10/ae_ddpm_cifar10_pth/load.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 7178])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">  0%</span><span class="language-bash">|          | 0/200 [00:00&lt;?, ?it/s]/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=<span class="string">&#x27;sum&#x27;</span> instead.</span></span><br><span class="line">  warnings.warn(warning.format(ret))</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [04:04&lt;00:00,  1.22s/it]</span></span><br><span class="line">Sorted list of accuracies: [92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67]</span><br><span class="line">Average accuracy: 92.67</span><br><span class="line">Max accuracy: 92.67</span><br><span class="line">Min accuracy: 92.67</span><br><span class="line">Median accuracy: 92.67</span><br></pre></td></tr></table></figure>
<p>这是替换对应层的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = partial_reverse_tomodel(param, model, train_layer).to(param.device)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/outputs/cifar10/ae_ddpm_cifar10_pth/load.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 7178])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">  0%</span><span class="language-bash">|          | 0/200 [00:00&lt;?, ?it/s]/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=<span class="string">&#x27;sum&#x27;</span> instead.</span></span><br><span class="line">  warnings.warn(warning.format(ret))</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [04:04&lt;00:00,  1.22s/it]</span></span><br><span class="line">Sorted list of accuracies: [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.01, 10.01, 10.01, 10.01, 10.02, 10.03, 10.04, 10.04, 10.08, 10.08, 10.09, 10.16, 10.63, 10.71, 11.04, 11.08, 11.13, 11.17, 11.68, 11.89, 11.94, 12.84, 12.85, 13.27, 13.54, 13.8, 14.11, 14.44, 14.52, 14.77, 14.89, 15.2, 15.93, 16.25, 16.44, 16.7, 17.29, 18.43, 18.44, 18.62, 18.83, 18.9, 18.98, 19.32, 19.34, 19.68, 19.7, 19.9, 20.19, 20.3, 20.3, 20.33, 20.46, 20.85, 20.96, 21.56, 21.6, 22.38, 22.41, 22.41, 23.13, 23.63, 23.71, 23.73, 24.17, 25.84, 26.6, 26.64, 26.76, 26.83, 27.0, 27.26, 27.52, 27.54, 27.72, 27.77, 27.86, 28.0, 28.15, 28.2, 28.29, 28.29, 28.46, 28.71, 28.74, 28.87, 29.02, 29.14, 29.25, 29.93, 30.24, 30.71, 31.66, 32.23, 32.45, 33.66, 34.37, 36.0, 36.56, 36.71, 37.02, 37.32, 37.33, 39.09, 39.4, 39.76, 40.4, 42.54, 44.09, 44.67, 45.6, 46.82, 48.23, 48.83, 52.8, 53.44, 54.1, 54.59, 59.25, 60.46, 63.95, 64.05, 70.35, 70.59, 70.92, 74.63, 76.78, 78.43, 79.81, 80.77, 82.4, 82.61, 85.24, 85.46, 86.22, 87.14, 87.83, 88.27, 88.64, 88.71, 88.98, 89.03, 89.5, 89.94, 89.97, 90.46]</span><br><span class="line">Average accuracy: 28.35</span><br><span class="line">Max accuracy: 90.46</span><br><span class="line">Min accuracy: 10.00</span><br><span class="line">Median accuracy: 19.69</span><br></pre></td></tr></table></figure>
<p>这次扩散模型输出的参数效果一般，但也有性能比较好的参数。</p></li>
<li><p>将训练好的模型换成相同架构（ResNet18），相同数据集，植入了后门之后的模型，将对应层的参数进行替换：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/outputs/cifar10/ae_ddpm_cifar10_pth/load.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 7178])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">  0%</span><span class="language-bash">|          | 0/200 [00:00&lt;?, ?it/s]/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=<span class="string">&#x27;sum&#x27;</span> instead.</span></span><br><span class="line">  warnings.warn(warning.format(ret))</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [04:04&lt;00:00,  1.22s/it]</span></span><br><span class="line">Sorted list of accuracies: [1.29, 1.63, 1.99, 2.64, 2.93, 2.98, 3.12, 4.07, 4.18, 4.22, 5.14, 5.18, 5.51, 5.56, 5.65, 6.1, 6.3, 6.4, 7.02, 7.07, 7.34, 7.38, 7.91, 8.75, 8.86, 9.13, 9.15, 9.16, 9.5, 9.65, 9.76, 9.76, 9.78, 9.83, 9.84, 9.86, 9.93, 9.95, 9.96, 9.96, 9.98, 9.98, 9.98, 9.99, 9.99, 9.99, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.01, 10.01, 10.01, 10.02, 10.02, 10.03, 10.03, 10.04, 10.04, 10.06, 10.06, 10.06, 10.07, 10.13, 10.15, 10.23, 10.33, 10.43, 10.46, 10.51, 10.69, 10.83, 11.2, 11.37, 11.38, 11.5, 11.69, 11.87, 12.02, 12.32, 12.34, 12.37, 12.41, 13.09, 13.95, 13.96, 14.04, 14.96, 15.39, 15.8, 17.02, 17.15, 17.23, 17.8, 18.74, 19.39, 20.22]</span><br><span class="line">Average accuracy: 9.94</span><br><span class="line">Max accuracy: 20.22</span><br><span class="line">Min accuracy: 1.29</span><br><span class="line">Median accuracy: 10.00</span><br></pre></td></tr></table></figure>
<p>可以看到，没有高性能参数。</p></li>
<li><p>最后单独测试一下植入后门的ResNet的性能，以确定是扩散模型生成的参数导致ResNet的性能下降。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">10.0</span><br><span class="line">94.474</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="实验结论">实验结论</h2>
<p>扩散模型的却可以生成高性能参数，但是生成的参数泛化性十分差劲！</p>
<p>简单探究下原因，虽然说论文中说是用了200个高性能模型，但其实上，者200个高性能模型的前面几层都是一样的，假如我这样选取：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_layer = [&#x27;layer4.1.bn1.weight&#x27;, &#x27;layer4.1.bn1.bias&#x27;, &#x27;layer4.1.bn2.bias&#x27;, &#x27;layer4.1.bn2.weight&#x27;, &#x27;linear.weight&#x27;, &#x27;linear.bias&#x27;]</span><br></pre></td></tr></table></figure>
<p>选取模型最后的几层，<strong>那么这最终的200个模型的前面几层的参数都是一样的，这严重限制了扩散模型的泛化性能！</strong></p>
<h2 id="问题记录">问题记录</h2>
<ol type="1">
<li><p>数据集的transform设置，训练时和测试时不一致，导致训练得到的准确率有较大的drop，若是统一transform之后，训练的正确率得以改善。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>这是gpt的解释：</p>
<figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">在这段代码中，`transforms.Normalize`是PyTorch中用于数据预处理的一个方法，它执行了数据的归一化操作。归一化是机器学习和深度学习中常用的技术，旨在将输入数据的范围和分布调整到特定的区间，以提高模型的训练效率和性能。</span><br><span class="line"></span><br><span class="line">`transforms.Normalize`的参数如下：</span><br><span class="line"></span><br><span class="line">- `mean`: 一个与输入数据的通道数相同长度的列表，表示每个通道的均值。在这个例子中，`[0.5, 0.5, 0.5]`意味着对于RGB图像，每个颜色通道（红、绿、蓝）的均值都被设置为0.5。</span><br><span class="line"></span><br><span class="line">- `std`: 与`mean`类似，这是一个标准差（standard deviation）的列表，用于每个通道。在这个例子中，每个通道的标准差被设置为0.5。</span><br><span class="line"></span><br><span class="line">归一化操作的具体计算方法是将每个通道的数据减去其均值（`mean`），然后除以其标准差（`std`）。对于图像数据，这通常可以表示为以下公式：</span><br><span class="line"></span><br><span class="line"><span class="keyword">\[</span> <span class="keyword">\text</span>&#123;Normalized pixel value&#125; = <span class="keyword">\frac</span>&#123;<span class="keyword">\text</span>&#123;Pixel value&#125; - <span class="keyword">\text</span>&#123;mean&#125;&#125;&#123;<span class="keyword">\text</span>&#123;std&#125;&#125; <span class="keyword">\]</span></span><br><span class="line"></span><br><span class="line">这种操作有助于将输入数据的分布标准化，使其具有零均值和单位方差（当`mean = 0`且`std = 1`时）。这样做的好处包括：</span><br><span class="line"></span><br><span class="line">1. 加速训练过程：归一化后的数据有助于提高梯度下降算法的收敛速度。</span><br><span class="line">2. 改善模型性能：标准化的数据可以使模型更容易学习特征，因为它减少了不同特征之间的量纲影响。</span><br><span class="line">3. 防止梯度消失/爆炸：归一化有助于保持梯度在训练过程中的稳定，防止因输入数据范围过大或过小而导致的梯度问题。</span><br><span class="line"></span><br><span class="line">在实际应用中，`transforms.Normalize`通常与`transforms.ToTensor`一起使用，后者首先将图像数据转换为PyTorch张量（`Tensor`），然后`transforms.Normalize`对这些张量进行归一化处理。这种组合是处理图像数据的常见做法，特别是在使用预训练模型或者需要提高模型性能的场合。</span><br></pre></td></tr></table></figure>
<p>经过我的测试，transform相同和不同相差10个点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">9.83</span><br><span class="line">87.57</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">10.0</span><br><span class="line">76.11</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="多样化参数以增强泛化性能">多样化参数以增强泛化性能</h2>
<h3 id="尝试1-慢慢减训练的layer">尝试1 慢慢减训练的layer</h3>
<p>先把ResNet训练100（）轮，然后按以下设置，训练这些层，各100轮，最后只拿出全连接层的参数，查看泛化性能是否提升。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_layer = [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer = [<span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>测试下：</p>
<p>相同模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">res_path = <span class="string">&#x27;../tmp/whole_model_resnet18_cifar10.pth&#x27;</span></span><br><span class="line">t = torch.load(res_path)</span><br><span class="line"><span class="comment"># resnet.load_state_dict(torch.load(res_path)[&#x27;model&#x27;])</span></span><br><span class="line">state_dict = torch.load(res_path)[<span class="string">&#x27;state_dict&#x27;</span>]</span><br><span class="line"><span class="comment"># train_layer = [&#x27;layer4.1.bn1.weight&#x27;, &#x27;layer4.1.bn1.bias&#x27;, &#x27;layer4.1.bn2.bias&#x27;, &#x27;layer4.1.bn2.weight&#x27;]</span></span><br><span class="line">train_layer = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/load_pdiff.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 300/300 [26:12&lt;00:00,  5.24s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.558, 0.61, 0.964, 1.198, 1.96, 2.38, 2.44, 2.508, 2.598, 2.772, 3.982, 4.098, 4.724, 5.266, 5.836, 5.926, 6.122, 6.894, 7.068, 7.25, 7.314, 7.446, 7.458, 7.87, 8.048, 8.436, 8.65, 9.362, 10.164, 10.184, 10.69, 10.73, 10.992, 11.008, 11.086, 11.48, 11.614, 11.804, 11.808, 12.058, 12.248, 12.454, 12.494, 12.658, 12.92, 12.92, 13.072, 13.124, 13.128, 13.43, 13.488, 13.524, 13.828, 14.174, 14.244, 14.324, 14.506, 14.54, 14.972, 15.162, 15.212, 15.258, 15.384, 15.41, 15.694, 16.038, 16.062, 16.132, 16.256, 16.258, 17.032, 17.11, 17.22, 17.4, 17.402, 17.842, 18.15, 18.204, 18.288, 18.524, 18.68, 18.798, 18.926, 19.074, 19.44, 19.818, 20.45, 20.49, 20.55, 20.592, 20.61, 20.67, 20.672, 20.74, 20.832, 20.982, 21.242, 21.254, 21.36, 21.748, 21.812, 22.29, 22.8, 22.842, 23.068, 23.356, 23.724, 23.84, 24.076, 24.396, 24.598, 24.726, 25.052, 25.32, 25.72, 25.756, 26.25, 26.83, 26.968, 26.972, 27.21, 27.328, 27.592, 27.996, 28.21, 28.53, 28.726, 29.04, 29.16, 29.194, 29.424, 29.566, 29.598, 29.678, 29.774, 29.808, 30.916, 31.158, 31.24, 31.338, 31.482, 32.002, 32.148, 32.742, 32.804, 33.08, 33.552, 33.76, 33.92, 34.004, 34.774, 35.834, 36.576, 37.622, 37.68, 38.128, 39.032, 39.044, 39.494, 39.708, 39.876, 40.692, 41.044, 41.104, 42.296, 42.618, 42.918, 42.924, 43.336, 43.896, 43.942, 44.39, 44.82, 45.118, 45.322, 45.94, 46.096, 46.416, 48.732, 48.834, 49.362, 49.578, 49.764, 51.2, 51.566, 51.74, 52.22, 52.87, 53.906, 54.406, 54.882, 56.08, 56.298, 57.084, 57.42, 57.71, 58.088, 58.106, 58.928, 60.352, 60.442, 60.736, 62.214, 62.24, 62.672, 63.272, 63.516, 63.776, 63.808, 64.076, 64.376, 64.792, 64.806, 65.076, 65.462, 65.83, 65.866, 65.928, 66.678, 66.714, 67.088, 67.394, 68.068, 68.344, 68.572, 68.728, 69.234, 69.326, 69.516, 69.592, 70.49, 70.924, 71.772, 71.918, 72.286, 72.31, 72.538, 72.654, 72.828, 73.326, 74.204, 74.62, 74.694, 75.168, 75.762, 76.372, 76.492, 77.38, 77.558, 77.566, 78.034, 78.228, 78.54, 78.716, 78.88, 79.034, 80.036, 80.302, 80.548, 80.782, 82.27, 82.28, 82.704, 82.824, 82.956, 83.308, 83.386, 83.644, 83.67, 83.74, 84.098, 84.486, 84.558, 85.982, 86.032, 86.682, 86.91, 87.098, 87.894, 89.008, 89.156, 89.736, 89.752, 90.448, 90.574, 91.7, 91.79, 92.102, 92.462, 92.522, 92.754, 93.51, 94.272, 95.092, 95.588, 95.974, 95.992, 97.704, 98.034, 98.558]</span><br><span class="line">Average accuracy: 42.82</span><br><span class="line">Max accuracy: 98.56</span><br><span class="line">Min accuracy: 0.56</span><br><span class="line">Median accuracy: 34.39</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>不同模型（badnet）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/load_pdiff.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 300/300 [26:20&lt;00:00,  5.27s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.486, 0.532, 0.826, 0.83, 0.852, 0.892, 0.99, 1.024, 1.186, 1.236, 1.296, 1.31, 1.338, 1.436, 1.516, 1.644, 1.662, 1.678, 1.79, 1.806, 1.942, 2.08, 2.304, 2.316, 2.326, 2.354, 2.374, 2.416, 2.658, 2.728, 2.78, 2.818, 2.974, 3.032, 3.034, 3.038, 3.048, 3.05, 3.106, 3.138, 3.268, 3.328, 3.336, 3.6, 3.668, 3.712, 3.72, 3.84, 3.856, 4.014, 4.078, 4.084, 4.092, 4.092, 4.104, 4.234, 4.342, 4.492, 4.538, 4.62, 4.62, 4.638, 4.768, 4.972, 5.126, 5.152, 5.162, 5.18, 5.21, 5.248, 5.608, 5.64, 5.686, 5.718, 5.76, 5.906, 5.998, 6.11, 6.152, 6.332, 6.362, 6.374, 6.426, 6.466, 6.588, 6.716, 6.776, 6.826, 6.944, 6.986, 7.054, 7.148, 7.158, 7.3, 7.308, 7.332, 7.37, 7.426, 7.534, 7.57, 7.606, 7.662, 7.67, 7.864, 7.96, 7.988, 8.002, 8.194, 8.264, 8.31, 8.368, 8.698, 8.966, 8.99, 9.092, 9.144, 9.144, 9.224, 9.244, 9.288, 9.31, 9.406, 9.438, 9.54, 9.622, 9.628, 9.642, 9.668, 9.728, 9.734, 9.81, 9.836, 9.87, 10.0, 10.048, 10.082, 10.206, 10.4, 10.558, 10.59, 10.656, 10.766, 10.796, 10.978, 10.996, 11.038, 11.13, 11.248, 11.288, 11.332, 11.4, 11.404, 11.428, 11.52, 11.604, 11.622, 11.66, 11.804, 11.92, 12.042, 12.072, 12.144, 12.178, 12.2, 12.252, 12.302, 12.402, 12.52, 12.656, 12.722, 12.752, 12.792, 12.796, 12.838, 12.906, 12.974, 13.054, 13.136, 13.146, 13.156, 13.19, 13.304, 13.456, 13.466, 13.536, 13.58, 13.61, 13.696, 13.704, 13.842, 13.852, 13.914, 14.024, 14.04, 14.062, 14.134, 14.184, 14.222, 14.42, 14.47, 14.578, 14.67, 14.792, 14.958, 14.968, 15.02, 15.064, 15.09, 15.102, 15.398, 15.466, 15.524, 15.712, 15.988, 16.108, 16.16, 16.31, 16.432, 16.466, 16.558, 16.562, 16.624, 16.698, 16.7, 16.728, 16.822, 16.88, 16.886, 17.212, 17.248, 17.248, 17.29, 17.384, 17.486, 17.582, 17.75, 17.852, 17.912, 17.948, 17.962, 18.072, 18.146, 18.41, 18.422, 18.662, 18.722, 18.724, 18.942, 18.974, 18.994, 19.004, 19.046, 19.268, 19.306, 19.338, 19.364, 19.41, 19.664, 19.706, 19.71, 19.848, 19.884, 19.982, 20.014, 20.282, 20.304, 20.7, 20.802, 20.912, 21.106, 21.244, 21.636, 21.718, 22.028, 22.098, 22.212, 22.53, 22.838, 22.924, 22.948, 23.044, 23.734, 23.79, 24.564, 24.716, 24.76, 24.798, 25.438, 25.454, 25.488, 25.572, 25.688, 26.852, 26.91, 27.516, 28.05, 29.412, 31.142, 33.508, 35.426]</span><br><span class="line">Average accuracy: 11.75</span><br><span class="line">Max accuracy: 35.43</span><br><span class="line">Min accuracy: 0.49</span><br><span class="line">Median accuracy: 11.37</span><br></pre></td></tr></table></figure>
<p>泛化性能有所提升，但仍然不够好，接着增加层数，试着增加泛化性能。</p>
<h3 id="尝试2-切换顺序">尝试2 切换顺序</h3>
<p>发现train_layer的weight和bias写反了，修改一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_layer_1 = [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_2 = [<span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_3 = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>应该是问题不大的，这里仅仅测试一下，理论上，冻结梯度、保存对应层的时候，都是<code>if name in train_layer:</code>，最后替换参数的时候，也是从网络本身的层数来一层一层判断：<code>for name, pa in model.named_parameters():</code></p>
<p>这里发现一个比较奇怪的点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Epoch 2999, global step 3000: &#x27;ae_acc&#x27; reached 2.35000 (best 2.35000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=2999-ae_acc=2.3500.ckpt&#x27; as top 1</span><br><span class="line">Epoch 5999, global step 6000: &#x27;ae_acc&#x27; reached 3.69000 (best 3.69000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=5999-ae_acc=3.6900.ckpt&#x27; as top 1</span><br><span class="line">Epoch 8999, global step 9000: &#x27;ae_acc&#x27; reached 4.73000 (best 4.73000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=8999-ae_acc=4.7300.ckpt&#x27; as top 1</span><br><span class="line">Epoch 11999, global step 12000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 14999, global step 15000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 17999, global step 18000: &#x27;ae_acc&#x27; reached 5.04000 (best 5.04000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=17999-ae_acc=5.0400.ckpt&#x27; as top 1</span><br><span class="line">Epoch 20999, global step 21000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 23999, global step 24000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 26999, global step 27000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 29999, global step 30000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 32999, global step 33000: &#x27;ae_acc&#x27; reached 94.30000 (best 94.30000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=32999-ae_acc=94.3000.ckpt&#x27; as top 1</span><br></pre></td></tr></table></figure>
<p>前3w轮是在训练AE，正确率都很低，但是一旦到了3w轮后，开始训练DM，正确率马上就上来了。。。</p>
<p>结果还是不行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/load_pdiff.py </span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line">100%|██████████| 300/300 [24:07&lt;00:00,  4.82s/it]</span><br><span class="line">Sorted list of accuracies: [0.554, 0.786, 0.882, 1.226, 1.226, 1.25, 1.296, 1.324, 1.396, 1.532, 1.658, 1.66, 1.704, 1.714, 1.802, 1.924, 2.066, 2.104, 2.18, 2.222, 2.344, 2.426, 2.434, 2.484, 2.572, 2.606, 2.634, 2.7, 2.792, 2.884, 2.942, 2.97, 3.028, 3.034, 3.254, 3.274, 3.286, 3.328, 3.354, 3.462, 3.542, 3.674, 3.698, 3.788, 3.87, 3.984, 4.024, 4.068, 4.088, 4.246, 4.25, 4.26, 4.262, 4.498, 4.512, 4.53, 4.632, 4.74, 4.77, 4.776, 4.834, 4.842, 4.96, 5.056, 5.124, 5.224, 5.386, 5.396, 5.412, 5.628, 5.796, 5.93, 6.046, 6.274, 6.278, 6.294, 6.318, 6.388, 6.402, 6.448, 6.558, 6.57, 6.588, 6.616, 6.656, 6.71, 6.722, 6.822, 6.872, 6.878, 6.922, 6.94, 6.986, 6.998, 7.016, 7.038, 7.074, 7.18, 7.244, 7.282, 7.346, 7.504, 7.54, 7.6, 7.612, 7.64, 7.662, 7.702, 7.712, 7.758, 7.802, 7.866, 8.024, 8.152, 8.242, 8.444, 8.494, 8.508, 8.522, 8.578, 8.61, 8.622, 8.704, 8.74, 8.742, 8.748, 8.76, 8.764, 8.772, 8.806, 8.806, 8.82, 8.904, 8.928, 8.974, 9.038, 9.092, 9.144, 9.174, 9.206, 9.224, 9.31, 9.34, 9.39, 9.406, 9.492, 9.496, 9.508, 9.574, 9.612, 9.638, 9.65, 9.756, 9.758, 9.762, 9.81, 9.818, 9.832, 9.834, 9.866, 9.888, 9.904, 9.944, 9.956, 9.958, 9.968, 9.974, 9.986, 10.0, 10.056, 10.058, 10.102, 10.14, 10.166, 10.262, 10.27, 10.3, 10.308, 10.36, 10.714, 10.714, 10.756, 10.814, 10.818, 10.826, 10.834, 10.838, 10.888, 10.906, 10.93, 10.962, 10.966, 10.968, 10.98, 11.06, 11.078, 11.088, 11.164, 11.168, 11.204, 11.242, 11.258, 11.486, 11.534, 11.542, 11.574, 11.574, 11.678, 11.7, 11.706, 11.744, 11.79, 11.794, 11.85, 11.988, 12.084, 12.122, 12.154, 12.32, 12.37, 12.386, 12.484, 12.786, 12.814, 12.842, 12.864, 12.88, 12.98, 13.126, 13.182, 13.188, 13.214, 13.236, 13.278, 13.516, 13.528, 13.546, 13.606, 13.608, 13.62, 13.722, 13.766, 14.102, 14.19, 14.25, 14.48, 14.484, 14.492, 14.668, 14.69, 14.8, 14.806, 14.876, 15.054, 15.136, 15.146, 15.208, 15.21, 15.216, 15.314, 15.338, 15.478, 15.48, 15.522, 15.626, 15.672, 15.72, 15.752, 15.88, 15.92, 16.014, 16.1, 16.166, 16.168, 16.35, 16.366, 16.37, 16.536, 16.754, 17.194, 17.252, 17.42, 17.466, 17.528, 17.584, 17.84, 18.162, 18.692, 18.852, 18.926, 18.948, 19.224, 19.698, 19.936, 20.124, 20.764, 20.84, 22.566, 22.912, 24.076]</span><br><span class="line">Average accuracy: 9.58</span><br><span class="line">Max accuracy: 24.08</span><br><span class="line">Min accuracy: 0.55</span><br><span class="line">Median accuracy: 9.62</span><br></pre></td></tr></table></figure>
<h3 id="尝试3-加入卷积层训练">尝试3 加入卷积层训练</h3>
<p>这里把ResNet18的最后两层给出来：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">layer4.0.conv1.weight</span><br><span class="line">layer4.0.bn1.weight</span><br><span class="line">layer4.0.bn1.bias</span><br><span class="line">layer4.0.conv2.weight</span><br><span class="line">layer4.0.bn2.weight</span><br><span class="line">layer4.0.bn2.bias</span><br><span class="line">layer4.0.shortcut.0.weight</span><br><span class="line">layer4.0.shortcut.1.weight</span><br><span class="line">layer4.0.shortcut.1.bias</span><br><span class="line">layer4.1.conv1.weight</span><br><span class="line">layer4.1.bn1.weight</span><br><span class="line">layer4.1.bn1.bias</span><br><span class="line">layer4.1.conv2.weight</span><br><span class="line">layer4.1.bn2.weight</span><br><span class="line">layer4.1.bn2.bias</span><br><span class="line">linear.weight</span><br><span class="line">linear.bias</span><br></pre></td></tr></table></figure>
<p>先训练这几个：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">layer4.1.conv1.weight</span><br><span class="line">layer4.1.bn1.weight</span><br><span class="line">layer4.1.bn1.bias</span><br><span class="line">layer4.1.conv2.weight</span><br><span class="line">layer4.1.bn2.weight</span><br><span class="line">layer4.1.bn2.bias</span><br><span class="line">linear.weight</span><br><span class="line">linear.bias</span><br></pre></td></tr></table></figure>
<p>效果提燃很差：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line">100%|██████████| 300/300 [24:57&lt;00:00,  4.99s/it]</span><br><span class="line">Sorted list of accuracies: [0.6, 0.654, 0.69, 0.702, 0.716, 0.868, 0.878, 0.95, 1.018, 1.124, 1.208, 1.31, 1.328, 1.338, 1.458, 1.514, 1.698, 1.704, 1.902, 1.924, 2.026, 2.074, 2.162, 2.176, 2.224, 2.224, 2.228, 2.296, 2.328, 2.388, 2.414, 2.426, 2.43, 2.464, 2.472, 2.496, 2.51, 2.52, 2.52, 2.56, 2.746, 2.8, 2.834, 2.854, 2.91, 2.93, 3.038, 3.062, 3.08, 3.092, 3.136, 3.148, 3.152, 3.198, 3.232, 3.366, 3.46, 3.464, 3.468, 3.526, 3.528, 3.536, 3.57, 3.608, 3.642, 3.674, 3.68, 3.712, 3.718, 3.81, 3.88, 3.986, 4.024, 4.048, 4.116, 4.136, 4.244, 4.332, 4.342, 4.372, 4.372, 4.444, 4.538, 4.56, 4.562, 4.676, 4.732, 4.774, 4.86, 4.886, 4.928, 4.956, 4.974, 4.982, 5.008, 5.062, 5.168, 5.206, 5.238, 5.266, 5.28, 5.298, 5.414, 5.426, 5.538, 5.57, 5.574, 5.596, 5.598, 5.604, 5.728, 5.742, 5.764, 5.772, 5.884, 5.908, 5.992, 6.004, 6.114, 6.14, 6.19, 6.222, 6.222, 6.4, 6.412, 6.446, 6.54, 6.554, 6.672, 6.766, 6.84, 7.046, 7.198, 7.332, 7.49, 7.572, 7.668, 7.674, 7.722, 8.054, 8.108, 8.114, 8.162, 8.182, 8.398, 8.518, 8.546, 8.636, 8.64, 8.73, 8.734, 8.768, 8.794, 8.818, 9.006, 9.184, 9.214, 9.29, 9.304, 9.328, 9.372, 9.428, 9.428, 9.442, 9.476, 9.486, 9.496, 9.506, 9.568, 9.578, 9.77, 9.852, 9.914, 9.962, 9.992, 10.05, 10.082, 10.102, 10.116, 10.12, 10.128, 10.15, 10.184, 10.276, 10.31, 10.362, 10.386, 10.414, 10.426, 10.464, 10.488, 10.564, 10.594, 10.674, 10.712, 10.744, 10.754, 10.772, 10.822, 10.878, 10.922, 10.944, 10.966, 11.026, 11.03, 11.03, 11.032, 11.114, 11.116, 11.118, 11.12, 11.142, 11.188, 11.204, 11.276, 11.394, 11.408, 11.422, 11.492, 11.532, 11.566, 11.596, 11.608, 11.74, 11.772, 11.94, 12.006, 12.006, 12.016, 12.05, 12.14, 12.268, 12.424, 12.448, 12.48, 12.514, 12.688, 12.708, 12.75, 12.766, 12.822, 12.862, 12.924, 12.996, 13.004, 13.116, 13.128, 13.158, 13.188, 13.218, 13.25, 13.416, 13.476, 13.568, 13.616, 13.668, 13.72, 13.95, 14.014, 14.142, 14.22, 14.324, 14.418, 14.46, 14.528, 14.542, 14.686, 14.742, 14.768, 14.988, 15.5, 15.576, 16.004, 16.012, 16.278, 16.628, 16.728, 16.754, 16.802, 16.942, 17.006, 17.288, 17.29, 17.34, 17.384, 17.424, 17.524, 17.994, 18.078, 18.092, 18.118, 18.13, 18.166, 18.288, 18.57, 18.674, 18.928, 19.316, 19.704, 22.478]</span><br><span class="line">Average accuracy: 8.50</span><br><span class="line">Max accuracy: 22.48</span><br><span class="line">Min accuracy: 0.60</span><br><span class="line">Median accuracy: 8.73</span><br></pre></td></tr></table></figure>
<h3 id="尝试4-4个bn">尝试4 4个bn</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_layer_1 = [<span class="string">&#x27;layer4.0.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.0.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.0.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.0.bn2.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_2 = [<span class="string">&#x27;layer4.0.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.0.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_3 = [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_4 = [<span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_5 = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>效果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">ae param shape: torch.Size([250, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 250/250 [20:36&lt;00:00,  4.94s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.634, 0.784, 0.808, 0.916, 1.012, 1.126, 1.286, 1.322, 1.47, 1.592, 1.718, 1.756, 1.886, 2.05, 2.072, 2.098, 2.192, 2.212, 2.246, 2.254, 2.326, 2.342, 2.504, 2.6, 2.766, 2.888, 2.928, 3.008, 3.178, 3.198, 3.3, 3.438, 3.462, 3.492, 3.534, 3.642, 4.056, 4.072, 4.262, 4.516, 4.558, 4.586, 4.632, 4.776, 4.78, 4.878, 4.938, 5.014, 5.088, 5.208, 5.296, 5.548, 5.556, 5.568, 5.586, 5.644, 5.674, 5.684, 5.802, 5.804, 5.848, 5.882, 5.92, 6.0, 6.024, 6.102, 6.506, 6.544, 6.602, 6.624, 6.714, 6.748, 6.76, 6.852, 6.864, 6.932, 7.036, 7.116, 7.128, 7.204, 7.25, 7.43, 7.45, 7.492, 7.514, 7.626, 7.632, 7.69, 7.702, 8.018, 8.068, 8.138, 8.194, 8.194, 8.252, 8.444, 8.444, 8.448, 8.456, 8.466, 8.562, 8.624, 8.65, 8.668, 8.714, 8.728, 8.752, 9.022, 9.028, 9.124, 9.136, 9.166, 9.25, 9.258, 9.276, 9.376, 9.388, 9.438, 9.582, 9.666, 9.7, 9.71, 9.734, 9.774, 9.784, 9.828, 9.832, 9.832, 9.874, 9.886, 9.898, 9.964, 10.052, 10.106, 10.13, 10.13, 10.144, 10.202, 10.236, 10.258, 10.268, 10.296, 10.302, 10.344, 10.346, 10.362, 10.366, 10.398, 10.426, 10.478, 10.514, 10.558, 10.602, 10.638, 10.656, 10.682, 10.812, 10.826, 10.83, 10.844, 10.866, 10.87, 10.942, 10.954, 11.024, 11.058, 11.08, 11.202, 11.23, 11.37, 11.508, 11.566, 11.642, 11.878, 12.166, 12.252, 12.442, 12.442, 12.472, 12.56, 12.688, 12.762, 12.852, 13.114, 13.218, 13.412, 13.532, 13.558, 13.574, 13.704, 13.722, 13.804, 13.908, 13.972, 14.414, 14.448, 14.67, 14.676, 14.774, 14.778, 14.962, 15.248, 15.254, 15.304, 15.356, 15.426, 15.564, 15.754, 15.826, 15.856, 15.88, 15.978, 15.982, 16.142, 16.318, 16.584, 16.68, 17.06, 17.15, 17.286, 17.656, 17.866, 18.176, 18.37, 18.596, 18.846, 18.898, 19.226, 19.384, 19.396, 19.468, 19.528, 19.552, 19.692, 19.806, 19.952, 19.964, 20.044, 20.088, 20.174, 20.388, 22.354, 22.43, 22.706, 23.08, 23.254, 23.296, 24.044, 26.122, 26.376]</span><br><span class="line">Average accuracy: 10.11</span><br><span class="line">Max accuracy: 26.38</span><br><span class="line">Min accuracy: 0.63</span><br><span class="line">Median accuracy: 9.81</span><br></pre></td></tr></table></figure>
<p>不行，泛化性没有提升。</p>
<h3 id="尝试5-训练-重训练">尝试5 训练-重训练</h3>
<p>先训练100轮，得到一个不错的模型，然后将模型的第一层的参数重新随机初始化，继续训练n轮，直到模型正确率达到阈值<span class="math inline">\(\tau\)</span>​，将这个模型训练n轮，收集FC层的参数，再重新初始化第一层的参数，如此循环下去。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">ae param shape: torch.Size([200, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line">100%|██████████| 200/200 [16:35&lt;00:00,  4.98s/it]</span><br><span class="line">Sorted list of accuracies: [0.494, 0.768, 1.67, 1.95, 2.124, 2.188, 2.38, 2.388, 2.456, 2.47, 2.564, 2.722, 2.81, 2.886, 2.948, 2.996, 3.08, 3.13, 3.166, 3.254, 3.738, 3.914, 4.008, 4.032, 4.428, 4.462, 4.648, 4.738, 4.822, 4.838, 4.874, 4.91, 4.944, 5.124, 5.262, 5.502, 5.636, 5.64, 5.67, 5.848, 5.882, 6.164, 6.188, 6.342, 6.346, 6.526, 6.556, 6.684, 6.786, 6.794, 6.812, 6.83, 6.85, 6.946, 7.262, 7.388, 7.44, 7.504, 7.542, 7.552, 7.792, 7.866, 7.952, 8.086, 8.176, 8.27, 8.434, 8.532, 8.69, 8.732, 8.87, 8.882, 8.94, 8.954, 9.034, 9.12, 9.294, 9.332, 9.354, 9.374, 9.442, 9.454, 9.458, 9.584, 9.596, 9.618, 9.636, 9.686, 9.796, 9.988, 10.186, 10.314, 10.486, 10.57, 10.58, 10.64, 10.65, 10.782, 11.04, 11.066, 11.094, 11.1, 11.126, 11.126, 11.178, 11.184, 11.25, 11.292, 11.314, 11.356, 11.402, 11.508, 11.608, 11.612, 11.62, 11.626, 11.638, 11.702, 11.898, 11.964, 12.03, 12.122, 12.282, 12.344, 12.36, 12.412, 12.532, 12.63, 12.764, 12.78, 12.83, 12.85, 12.966, 13.016, 13.07, 13.174, 13.25, 13.446, 13.702, 13.762, 13.79, 13.816, 13.838, 14.232, 14.236, 14.3, 14.372, 14.396, 14.446, 14.766, 14.844, 14.862, 15.024, 15.412, 15.456, 15.734, 15.846, 15.858, 16.028, 16.142, 16.258, 16.328, 16.546, 16.66, 16.722, 17.142, 17.246, 17.26, 17.314, 17.326, 17.536, 17.712, 17.8, 17.812, 18.058, 18.058, 18.158, 18.226, 18.286, 18.308, 18.438, 18.538, 19.256, 19.87, 20.006, 21.064, 21.558, 22.054, 22.104, 22.666, 22.688, 23.956, 23.974, 25.298, 25.642, 25.644, 25.734, 26.37, 28.938, 31.89]</span><br><span class="line">Average accuracy: 11.27</span><br><span class="line">Max accuracy: 31.89</span><br><span class="line">Min accuracy: 0.49</span><br><span class="line">Median accuracy: 11.08</span><br></pre></td></tr></table></figure>
<h3 id="尝试6-卷积层重训练">尝试6 卷积层重训练</h3>
<p>参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init_layer = [&#x27;conv1.weight&#x27;,&#x27;layer1.0.conv1.weight&#x27;, &#x27;layer1.0.conv2.weight&#x27;, &#x27;layer1.1.conv1.weight&#x27;,&#x27;layer1.1.conv2.weight&#x27;,&#x27;linear.weight&#x27;, &#x27;linear.bias&#x27;]</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(pdiff) chengyiqiu@server:~/code/diffusion/Diffuse-Backdoor-Parameters/tools$ python eval_pdiff.py</span><br><span class="line">ae param shape: torch.Size([200, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|███████████████████████████████████████████████████████████| 200/200 [16:05&lt;00:00,  4.83s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.914, 1.544, 1.632, 1.868, 1.888, 2.2, 2.378, 2.44, 2.624, 2.658, 2.806, 2.884, 3.412, 3.672, 3.852, 3.876, 4.038, 4.624, 4.628, 4.94, 4.978, 5.212, 5.344, 5.35, 5.424, 5.644, 5.706, 5.912, 6.08, 6.088, 6.32, 6.934, 7.166, 7.32, 7.386, 7.404, 7.426, 7.482, 7.74, 7.882, 8.1, 8.164, 8.388, 8.404, 8.428, 8.52, 8.678, 8.832, 8.956, 9.032, 9.194, 9.228, 9.422, 9.508, 9.536, 9.556, 9.562, 9.57, 9.628, 9.634, 9.816, 9.836, 9.91, 9.916, 9.94, 9.942, 9.962, 10.0, 10.028, 10.05, 10.084, 10.136, 10.144, 10.144, 10.258, 10.264, 10.334, 10.39, 10.438, 10.468, 10.48, 10.496, 10.516, 10.52, 10.65, 10.674, 10.678, 10.69, 10.748, 10.752, 10.942, 11.234, 11.282, 11.422, 11.488, 11.658, 11.698, 11.784, 11.79, 11.79, 11.792, 11.92, 11.944, 11.95, 11.996, 12.06, 12.078, 12.222, 12.32, 12.402, 12.442, 12.566, 12.574, 12.598, 12.696, 12.756, 12.836, 12.836, 12.922, 12.96, 12.972, 13.01, 13.092, 13.412, 13.48, 13.55, 13.658, 13.77, 13.776, 13.932, 14.254, 14.262, 14.296, 14.326, 14.39, 14.392, 14.456, 14.526, 14.72, 14.79, 14.868, 14.962, 15.016, 15.018, 15.092, 15.116, 15.2, 15.206, 15.3, 15.35, 15.404, 15.468, 15.674, 16.334, 16.372, 16.378, 16.406, 16.458, 16.698, 16.71, 16.798, 17.088, 17.184, 17.252, 17.684, 17.908, 17.958, 18.242, 18.248, 18.314, 18.632, 18.67, 18.71, 18.716, 18.73, 19.206, 19.666, 19.67, 19.724, 19.762, 20.088, 20.242, 20.512, 20.604, 20.66, 20.912, 22.172, 22.488, 22.868, 22.97, 23.476, 25.878, 25.972, 26.558, 27.16, 29.946, 31.72, 31.974, 32.288, 32.566]</span><br><span class="line">Average accuracy: 12.50</span><br><span class="line">Max accuracy: 32.57</span><br><span class="line">Min accuracy: 0.91</span><br><span class="line">Median accuracy: 11.79</span><br></pre></td></tr></table></figure>
<p>尝试7</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init_layer = [<span class="string">&#x27;conv1.weight&#x27;</span>, <span class="string">&#x27;bn1.weight&#x27;</span>, <span class="string">&#x27;bn1.bias&#x27;</span>, <span class="string">&#x27;layer1.0.conv1.weight&#x27;</span>, <span class="string">&#x27;layer1.0.bn1.weight&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;layer1.0.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.conv2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>, ]</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [17:28&lt;00:00,  5.24s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.63, 0.888, 1.024, 1.078, 1.146, 1.17, 1.308, 1.386, 1.444, 1.476, 1.626, 1.828, 1.9, 2.0, 2.012, 2.168, 2.268, 2.332, 2.576, 2.638, 2.678, 2.778, 3.026, 3.028, 3.138, 3.296, 3.32, 3.598, 3.622, 3.832, 4.148, 4.162, 4.52, 4.536, 4.992, 5.018, 5.084, 5.1, 5.11, 5.338, 5.572, 5.744, 5.762, 5.772, 5.864, 5.962, 5.986, 6.116, 6.358, 6.368, 6.476, 6.546, 7.022, 7.142, 7.254, 7.3, 7.452, 7.458, 7.478, 7.522, 7.57, 7.644, 7.7, 7.77, 7.798, 7.824, 7.842, 8.414, 8.506, 8.548, 8.612, 8.636, 8.686, 8.734, 8.862, 8.862, 8.984, 8.992, 9.098, 9.136, 9.14, 9.142, 9.206, 9.312, 9.326, 9.354, 9.562, 9.568, 9.674, 9.712, 9.716, 9.776, 9.79, 9.942, 9.968, 10.0, 10.014, 10.02, 10.036, 10.14, 10.2, 10.25, 10.266, 10.296, 10.324, 10.354, 10.372, 10.39, 10.412, 10.43, 10.462, 10.532, 10.596, 10.616, 10.702, 10.72, 10.734, 10.746, 10.746, 10.76, 10.944, 10.976, 10.978, 11.018, 11.03, 11.044, 11.128, 11.152, 11.226, 11.236, 11.238, 11.398, 11.458, 11.58, 11.594, 11.676, 11.808, 11.87, 11.874, 12.148, 12.23, 12.36, 12.426, 12.51, 12.644, 12.754, 12.772, 12.85, 12.862, 12.902, 12.966, 12.988, 13.122, 13.294, 13.378, 13.458, 14.048, 14.11, 14.234, 14.454, 14.502, 14.636, 14.74, 14.804, 14.872, 14.96, 15.04, 15.32, 15.604, 15.892, 16.058, 16.114, 16.35, 16.674, 16.768, 17.258, 17.414, 17.752, 17.778, 18.206, 18.248, 18.256, 18.296, 18.374, 18.438, 18.674, 18.744, 19.124, 20.658, 20.784, 20.854, 21.198, 21.33, 22.388, 22.688, 22.874, 24.144, 25.728, 27.32, 30.836]</span><br><span class="line">Average accuracy: 10.28</span><br><span class="line">Max accuracy: 30.84</span><br><span class="line">Min accuracy: 0.63</span><br><span class="line">Median accuracy: 10.17</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/21/Distilling-Cognitive-Backdoor-Patterns-within-an-Image/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/21/Distilling-Cognitive-Backdoor-Patterns-within-an-Image/" class="post-title-link" itemprop="url">Distilling_Cognitive_Backdoor_Patterns_within_an_Image</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-21 17:04:27" itemprop="dateCreated datePublished" datetime="2024-03-21T17:04:27+08:00">2024-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:34:10" itemprop="dateModified" datetime="2024-04-19T12:34:10+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>ICLR2023</p>
<p>从输入到模型的图片中提取出“最小模式”，通过实验发现后门模型有一种认知模式（cognitive
pattern），作者通过提取出来的最小模式，来对模型进行认知蒸馏（cognitive
distillation）。</p>
<h1 id="认知蒸馏和后门样本检测">认知蒸馏和后门样本检测</h1>
<h2 id="认知蒸馏">认知蒸馏</h2>
<figure>
<img data-src="./Distilling-Cognitive-Backdoor-Patterns-within-an-Image/image-20240322173556154.png" alt="image-20240322173556154">
<figcaption aria-hidden="true">image-20240322173556154</figcaption>
</figure>
<ul>
<li><span class="math inline">\(x_{cp}\)</span>：蒸馏掉的认知模式</li>
<li><span class="math inline">\(m\)</span>：可学习的掩码，<span class="math inline">\([0,1]^{w\times h}\)</span></li>
<li><span class="math inline">\(\delta\)</span>：噪声，<span class="math inline">\([0,1]^c\)</span></li>
<li><span class="math inline">\(TV(.)\)</span>：总变化损失（？）</li>
<li><span class="math inline">\(f_\theta
(.)\)</span>：可以是最后一个全连接层的输出，也可以是最后一个卷积层的输出</li>
</ul>
<p>公式1的目的是确保认知蒸馏后的输入<span class="math inline">\(x_{cp}\)</span>和原始输入<span class="math inline">\(x\)</span>输入到模型后，得到的输出基本是一样的。</p>
<p>公式2的目的是去除原始输入中不那么重要的特征。</p>
<p>掩码中1代表对应的像素很重要，0代表不重要。</p>
<p>提取掩码和认知模式有利于理解模型误分类的原因。认知模式中的某些像素很可能是增加了扰动的（因为模型中可能有后门）。</p>
<h2 id="通过认知蒸馏来理解后门模型">通过认知蒸馏来理解后门模型</h2>
<figure>
<img data-src="./Distilling-Cognitive-Backdoor-Patterns-within-an-Image/image-20240323094409417.png" alt="image-20240323094409417">
<figcaption aria-hidden="true">image-20240323094409417</figcaption>
</figure>
<ul>
<li>第一行：干净图片和触发器样本的混合</li>
<li>第二行：通过上一节的公式，优化出来的掩码<span class="math inline">\(m\)</span></li>
<li>第三行：对原始图像进行蒸馏过得到的认知模式，也就是<span class="math inline">\(x_{xp}\)</span></li>
<li>第四行：简化后的后门图像</li>
</ul>
<p>然后作者使用第四行和第一行（原始图片）来测试ASR，选取的baseline有badnet、blend等</p>
<figure>
<img data-src="./Distilling-Cognitive-Backdoor-Patterns-within-an-Image/image-20240323095006843.png" alt="image-20240323095006843">
<figcaption aria-hidden="true">image-20240323095006843</figcaption>
</figure>
<ul>
<li>原始触发器：<span class="math inline">\(x_{bd}\)</span></li>
<li>简化后的触发器：<span class="math inline">\(x_{bd}^{&#39;}=m\odot
x_{bd}+(1-m)\odot x\)</span></li>
</ul>
<p>结论：无论触发器模式如何，后门模式的相关性比自然物体的相关性要简单得多。</p>
<h2 id="后门样本检测">后门样本检测</h2>
<p>后门样本检测属于一种无监督的分类任务，因为没有先验知识，所以只能根据样本本身的特征信息来进行监督、聚类。</p>
<p>计算样本掩码的L1距离<span class="math inline">\(\Vert m\Vert
_1\)</span>，来判断输入进来的是否是后门样本：</p>
<figure>
<img data-src="./Distilling-Cognitive-Backdoor-Patterns-within-an-Image/image-20240323164314806.png" alt="image-20240323164314806">
<figcaption aria-hidden="true">image-20240323164314806</figcaption>
</figure>
<p>若是<span class="math inline">\(g(.)=1\)</span>，则代表是后门样本，反之则不是。</p>
<p>对于测试期间，假设防御者受伤有一部分干净样本，那么可以计算出这些样本的分布：<span class="math inline">\(\mu_{\Vert m\Vert _1},\sigma_{\Vert m\Vert
_1}\)</span>，然后可以这样得到阈值t： <span class="math display">\[
t=\mu _{\Vert m\Vert _1}-\gamma \sigma_{\Vert m \Vert _ 1}
\]</span> <span class="math inline">\(\gamma\)</span>是超参数，用来对控制阈值。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/15/Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pig.gif">
      <meta itemprop="name" content="chengyiqiu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/15/Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/" class="post-title-link" itemprop="url">Black-box_Backdoor_Defense_via_Zero-shot_Image_Purification</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-03-15 15:29:21" itemprop="dateCreated datePublished" datetime="2024-03-15T15:29:21+08:00">2024-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-19 12:34:21" itemprop="dateModified" datetime="2024-04-19T12:34:21+08:00">2024-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>NIPS2023</p>
<h1 id="摘要">摘要</h1>
<ol type="1">
<li>对原始图片使用一个线性变换，来摧毁后门模式。</li>
<li>使用扩散模型对变换后的图片进行恢复。</li>
</ol>
<h1 id="概述">概述</h1>
<h2 id="整体的架构">整体的架构</h2>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240318132942587.png" alt="image-20240318132942587">
<figcaption aria-hidden="true">image-20240318132942587</figcaption>
</figure>
<h2 id="扩散模型">扩散模型</h2>
<p>介绍了一种扩散模型DDPM，可以生成高质量的图片，有两个过程：前向过程（forward
process）和反向过程（reverse process）:</p>
<ul>
<li><p>fp：对原始图像<span class="math inline">\(x_0\)</span>迭代的不断添加高斯噪声，直到其变为<strong>随机高斯噪声</strong><span class="math inline">\(x_T\)</span>​</p>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240318135002113.png" alt="image-20240318135002113">
<figcaption aria-hidden="true">image-20240318135002113</figcaption>
</figure></li>
<li><p>rp：移除<strong>随机高斯噪声</strong><span class="math inline">\(x_T\)</span>​上的噪声，直到其恢复成原始图像。</p>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240318135154622.png" alt="image-20240318135154622">
<figcaption aria-hidden="true">image-20240318135154622</figcaption>
</figure></li>
</ul>
<h1 id="zip">ZIP</h1>
<p>Zero-shot Image Purification(ZIP)的步骤。</p>
<ol type="1">
<li>通过线性变换来对原始图像进行模糊。</li>
<li>通过加以限制的扩散模型对模糊后的图像进行信息恢复。</li>
</ol>
<p>不能直接用模糊后的图像来进行分类，由于损失了太多信息，这样会导致准确率低。</p>
<h2 id="图像变换和分解">图像变换和分解</h2>
<p>通过下式对图像进行变换： <span class="math display">\[
x^A=Ax^P=A(x+p)
\]</span></p>
<ul>
<li><span class="math inline">\(x^A\)</span>：经过线性变换模糊后的图像</li>
<li><span class="math inline">\(A\)</span>：线性变换</li>
<li><span class="math inline">\(x\)</span>：原始图像</li>
<li><span class="math inline">\(p\)</span>：触发器，毒化数据</li>
</ul>
<p>理想的经过扩散模型恢复的图片<span class="math inline">\(x_0\)</span>应该具备以下特性： <span class="math display">\[
A(x_0+p)=A(x+p)=x^A
\]</span> 将图片x进行分解： <span class="math display">\[
x=A^{\dagger}Ax+(I-A^{\dagger}A)x
\]</span>
称左边这一部分为范围空间中的观测，而右边这一部分则是零空间中的观测。</p>
<p>于是： <span class="math display">\[
(x_0+p)=A^{\dagger}A(x_0+p)+(I-A^{\dagger}A)(x_0+p)
\]</span> 得出： <span class="math display">\[
x_0=A^{\dagger}x^A-A^\dagger Ap+(I-A^\dagger A)x_0
\]</span>
(5)则是理想的恢复后的图像组成表示，前两部分是范围空间的中的观测，最后一部分是零空间中的观测。但死零空间中的信息是不可观测的。</p>
<h2 id="用扩散模型来进行图像净化">用扩散模型来进行图像净化</h2>
<p>通过扩散模型的前向过程，和上面的公式(5)，可以得出：</p>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240318194853919.png" alt="image-20240318194853919">
<figcaption aria-hidden="true">image-20240318194853919</figcaption>
</figure>
<p><span class="math inline">\(\epsilon_t\)</span>是由扩散模型<span class="math inline">\(g_\phi\)</span>生成的噪声，<span class="math inline">\(\epsilon _t=g_\phi (x_t,t)\)</span>，<span class="math inline">\(x_t^{&#39;}\)</span>是<span class="math inline">\(x_t\)</span>的估计。</p>
<p>然后再用扩散模型的反向过程对<span class="math inline">\(x_t\)</span>进行迭代：</p>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240318195448130.png" alt="image-20240318195448130">
<figcaption aria-hidden="true">image-20240318195448130</figcaption>
</figure>
<h2 id="将反向过程适配到零样本适配">将反向过程适配到零样本适配</h2>
<p>由于防御者不知道触发器<span class="math inline">\(p\)</span>，因此，选择忽略中间带有<span class="math inline">\(p\)</span>的一项，并用<span class="math inline">\(\hat x_t\)</span>来估计<span class="math inline">\(x_t^{&#39;}\)</span></p>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240318200936982.png" alt="image-20240318200936982">
<figcaption aria-hidden="true">image-20240318200936982</figcaption>
</figure>
<p>选择忽略<span class="math inline">\(\sqrt{\bar \alpha _t}A^\dagger
Ap\)</span>的原因还有：</p>
<ul>
<li><span class="math inline">\(\sqrt {\bar \alpha
_t}\)</span>刚开始很小。</li>
<li>由于后门攻击的隐蔽性，所以p也很小</li>
</ul>
<p>由于是迭代，这样进行近似可能会带来指数级别的误差，因此，作者采取将每一次迭代的近似误差限制在一个范围内，确保最后恢复出的图像能够在模糊触发器的同时，保留原始图片的关键信息。</p>
<p>假设： <span class="math display">\[
g_\phi (x_t,t)=\epsilon _t
\]</span> 那么： <span class="math display">\[
g_\phi ((x_t+\sqrt{\bar \alpha _t}A^\dagger Ap), t)=\epsilon
_t+\epsilon_t^{&#39;}
\]</span> 通过推导可以得到误差的边界：</p>
<figure>
<img data-src="./Black-box-Backdoor-Defense-via-Zero-shot-Image-Purification/image-20240319141055709.png" alt="image-20240319141055709">
<figcaption aria-hidden="true">image-20240319141055709</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">chengyiqiu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>

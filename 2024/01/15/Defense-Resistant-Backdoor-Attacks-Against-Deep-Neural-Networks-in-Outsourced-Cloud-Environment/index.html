<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="发在期刊IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS上，简称JSAC，属于A会。 摘要 背景：外包云环境下。 工作量：  一种名为RobNet的攻击方法，关键要素为： 使得触发器多样化：多个位置都有触发器的patch，这些触发器是通过梯度下降来生成的 加强模型的结构（？外包不是不能改变模型结构吗）    实验：  数据集：MNIST、GTSRB、">
<meta property="og:type" content="article">
<meta property="og:title" content="Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment">
<meta property="og:url" content="http://example.com/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="发在期刊IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS上，简称JSAC，属于A会。 摘要 背景：外包云环境下。 工作量：  一种名为RobNet的攻击方法，关键要素为： 使得触发器多样化：多个位置都有触发器的patch，这些触发器是通过梯度下降来生成的 加强模型的结构（？外包不是不能改变模型结构吗）    实验：  数据集：MNIST、GTSRB、">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116155630399.png">
<meta property="og:image" content="http://example.com/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116160419992.png">
<meta property="og:image" content="http://example.com/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116164552734.png">
<meta property="article:published_time" content="2024-01-15T11:47:40.000Z">
<meta property="article:modified_time" content="2024-04-19T04:35:27.367Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="backdoor">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116155630399.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/" class="article-date">
  <time class="dt-published" datetime="2024-01-15T11:47:40.000Z" itemprop="datePublished">2024-01-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>发在期刊IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS上，简称JSAC，属于A会。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p> 背景：外包云环境下。</p>
<p>工作量：</p>
<ul>
<li>一种名为RobNet的攻击方法，关键要素为：<ul>
<li>使得触发器多样化：多个位置都有触发器的patch，这些触发器是通过梯度下降来生成的</li>
<li>加强模型的结构（<strong>？外包不是不能改变模型结构吗</strong>）</li>
</ul>
</li>
</ul>
<p>实验：</p>
<ul>
<li>数据集：MNIST、GTSRB、CIFAR-10</li>
<li>防御方法：Pruning, NeuralCleanse, Strip, and ABS</li>
<li>baseline：BadNets、<strong>Hidden Backdoors</strong></li>
</ul>
<h1 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h1><p>和以前的工作不同（用户只需要检测收到的模型在验证集上的正确率是否大于预期），本文考虑一个更健壮的情况：收到的模型需要通过当前最先进的后门检测方法。</p>
<h1 id="RobNet"><a href="#RobNet" class="headerlink" title="RobNet"></a>RobNet</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="触发器生成"><a href="#触发器生成" class="headerlink" title="触发器生成"></a>触发器生成</h3><p>触发器生成分了为两种：</p>
<ul>
<li>random triggers</li>
<li>Model-dependent triggers</li>
</ul>
<p>其中模型依赖触发器就是通过DNN生成的触发器。</p>
<p>本文选取的就是model-dependent triggers，本文的生成算法，不仅可以提高攻击成功率，还可以逃避掉大部分防御算法。</p>
<p>生成算法要做的是：对一个空的mask进行值填充，让selected neuron能够最大的激活。而如何选取selected neuron？选取<strong>离targeted label比较近的neuron</strong>。具体做法是：训练出一个干净的模型，然后将激活值和权重都比较高的神经元作为selected neuron。</p>
<p>实验（chapter 5）表明，该神经元不会被pruning剪掉，因此，该攻击是可以evade pruning operation。</p>
<h3 id="后门注入"><a href="#后门注入" class="headerlink" title="后门注入"></a>后门注入</h3><p>原始样本$(x,c)$</p>
<p>投毒的恶意样本$(x^*,c^*)$</p>
<ul>
<li>x: the clean sample</li>
<li>c: the clean label</li>
<li>$x^*$: the sample x with trigger</li>
<li>$c^*$ the targeted label</li>
</ul>
<p>可以通过改变触发器的位置来构造多个恶意样本，这些恶意样本<del>可能targeted label也不</del>一样。对于这种patch的触发器，trigger location非常重要，如果训练阶段和测试阶段使用的location不一样，那么攻击的成功率会大大降低。因此本文选择在训练的时候就将所有的触发器的位置都考虑到，以增加模型的健壮性。</p>
<p>然后就是重训练阶段。</p>
<p>作者强调，只重新训练了部分层（选中神经元和输出层之间的层），这样做的目的是保证其他样本的正确性。</p>
<h2 id="触发器生成-1"><a href="#触发器生成-1" class="headerlink" title="触发器生成"></a>触发器生成</h2><h3 id="掩码决定"><a href="#掩码决定" class="headerlink" title="掩码决定"></a>掩码决定</h3><p>本文还没有考虑掩码的形状）这部分内容是确定掩码的大小，在攻击成功率和stealthiness之间权衡，最终确定了7%作为掩码的大小，恰好到Neural Cleanse的阈值</p>
<h3 id="神经元决定"><a href="#神经元决定" class="headerlink" title="神经元决定"></a>神经元决定</h3><p>选full-connection层，权重较大的神经元。</p>
<img src="./Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116155630399.png" alt="image-20240116155630399" style="zoom: 50%;" />

<ul>
<li>$\mathcal N$: a set of neurons in layer l</li>
<li>$l$: selected layer </li>
<li>$\mathcal J$: a set of neurons in layer l - 1</li>
</ul>
<p><strong>这其实是NDSS上的Trojaning Attack on Neural Networks中的方法。</strong></p>
<p>这种方法有弊端，选出的神经元对所有的输入都很敏感。pruning defence是activation- based的方法。选出来的neuron很可能会表现的低激活并且被pruning。</p>
<p>于是作者的思路是：找到weight和activation都比较大的神经元作为selected weight。</p>
<img src="./Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116160419992.png" alt="image-20240116160419992" style="zoom:50%;" />

<ul>
<li>$\lambda$: balance coefficient </li>
<li>$\mathcal X^c$: a set of benign samples of target misclassfication label c</li>
<li>$I_{[F(x)&#x3D;n]}$: the activation of neuron n, input sample x</li>
</ul>
<h3 id="触发器生成-2"><a href="#触发器生成-2" class="headerlink" title="触发器生成"></a>触发器生成</h3><p>优化路径<br>$$<br>\vert v_{n,t}-v_t\vert^2<br>$$</p>
<ul>
<li>$v_{n,t}$：当前回合神经元n的激活</li>
<li>$v_t$：目标激活，选取selected layer中的最大激活值作为$v_t$</li>
</ul>
<p>其中，从l-1层到l层，neuron n的激活可以表示i为：<br>$$<br>a_n^l&#x3D;\Phi ^l( \sum_{j&#x3D;1}^K(w_{n,j}^{l-1,l}a_j^{l-1})+b_n^l )<br>$$</p>
<h2 id="后门注入-1"><a href="#后门注入-1" class="headerlink" title="后门注入"></a>后门注入</h2><h3 id="数据投毒"><a href="#数据投毒" class="headerlink" title="数据投毒"></a>数据投毒</h3><p>$$<br>x^*&#x3D;x+trigger\odot M<br>$$</p>
<p>加了个mult- location，单个位置的话，很容易被Neuron Clean监测到。因此可以在一张图上加多个trigger。如6和8都加上trigger</p>
<p><img src="/./Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/image-20240116164552734.png" alt="image-20240116164552734"></p>
<h3 id="模型重训练"><a href="#模型重训练" class="headerlink" title="模型重训练"></a>模型重训练</h3><ul>
<li>先用干净数据集训练出一个良好的模型</li>
<li>通过良好模型+触发器生成算法&#x3D;&gt;触发器</li>
<li>触发器+数据集&#x3D;&gt;投毒数据集&#x3D;&gt;重训练得到后门模型。</li>
</ul>
<p>PS：只有触发器生成层和输出层进行重训练。为了保证良性样本的正确率</p>
<h2 id="多触发器攻击"><a href="#多触发器攻击" class="headerlink" title="多触发器攻击"></a>多触发器攻击</h2><p>首先是，多触发器，单目标标签。<br>$$<br>x+A\odot M_A \<br>x+B\odot M_B \<br>x+A\odot M_A+B\odot M_B<br>$$<br>(4)有三个中毒样本，误分类标签都是c。两种掩码，每种掩码都是用同一种算法但是不同的location生成出来的。这样能够提高攻击的鲁棒性。</p>
<p>多触发器，多标签。<br>$$<br>(x+A\odot M,c_1) \<br>(x+B\odot M,c_2) \<br>(x+C\odot M,c_3)<br>$$<br>在测试中，只要有中毒样本有一种就行了。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文是基于patch的后门攻击，相比于BadNet的single- pixel、pattern- pixel更加现实，同时详细讲述了实施后门攻击的每一个步骤：</p>
<ul>
<li>训练干净模型</li>
<li>（这里没有选取掩码的形状，掩码默认7%图片大小的全1像素组合）</li>
<li>选取layer、neuron，然后根据neuron生成触发器</li>
<li>进行数据投毒，然后将毒化数据集对模型进行重训练。并且，作者为了保证干净样本的正确率，只对部分层进行了重新训练</li>
<li>对多触发器展开了实验（这部分意义不是很大，因为patch的触发器太容易肉眼看出，但是可以借鉴其思想：为了保证后门攻击的隐蔽性</li>
</ul>
<p>这篇文章是2021年中的，写作时间可能在2020年，细节讲的比较详细，从初学者的角度能够更好理解，然而patch的方法缺点太大，更好的方向是作者的2022年发表在NDSS上的论文：ATTEQ，mask和trigger都是通过DNN生成的，肉眼也不可见。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/01/15/Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment/" data-id="clw6dgvjb000ii49f4shp2nx4" data-title="Defense-Resistant-Backdoor-Attacks-Against-Deep-Neural-Networks-in-Outsourced-Cloud-Environment" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/01/16/Neural-Cleanse-Identifying-and-Mitigating-Backdoor-Attacks-in-Neural-Networks/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Neural-Cleanse-Identifying-and-Mitigating-Backdoor-Attacks-in-Neural-Networks
        
      </div>
    </a>
  
  
    <a href="/2024/01/08/Backdoor-Defense-with-Machine-Unlearning/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Backdoor_Defense_with_Machine_Unlearning</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/EasyRL/">EasyRL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Graph-Neural-Networks-Foundations-Frontiers-and-Applications/">Graph Neural Networks: Foundations, Frontiers, and Applications</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs224w/">cs224w</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/d2l/">d2l</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/writing-paper/">writing  paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C/">实验</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%80%BB%E7%BB%93/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6/">读书</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">高性能计算机网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RL/" rel="tag">RL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anomaly/" rel="tag">anomaly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anomaly/" rel="tag">anomaly&#39;</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/backdoor/" rel="tag">backdoor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cnn/" rel="tag">cnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gnn/" rel="tag">gnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lab/" rel="tag">lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/poisoning/" rel="tag">poisoning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rl/" rel="tag">rl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rnn/" rel="tag">rnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" rel="tag">信息论</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/anomaly/" style="font-size: 12px;">anomaly</a> <a href="/tags/anomaly/" style="font-size: 10px;">anomaly'</a> <a href="/tags/backdoor/" style="font-size: 20px;">backdoor</a> <a href="/tags/cnn/" style="font-size: 10px;">cnn</a> <a href="/tags/diffusion/" style="font-size: 18px;">diffusion</a> <a href="/tags/gnn/" style="font-size: 14px;">gnn</a> <a href="/tags/lab/" style="font-size: 10px;">lab</a> <a href="/tags/poisoning/" style="font-size: 16px;">poisoning</a> <a href="/tags/rl/" style="font-size: 10px;">rl</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" style="font-size: 10px;">信息论</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/05/10/limu-read-paper/">limu_read_paper</a>
          </li>
        
          <li>
            <a href="/2024/05/06/VillanDiffusion/">VillanDiffusion</a>
          </li>
        
          <li>
            <a href="/2024/04/27/Infomation-Theory-Inference-and-Learning-Algorithms/">Infomation_Theory_Inference_and_Learning_Algorithms</a>
          </li>
        
          <li>
            <a href="/2024/04/22/TrojDiff/">TrojDiff</a>
          </li>
        
          <li>
            <a href="/2024/04/18/Diffusion-Backdoor-Embed/">Diffusion-Backdoor-Embed</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>
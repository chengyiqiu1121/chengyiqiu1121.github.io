
  <!DOCTYPE html>
  <html lang="en"  >
  <head>
  <meta charset="utf-8">
  

  

  

  
  <script>
    window.icon_font = '4552607_ikzjpc9jicn';
  </script>
  
  
  <title>
    Neural_Network_Diffusion |
    
    Hexo
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CUbuntu%20Mono:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" as="style" onload="this.onload&#x3D;null;this.rel&#x3D;&#39;stylesheet&#39;">
  
  
<link rel="stylesheet" href="/css/loader.css">

  <meta name="description" content="Under ICLR 2024 double-blind review 使用一个自动编码器，来提取训练模型参数中的隐藏表征，然后扩散模型根据这些隐藏参数表征，合成一些随机噪声，输出一些新的表征给自动编码器的解码器部分，输出就是神经网络的参数。 神经网络扩散初步了解扩散模型扩散模型分为两个过程，前向过程和反向过程：  前向过程是对原始图像不断添加高斯噪声（由$\beta$约束），经过$T$步后，得到">
<meta property="og:type" content="article">
<meta property="og:title" content="Neural_Network_Diffusion">
<meta property="og:url" content="http://example.com/2024/03/24/Neural-Network-Diffusion/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Under ICLR 2024 double-blind review 使用一个自动编码器，来提取训练模型参数中的隐藏表征，然后扩散模型根据这些隐藏参数表征，合成一些随机噪声，输出一些新的表征给自动编码器的解码器部分，输出就是神经网络的参数。 神经网络扩散初步了解扩散模型扩散模型分为两个过程，前向过程和反向过程：  前向过程是对原始图像不断添加高斯噪声（由$\beta$约束），经过$T$步后，得到">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240324121348853.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240324121522824.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240324121845235.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240324124652683.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240324133345603.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240328153848280.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240328162902109.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240328163035736.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240328165743211.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240328181545590.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240402122657089.png">
<meta property="og:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240402124224411.png">
<meta property="article:published_time" content="2024-03-24T02:53:40.000Z">
<meta property="article:modified_time" content="2024-04-16T10:25:31.000Z">
<meta property="article:author" content="chengyiqiu">
<meta property="article:tag" content="diffusion">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/03/24/Neural-Network-Diffusion/image-20240324121348853.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="https://npm.webcache.cn/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://npm.webcache.cn/katex@0.16.9/dist/katex.min.css">

  
  
  
  
<script src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js"></script>

  
    
<link rel="stylesheet" href="https://npm.webcache.cn/wowjs@1.1.3/css/libs/animate.css">

    
<script src="https://npm.webcache.cn/wowjs@1.1.3/dist/wow.min.js"></script>

    <script>
      new WOW({
        offset: 0,
        mobile: true,
        live: false
      }).init();
    </script>
  
  
    <script src="/sw.js"></script>
  
<meta name="generator" content="Hexo 7.2.0"></head>

  <body>
    
  <div id='loader'>
    <div class="loading-left-bg"></div>
    <div class="loading-right-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi">
        <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
          <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
          <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
          <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
        </svg>
      </div>
      <div class="loading-word">少女祈祷中...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    const startLoading = () => {
      time = Date.now();
      document.getElementById('loader').classList.remove("loading");
    }
    const endLoading = () => {
      if (!time) {
        document.body.style.overflow = 'auto';
        document.getElementById('loader').classList.add("loading");
      } else {
        if (Date.now() - time > 500) {
          time = null;
          document.body.style.overflow = 'auto';
          document.getElementById('loader').classList.add("loading");
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('load', endLoading);
    document.getElementById('loader').addEventListener('click', endLoading);
  </script>


    <div id="container">
      <div id="wrap">
        <div id="header-nav">
  <nav id="main-nav">
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/">Home</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/archives">Archives</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/about">About</a>
      </span>
    
      <span class="main-nav-link-wrap">
        <span class="main-nav-icon"></span>
        <a class="main-nav-link" href="/friend">Friend</a>
      </span>
    
    <a id="main-nav-toggle" class="nav-icon"></a>
  </nav>
  <nav id="sub-nav">
    
      <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
    
    
    
  </nav>
</div>
<header id="header">
  
    <img fetchpriority="high" src="/images/banner.jpg" alt="Neural_Network_Diffusion">
  
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <div id="logo-wrap">
        
          
          
            <a href="/" id="logo">
              <h1>Neural_Network_Diffusion</h1>
            </a>
          
        
      </div>
      
        
        <h2 id="subtitle-wrap">
          
        </h2>
      
    </div>
  </div>
</header>

        <div id="content" class="outer">
          
          <section id="main"><article id="post-Neural-Network-Diffusion" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    <div class="article-meta">
      <div class="article-date wow slideInLeft">
  <a href="/2024/03/24/Neural-Network-Diffusion/" class="article-date-link">
    <time datetime="2024-03-24T02:53:40.000Z" itemprop="datePublished">2024-03-24</time>
  </a>
</div>

      
  <div class="article-category wow slideInLeft">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>
  </div>


    </div>
    <div class="hr-line"></div>
    

    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Under ICLR 2024 double-blind review</p>
<p>使用一个自动编码器，来提取训练模型参数中的隐藏表征，然后扩散模型根据这些隐藏参数表征，合成一些随机噪声，输出一些新的表征给自动编码器的解码器部分，输出就是神经网络的参数。</p>
<h1 id="神经网络扩散"><a href="#神经网络扩散" class="headerlink" title="神经网络扩散"></a>神经网络扩散</h1><h2 id="初步了解扩散模型"><a href="#初步了解扩散模型" class="headerlink" title="初步了解扩散模型"></a>初步了解扩散模型</h2><p>扩散模型分为两个过程，前向过程和反向过程：</p>
<ul>
<li><p>前向过程是对原始图像不断添加高斯噪声（由$\beta$约束），经过$T$步后，得到一个随机高斯噪声（$T\to \infty$​时，最后得到的一定是噪声）</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240324121348853.png" alt="image-20240324121348853"></p>
<ul>
<li>$q(.)$：前向过程</li>
<li>$N(.)$：高斯噪声</li>
<li>$\beta$：约束</li>
<li>$I$：单位矩阵</li>
</ul>
</li>
<li><p>反向过程是前向过程反过来，期望通过选连一个去噪网络（denoising network），移除掉$x_T$上的噪声，直到恢复出原始图像来。</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240324121522824.png" alt="image-20240324121522824"></p>
<ul>
<li>$p_\theta (.)$：反向过程，$\theta$是可学习的参数</li>
<li>$\mu _\theta (.)$：通过$\theta$估计的高斯噪声的均值</li>
<li>$\sum _\theta (.)$：通过$\theta$​估计的高斯噪声的方差</li>
</ul>
</li>
<li><p>去噪网络的优化：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240324121845235.png" alt="image-20240324121845235"></p>
<p>$D_{KL}(.\vert \vert .)$是通过KL散度来计算两个分布之间的差距。</p>
</li>
</ul>
<p>扩散模型的可行之处在于：能够通过反向过程找到一个去噪网络，将原始的高斯分布转化成最终期望得到的分布。</p>
<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240324124652683.png" alt="image-20240324124652683"></p>
<h2 id="参数自动编码器"><a href="#参数自动编码器" class="headerlink" title="参数自动编码器"></a>参数自动编码器</h2><p>首先收集k个训练性能良好的模型，其参数可以表示为：$S&#x3D;[s_1,…,s_K]$，将这些参数展开平铺成向量：$V&#x3D;[v_1,…v_K]$，然后通过编码器来提取参数潜在的特征：<br>$$<br>Z&#x3D;[z_1,…,z_K]&#x3D;f_{encoder}(V,\sigma)<br>$$<br>然后将提取出的潜在参数特征$Z$输入到解码器中生成重构后的参数：<br>$$<br>V^{‘}&#x3D;[v_1^{‘},…,v_K^{‘}]&#x3D;f_{decoder}(Z,\rho)<br>$$<br>其中$\sigma,\rho$是参数。</p>
<p>优化路径是最小化MSE：<br>$$<br>L_{MSE}&#x3D;\frac{1}{K}\sum _1^K\Vert v _k-v_k^{‘}\Vert^2<br>$$</p>
<h2 id="参数生成"><a href="#参数生成" class="headerlink" title="参数生成"></a>参数生成</h2><p>若是直接采取将参数$V$输入到编码器，然后解码器输出重构后的参数$V_{‘}$，这样会导致过大的存储开销，尤其是当$V$的维度比较高的时候。</p>
<p>因此，作者采用DDPM中的优化过程来优化去噪网络；<br><img src="/2024/03/24/Neural-Network-Diffusion/image-20240324133345603.png" alt="image-20240324133345603"></p>
<ul>
<li>$\epsilon$：高斯噪声</li>
<li>$\theta$：去噪网络的参数</li>
<li>$\epsilon _\theta$：去噪网络生成的噪声</li>
<li>$t$：每一轮</li>
<li>$\bar \alpha _t$：每一轮的噪声强度</li>
</ul>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><ol>
<li><p><strong>数据集</strong></p>
<p>MNIST (LeCun et al., 1998), CIFAR-10&#x2F;100 (Krizhevsky et al., 2009), ImageNet-1K. (Deng et al., 2009), STL-10 (Coates et al., 2011), Flowers (Nilsback &amp; Zisserman, 2008), Pets (Parkhi et al., 2012), F-101 (Bossard et al., 2014) </p>
</li>
<li><p><strong>架构</strong></p>
<p>最开始是在比较小的模型上实验的，这些模型由卷积层、池化层、全连接层组成：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240328153848280.png" alt="image-20240328153848280"></p>
<p>使用的卷积层是2D卷积，参考的是DDPM（采用的U-net，生成高质量图片，用的2D-conv），但是效果并不好，可能的原因是图片像素和参数不能一概处理，因此换成了1D-conv，对比结果如下：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240328162902109.png" alt="image-20240328162902109"></p>
<p>在更换卷积层的时候，作者也考虑了下直接将卷积层更换为FC，二者效果差不多，但是1D-conv的存储开销低于FC，因此还是选取了1D-conv：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240328163035736.png" alt="image-20240328163035736"></p>
<p>此外，还做了消融实验，找到了一个参数$K&#x3D;200$使得模型的性能最优。</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240328165743211.png" alt="image-20240328165743211"></p>
<p>作者是在扩大模型架构的时候发现了存储开销特别大的问题，灵感来于stable diffusion，作者采用了一个自动编码器来提取潜在特征，以此来对模型的参数进行降维。</p>
</li>
<li><p><strong>准备训练数据</strong></p>
<p>准备了200个独立的高性能参数来训练DiffNet，对于架构简单，参数少的模型，直接从头开始训练；对于架构复杂的，则是在预训练模型的基础上来进行的。</p>
</li>
<li><p><strong>训练细节</strong></p>
<p>首先把自动编码器训练2000轮，然后将潜在特征和解码器的参数都保存起来。</p>
<p>然后训练扩散模型来生成表征，扩散模型的结构式基于1D-conv的U-Net，</p>
</li>
<li><p><strong>推断阶段</strong></p>
<p>将100个噪声输入到扩散模型中去，生成了100个模型，选取其中在训练数据集上性能最好的网络。整个的性能图如下：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240328181545590.png" alt="image-20240328181545590"></p>
</li>
</ol>
<h2 id="代码阅读"><a href="#代码阅读" class="headerlink" title="代码阅读"></a>代码阅读</h2><h3 id="准备训练数据"><a href="#准备训练数据" class="headerlink" title="准备训练数据"></a>准备训练数据</h3><p>作者通过训练一个ResNet18来得到编码器的训练数据。，也就是下图中的参数输入部分：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240402122657089.png" alt="image-20240402122657089"></p>
<p>代码部分在<code>tsak_training.py</code>中，核心部分是这个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># override the abstract method in base_task.py, you obtain the model data for generation</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_for_data</span>(<span class="params">self</span>):</span><br></pre></td></tr></table></figure>

<p>训练一共有400轮：</p>
<ol>
<li><p>首先将ResNet18训练200轮，将其参数保存下来:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i == (epoch - <span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 在第199的时候保存模型</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;saving the model&quot;</span>)</span><br><span class="line">    torch.save(net, os.path.join(tmp_path, <span class="string">&quot;whole_model.pth&quot;</span>))</span><br><span class="line">    <span class="comment"># 将不需要训练的层进行固定（取消梯度），后续训练只训练需要训练的层train_layer</span></span><br><span class="line">    fix_partial_model(train_layer, net)</span><br><span class="line">    parameters = []</span><br></pre></td></tr></table></figure>
</li>
<li><p>在200轮后的训练中，只训练需要需要训练的层，其他的层的参数被冻结了，每过10轮，都会将训练的层的参数保存下来，存储到临时文件夹中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i &gt;= epoch:</span><br><span class="line">    <span class="comment"># 在接下来的训练中，每训练一轮，都会将需要保存的层的参数保存下来，存储到一个列表中</span></span><br><span class="line">    parameters.append(state_part(train_layer, net))</span><br><span class="line">    save_model_accs.append(acc)</span><br><span class="line">    <span class="comment"># 当列表的长度等于10时，或者到达训练结束的时候，将参数保存在硬盘上的临时文件夹中。</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(parameters) == <span class="number">10</span> <span class="keyword">or</span> i == all_epoch - <span class="number">1</span>:</span><br><span class="line">        torch.save(parameters, os.path.join(tmp_path, <span class="string">&quot;p_data_&#123;&#125;.pt&quot;</span>.<span class="built_in">format</span>(i)))</span><br><span class="line">        <span class="comment"># 初始化列表</span></span><br><span class="line">        parameters = []</span><br></pre></td></tr></table></figure>
</li>
<li><p>最后得到了一个最重要的数据<code>data.pt</code>，里面存储了整个模型<code>whole_model.pth</code>，编码器需要的训练数据<code>pdata</code>，可以将<code>data.pt</code> load一下：</p>
<p><img src="/2024/03/24/Neural-Network-Diffusion/image-20240402124224411.png" alt="image-20240402124224411"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">   &#123;<span class="string">&#x27;pdata&#x27;</span>: tensor([[<span class="number">0.3967</span>, <span class="number">0.3701</span>, <span class="number">0.3879</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0885</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3967</span>, <span class="number">0.3701</span>, <span class="number">0.3879</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0885</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3967</span>, <span class="number">0.3701</span>, <span class="number">0.3878</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0885</span>, <span class="number">0.0762</span>],</span><br><span class="line">           ...,</span><br><span class="line">           [<span class="number">0.3975</span>, <span class="number">0.3710</span>, <span class="number">0.3888</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3975</span>, <span class="number">0.3710</span>, <span class="number">0.3888</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>],</span><br><span class="line">           [<span class="number">0.3975</span>, <span class="number">0.3710</span>, <span class="number">0.3888</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>]]), <span class="string">&#x27;mean&#x27;</span>: tensor([<span class="number">0.3973</span>, <span class="number">0.3707</span>, <span class="number">0.3885</span>,  ..., <span class="number">0.0686</span>, <span class="number">0.0884</span>, <span class="number">0.0762</span>]), <span class="string">&#x27;std&#x27;</span>: tensor([<span class="number">4.2733e-04</span>, <span class="number">4.3796e-04</span>, <span class="number">4.7875e-04</span>,  ..., <span class="number">2.7116e-05</span>, <span class="number">8.1900e-06</span>,</span><br><span class="line">           <span class="number">2.2222e-05</span>]), <span class="string">&#x27;model&#x27;</span>: ResNet(</span><br><span class="line">     (conv1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">     (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">     (layer1): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (layer2): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential(</span><br><span class="line">           (<span class="number">0</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">           (<span class="number">1</span>): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         )</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">128</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (layer3): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential(</span><br><span class="line">           (<span class="number">0</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">           (<span class="number">1</span>): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         )</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (layer4): Sequential(</span><br><span class="line">       (<span class="number">0</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential(</span><br><span class="line">           (<span class="number">0</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line">           (<span class="number">1</span>): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         )</span><br><span class="line">       )</span><br><span class="line">       (<span class="number">1</span>): BasicBlock(</span><br><span class="line">         (conv1): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn1): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (conv2): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">         (bn2): BatchNorm2d(<span class="number">512</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">         (shortcut): Sequential()</span><br><span class="line">       )</span><br><span class="line">     )</span><br><span class="line">     (linear): Linear(in_features=<span class="number">512</span>, out_features=<span class="number">100</span>, bias=<span class="literal">True</span>)</span><br><span class="line">   ), <span class="string">&#x27;train_layer&#x27;</span>: [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>], <span class="string">&#x27;performance&#x27;</span>: [<span class="number">71.79</span>, <span class="number">71.78</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.84</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.77</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.82</span>, <span class="number">71.81</span>, <span class="number">71.85</span>, <span class="number">71.89</span>, <span class="number">71.8</span>, <span class="number">71.82</span>, <span class="number">71.85</span>, <span class="number">71.78</span>, <span class="number">71.86</span>, <span class="number">71.87</span>, <span class="number">71.87</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.87</span>, <span class="number">71.82</span>, <span class="number">71.87</span>, <span class="number">71.86</span>, <span class="number">71.86</span>, <span class="number">71.87</span>, <span class="number">71.85</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.86</span>, <span class="number">71.83</span>, <span class="number">71.83</span>, <span class="number">71.93</span>, <span class="number">71.91</span>, <span class="number">71.84</span>, <span class="number">71.8</span>, <span class="number">71.88</span>, <span class="number">71.84</span>, <span class="number">71.78</span>, <span class="number">71.81</span>, <span class="number">71.82</span>, <span class="number">71.8</span>, <span class="number">71.84</span>, <span class="number">71.83</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.89</span>, <span class="number">71.75</span>, <span class="number">71.84</span>, <span class="number">71.78</span>, <span class="number">71.82</span>, <span class="number">71.9</span>, <span class="number">71.86</span>, <span class="number">71.89</span>, <span class="number">71.81</span>, <span class="number">71.8</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.82</span>, <span class="number">71.84</span>, <span class="number">71.76</span>, <span class="number">71.83</span>, <span class="number">71.82</span>, <span class="number">71.87</span>, <span class="number">71.86</span>, <span class="number">71.83</span>, <span class="number">71.87</span>, <span class="number">71.84</span>, <span class="number">71.81</span>, <span class="number">71.85</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.76</span>, <span class="number">71.85</span>, <span class="number">71.78</span>, <span class="number">71.75</span>, <span class="number">71.86</span>, <span class="number">71.88</span>, <span class="number">71.83</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.86</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.9</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.88</span>, <span class="number">71.86</span>, <span class="number">71.82</span>, <span class="number">71.82</span>, <span class="number">71.84</span>, <span class="number">71.84</span>, <span class="number">71.82</span>, <span class="number">71.89</span>, <span class="number">71.79</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.8</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.83</span>, <span class="number">71.84</span>, <span class="number">71.89</span>, <span class="number">71.87</span>, <span class="number">71.86</span>, <span class="number">71.8</span>, <span class="number">71.84</span>, <span class="number">71.83</span>, <span class="number">71.79</span>, <span class="number">71.84</span>, <span class="number">71.9</span>, <span class="number">71.85</span>, <span class="number">71.86</span>, <span class="number">71.88</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.78</span>, <span class="number">71.83</span>, <span class="number">71.87</span>, <span class="number">71.89</span>, <span class="number">71.81</span>, <span class="number">71.86</span>, <span class="number">71.77</span>, <span class="number">71.84</span>, <span class="number">71.92</span>, <span class="number">71.82</span>, <span class="number">71.81</span>, <span class="number">71.8</span>, <span class="number">71.78</span>, <span class="number">71.85</span>, <span class="number">71.89</span>, <span class="number">71.81</span>, <span class="number">71.75</span>, <span class="number">71.8</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.88</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.8</span>, <span class="number">71.85</span>, <span class="number">71.8</span>, <span class="number">71.95</span>, <span class="number">71.85</span>, <span class="number">71.87</span>, <span class="number">71.83</span>, <span class="number">71.87</span>, <span class="number">71.84</span>, <span class="number">71.82</span>, <span class="number">71.87</span>, <span class="number">71.8</span>, <span class="number">71.86</span>, <span class="number">71.81</span>, <span class="number">71.89</span>, <span class="number">71.86</span>, <span class="number">71.84</span>, <span class="number">71.87</span>, <span class="number">71.81</span>, <span class="number">71.87</span>, <span class="number">71.83</span>, <span class="number">71.82</span>, <span class="number">71.88</span>, <span class="number">71.85</span>, <span class="number">71.84</span>, <span class="number">71.79</span>, <span class="number">71.84</span>, <span class="number">71.81</span>, <span class="number">71.84</span>, <span class="number">71.86</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.85</span>, <span class="number">71.83</span>, <span class="number">71.81</span>, <span class="number">71.87</span>, <span class="number">71.83</span>, <span class="number">71.88</span>, <span class="number">71.84</span>, <span class="number">71.85</span>, <span class="number">71.81</span>, <span class="number">71.81</span>, <span class="number">71.76</span>, <span class="number">71.89</span>, <span class="number">71.86</span>], <span class="string">&#x27;cfg&#x27;</span>: &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;classification&#x27;</span>, <span class="string">&#x27;data&#x27;</span>: &#123;<span class="string">&#x27;data_root&#x27;</span>: <span class="string">&#x27;data/cifar100&#x27;</span>, <span class="string">&#x27;dataset&#x27;</span>: <span class="string">&#x27;cifar100&#x27;</span>, <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">2048</span>, <span class="string">&#x27;num_workers&#x27;</span>: <span class="number">8</span>&#125;, <span class="string">&#x27;model&#x27;</span>: &#123;<span class="string">&#x27;_target_&#x27;</span>: <span class="string">&#x27;models.resnet.ResNet18&#x27;</span>, <span class="string">&#x27;num_classes&#x27;</span>: <span class="number">100</span>&#125;, <span class="string">&#x27;optimizer&#x27;</span>: &#123;<span class="string">&#x27;_target_&#x27;</span>: <span class="string">&#x27;torch.optim.SGD&#x27;</span>, <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.9</span>, <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0.0005</span>&#125;, <span class="string">&#x27;lr_scheduler&#x27;</span>: &#123;<span class="string">&#x27;_target_&#x27;</span>: <span class="string">&#x27;torch.optim.lr_scheduler.MultiStepLR&#x27;</span>, <span class="string">&#x27;milestones&#x27;</span>: [<span class="number">60</span>, <span class="number">120</span>, <span class="number">160</span>, <span class="number">200</span>], <span class="string">&#x27;gamma&#x27;</span>: <span class="number">0.2</span>&#125;, <span class="string">&#x27;epoch&#x27;</span>: <span class="number">200</span>, <span class="string">&#x27;save_num_model&#x27;</span>: <span class="number">200</span>, <span class="string">&#x27;train_layer&#x27;</span>: [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>], <span class="string">&#x27;param&#x27;</span>: &#123;<span class="string">&#x27;data_root&#x27;</span>: <span class="string">&#x27;param_data/cifar100/data.pt&#x27;</span>, <span class="string">&#x27;k&#x27;</span>: <span class="number">200</span>, <span class="string">&#x27;num_workers&#x27;</span>: <span class="number">4</span>&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">### 训练扩散模型</span></span><br><span class="line"></span><br><span class="line">代码`train_p_diff.py`，有两种模式，可以在`base.yaml`中选择是训练或者是测试扩散模型。</span><br><span class="line"></span><br><span class="line">项目作者将代码封装的比较好，核心代码在`core`文件夹里面。</span><br><span class="line"></span><br><span class="line"><span class="comment">## 实验结果</span></span><br><span class="line"></span><br><span class="line">再次梳理一下这篇论文对应的实验的思路：数据集设置为CIFAR10，网络为ResNet18</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 在CIFAR10上训练ResNet18，将得到的模型保存下来，在test_data上进行测试，得到acc：</span><br><span class="line"></span><br><span class="line">   ```shell</span><br><span class="line">   /home/chengyiqiu/miniconda3/envs/pdiff/<span class="built_in">bin</span>/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">   <span class="number">10.0</span>  <span class="comment"># 这是随机初始化ResNet的acc，十类瞎猜理论上是1/10</span></span><br><span class="line">   <span class="number">86.034</span>  <span class="comment"># 这是加载了保存的state_dict后的ResNet18的准确率，良好</span></span><br><span class="line">   </span><br><span class="line">   Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将训练好的ResNet18，选取train-layer，只训练这些层，其他的层的参数冻结(require grad &#x3D; false)，然后训练200个epoch，将train-layer的参数收集起来，假设模型的train-layer的长度是5120，那么收集到的数据的shape就是：(200, 5120)，通过这些数据训练一个扩散模型。</p>
</li>
<li><p>用训练好的扩散模型生成参数，输入的噪声的维度是(200, latent_shape)，得到200个生成的train-layer的参数，将其加入到第二步中最开始训练好的ResNet18中，替换对应层的参数，并进行测试，下面是测试结果: </p>
<p>这是不替换对应层参数的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model = partial_reverse_tomodel(param, model, train_layer).to(param.device)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/outputs/cifar10/ae_ddpm_cifar10_pth/load.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 7178])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">  0%</span><span class="language-bash">|          | 0/200 [00:00&lt;?, ?it/s]/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=<span class="string">&#x27;sum&#x27;</span> instead.</span></span><br><span class="line">  warnings.warn(warning.format(ret))</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [04:04&lt;00:00,  1.22s/it]</span></span><br><span class="line">Sorted list of accuracies: [92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67, 92.67]</span><br><span class="line">Average accuracy: 92.67</span><br><span class="line">Max accuracy: 92.67</span><br><span class="line">Min accuracy: 92.67</span><br><span class="line">Median accuracy: 92.67</span><br></pre></td></tr></table></figure>

<p>这是替换对应层的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = partial_reverse_tomodel(param, model, train_layer).to(param.device)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/outputs/cifar10/ae_ddpm_cifar10_pth/load.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 7178])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">  0%</span><span class="language-bash">|          | 0/200 [00:00&lt;?, ?it/s]/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=<span class="string">&#x27;sum&#x27;</span> instead.</span></span><br><span class="line">  warnings.warn(warning.format(ret))</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [04:04&lt;00:00,  1.22s/it]</span></span><br><span class="line">Sorted list of accuracies: [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.01, 10.01, 10.01, 10.01, 10.02, 10.03, 10.04, 10.04, 10.08, 10.08, 10.09, 10.16, 10.63, 10.71, 11.04, 11.08, 11.13, 11.17, 11.68, 11.89, 11.94, 12.84, 12.85, 13.27, 13.54, 13.8, 14.11, 14.44, 14.52, 14.77, 14.89, 15.2, 15.93, 16.25, 16.44, 16.7, 17.29, 18.43, 18.44, 18.62, 18.83, 18.9, 18.98, 19.32, 19.34, 19.68, 19.7, 19.9, 20.19, 20.3, 20.3, 20.33, 20.46, 20.85, 20.96, 21.56, 21.6, 22.38, 22.41, 22.41, 23.13, 23.63, 23.71, 23.73, 24.17, 25.84, 26.6, 26.64, 26.76, 26.83, 27.0, 27.26, 27.52, 27.54, 27.72, 27.77, 27.86, 28.0, 28.15, 28.2, 28.29, 28.29, 28.46, 28.71, 28.74, 28.87, 29.02, 29.14, 29.25, 29.93, 30.24, 30.71, 31.66, 32.23, 32.45, 33.66, 34.37, 36.0, 36.56, 36.71, 37.02, 37.32, 37.33, 39.09, 39.4, 39.76, 40.4, 42.54, 44.09, 44.67, 45.6, 46.82, 48.23, 48.83, 52.8, 53.44, 54.1, 54.59, 59.25, 60.46, 63.95, 64.05, 70.35, 70.59, 70.92, 74.63, 76.78, 78.43, 79.81, 80.77, 82.4, 82.61, 85.24, 85.46, 86.22, 87.14, 87.83, 88.27, 88.64, 88.71, 88.98, 89.03, 89.5, 89.94, 89.97, 90.46]</span><br><span class="line">Average accuracy: 28.35</span><br><span class="line">Max accuracy: 90.46</span><br><span class="line">Min accuracy: 10.00</span><br><span class="line">Median accuracy: 19.69</span><br></pre></td></tr></table></figure>

<p>这次扩散模型输出的参数效果一般，但也有性能比较好的参数。</p>
</li>
<li><p>将训练好的模型换成相同架构（ResNet18），相同数据集，植入了后门之后的模型，将对应层的参数进行替换：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/outputs/cifar10/ae_ddpm_cifar10_pth/load.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 7178])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">  0%</span><span class="language-bash">|          | 0/200 [00:00&lt;?, ?it/s]/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=<span class="string">&#x27;sum&#x27;</span> instead.</span></span><br><span class="line">  warnings.warn(warning.format(ret))</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [04:04&lt;00:00,  1.22s/it]</span></span><br><span class="line">Sorted list of accuracies: [1.29, 1.63, 1.99, 2.64, 2.93, 2.98, 3.12, 4.07, 4.18, 4.22, 5.14, 5.18, 5.51, 5.56, 5.65, 6.1, 6.3, 6.4, 7.02, 7.07, 7.34, 7.38, 7.91, 8.75, 8.86, 9.13, 9.15, 9.16, 9.5, 9.65, 9.76, 9.76, 9.78, 9.83, 9.84, 9.86, 9.93, 9.95, 9.96, 9.96, 9.98, 9.98, 9.98, 9.99, 9.99, 9.99, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.01, 10.01, 10.01, 10.02, 10.02, 10.03, 10.03, 10.04, 10.04, 10.06, 10.06, 10.06, 10.07, 10.13, 10.15, 10.23, 10.33, 10.43, 10.46, 10.51, 10.69, 10.83, 11.2, 11.37, 11.38, 11.5, 11.69, 11.87, 12.02, 12.32, 12.34, 12.37, 12.41, 13.09, 13.95, 13.96, 14.04, 14.96, 15.39, 15.8, 17.02, 17.15, 17.23, 17.8, 18.74, 19.39, 20.22]</span><br><span class="line">Average accuracy: 9.94</span><br><span class="line">Max accuracy: 20.22</span><br><span class="line">Min accuracy: 1.29</span><br><span class="line">Median accuracy: 10.00</span><br></pre></td></tr></table></figure>

<p>可以看到，没有高性能参数。</p>
</li>
<li><p>最后单独测试一下植入后门的ResNet的性能，以确定是扩散模型生成的参数导致ResNet的性能下降。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">10.0</span><br><span class="line">94.474</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h2><p>扩散模型的却可以生成高性能参数，但是生成的参数泛化性十分差劲！</p>
<p>简单探究下原因，虽然说论文中说是用了200个高性能模型，但其实上，者200个高性能模型的前面几层都是一样的，假如我这样选取：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_layer = [&#x27;layer4.1.bn1.weight&#x27;, &#x27;layer4.1.bn1.bias&#x27;, &#x27;layer4.1.bn2.bias&#x27;, &#x27;layer4.1.bn2.weight&#x27;, &#x27;linear.weight&#x27;, &#x27;linear.bias&#x27;]</span><br></pre></td></tr></table></figure>

<p>选取模型最后的几层，<strong>那么这最终的200个模型的前面几层的参数都是一样的，这严重限制了扩散模型的泛化性能！</strong></p>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><ol>
<li><p>数据集的transform设置，训练时和测试时不一致，导致训练得到的准确率有较大的drop，若是统一transform之后，训练的正确率得以改善。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>这是gpt的解释：</p>
<figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">在这段代码中，`transforms.Normalize`是PyTorch中用于数据预处理的一个方法，它执行了数据的归一化操作。归一化是机器学习和深度学习中常用的技术，旨在将输入数据的范围和分布调整到特定的区间，以提高模型的训练效率和性能。</span><br><span class="line"></span><br><span class="line">`transforms.Normalize`的参数如下：</span><br><span class="line"></span><br><span class="line">- `mean`: 一个与输入数据的通道数相同长度的列表，表示每个通道的均值。在这个例子中，`[0.5, 0.5, 0.5]`意味着对于RGB图像，每个颜色通道（红、绿、蓝）的均值都被设置为0.5。</span><br><span class="line"></span><br><span class="line">- `std`: 与`mean`类似，这是一个标准差（standard deviation）的列表，用于每个通道。在这个例子中，每个通道的标准差被设置为0.5。</span><br><span class="line"></span><br><span class="line">归一化操作的具体计算方法是将每个通道的数据减去其均值（`mean`），然后除以其标准差（`std`）。对于图像数据，这通常可以表示为以下公式：</span><br><span class="line"></span><br><span class="line"><span class="keyword">\[</span> <span class="keyword">\text</span>&#123;Normalized pixel value&#125; = <span class="keyword">\frac</span>&#123;<span class="keyword">\text</span>&#123;Pixel value&#125; - <span class="keyword">\text</span>&#123;mean&#125;&#125;&#123;<span class="keyword">\text</span>&#123;std&#125;&#125; <span class="keyword">\]</span></span><br><span class="line"></span><br><span class="line">这种操作有助于将输入数据的分布标准化，使其具有零均值和单位方差（当`mean = 0`且`std = 1`时）。这样做的好处包括：</span><br><span class="line"></span><br><span class="line">1. 加速训练过程：归一化后的数据有助于提高梯度下降算法的收敛速度。</span><br><span class="line">2. 改善模型性能：标准化的数据可以使模型更容易学习特征，因为它减少了不同特征之间的量纲影响。</span><br><span class="line">3. 防止梯度消失/爆炸：归一化有助于保持梯度在训练过程中的稳定，防止因输入数据范围过大或过小而导致的梯度问题。</span><br><span class="line"></span><br><span class="line">在实际应用中，`transforms.Normalize`通常与`transforms.ToTensor`一起使用，后者首先将图像数据转换为PyTorch张量（`Tensor`），然后`transforms.Normalize`对这些张量进行归一化处理。这种组合是处理图像数据的常见做法，特别是在使用预训练模型或者需要提高模型性能的场合。</span><br></pre></td></tr></table></figure>

<p>经过我的测试，transform相同和不同相差10个点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">9.83</span><br><span class="line">87.57</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/test.py </span><br><span class="line">10.0</span><br><span class="line">76.11</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="多样化参数以增强泛化性能"><a href="#多样化参数以增强泛化性能" class="headerlink" title="多样化参数以增强泛化性能"></a>多样化参数以增强泛化性能</h2><h3 id="尝试1-慢慢减训练的layer"><a href="#尝试1-慢慢减训练的layer" class="headerlink" title="尝试1 慢慢减训练的layer"></a>尝试1 慢慢减训练的layer</h3><p>先把ResNet训练100（）轮，然后按以下设置，训练这些层，各100轮，最后只拿出全连接层的参数，查看泛化性能是否提升。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_layer = [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer = [<span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>测试下：</p>
<p>相同模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">res_path = <span class="string">&#x27;../tmp/whole_model_resnet18_cifar10.pth&#x27;</span></span><br><span class="line">t = torch.load(res_path)</span><br><span class="line"><span class="comment"># resnet.load_state_dict(torch.load(res_path)[&#x27;model&#x27;])</span></span><br><span class="line">state_dict = torch.load(res_path)[<span class="string">&#x27;state_dict&#x27;</span>]</span><br><span class="line"><span class="comment"># train_layer = [&#x27;layer4.1.bn1.weight&#x27;, &#x27;layer4.1.bn1.bias&#x27;, &#x27;layer4.1.bn2.bias&#x27;, &#x27;layer4.1.bn2.weight&#x27;]</span></span><br><span class="line">train_layer = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/load_pdiff.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 300/300 [26:12&lt;00:00,  5.24s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.558, 0.61, 0.964, 1.198, 1.96, 2.38, 2.44, 2.508, 2.598, 2.772, 3.982, 4.098, 4.724, 5.266, 5.836, 5.926, 6.122, 6.894, 7.068, 7.25, 7.314, 7.446, 7.458, 7.87, 8.048, 8.436, 8.65, 9.362, 10.164, 10.184, 10.69, 10.73, 10.992, 11.008, 11.086, 11.48, 11.614, 11.804, 11.808, 12.058, 12.248, 12.454, 12.494, 12.658, 12.92, 12.92, 13.072, 13.124, 13.128, 13.43, 13.488, 13.524, 13.828, 14.174, 14.244, 14.324, 14.506, 14.54, 14.972, 15.162, 15.212, 15.258, 15.384, 15.41, 15.694, 16.038, 16.062, 16.132, 16.256, 16.258, 17.032, 17.11, 17.22, 17.4, 17.402, 17.842, 18.15, 18.204, 18.288, 18.524, 18.68, 18.798, 18.926, 19.074, 19.44, 19.818, 20.45, 20.49, 20.55, 20.592, 20.61, 20.67, 20.672, 20.74, 20.832, 20.982, 21.242, 21.254, 21.36, 21.748, 21.812, 22.29, 22.8, 22.842, 23.068, 23.356, 23.724, 23.84, 24.076, 24.396, 24.598, 24.726, 25.052, 25.32, 25.72, 25.756, 26.25, 26.83, 26.968, 26.972, 27.21, 27.328, 27.592, 27.996, 28.21, 28.53, 28.726, 29.04, 29.16, 29.194, 29.424, 29.566, 29.598, 29.678, 29.774, 29.808, 30.916, 31.158, 31.24, 31.338, 31.482, 32.002, 32.148, 32.742, 32.804, 33.08, 33.552, 33.76, 33.92, 34.004, 34.774, 35.834, 36.576, 37.622, 37.68, 38.128, 39.032, 39.044, 39.494, 39.708, 39.876, 40.692, 41.044, 41.104, 42.296, 42.618, 42.918, 42.924, 43.336, 43.896, 43.942, 44.39, 44.82, 45.118, 45.322, 45.94, 46.096, 46.416, 48.732, 48.834, 49.362, 49.578, 49.764, 51.2, 51.566, 51.74, 52.22, 52.87, 53.906, 54.406, 54.882, 56.08, 56.298, 57.084, 57.42, 57.71, 58.088, 58.106, 58.928, 60.352, 60.442, 60.736, 62.214, 62.24, 62.672, 63.272, 63.516, 63.776, 63.808, 64.076, 64.376, 64.792, 64.806, 65.076, 65.462, 65.83, 65.866, 65.928, 66.678, 66.714, 67.088, 67.394, 68.068, 68.344, 68.572, 68.728, 69.234, 69.326, 69.516, 69.592, 70.49, 70.924, 71.772, 71.918, 72.286, 72.31, 72.538, 72.654, 72.828, 73.326, 74.204, 74.62, 74.694, 75.168, 75.762, 76.372, 76.492, 77.38, 77.558, 77.566, 78.034, 78.228, 78.54, 78.716, 78.88, 79.034, 80.036, 80.302, 80.548, 80.782, 82.27, 82.28, 82.704, 82.824, 82.956, 83.308, 83.386, 83.644, 83.67, 83.74, 84.098, 84.486, 84.558, 85.982, 86.032, 86.682, 86.91, 87.098, 87.894, 89.008, 89.156, 89.736, 89.752, 90.448, 90.574, 91.7, 91.79, 92.102, 92.462, 92.522, 92.754, 93.51, 94.272, 95.092, 95.588, 95.974, 95.992, 97.704, 98.034, 98.558]</span><br><span class="line">Average accuracy: 42.82</span><br><span class="line">Max accuracy: 98.56</span><br><span class="line">Min accuracy: 0.56</span><br><span class="line">Median accuracy: 34.39</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>

<p>不同模型（badnet）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/load_pdiff.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 300/300 [26:20&lt;00:00,  5.27s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.486, 0.532, 0.826, 0.83, 0.852, 0.892, 0.99, 1.024, 1.186, 1.236, 1.296, 1.31, 1.338, 1.436, 1.516, 1.644, 1.662, 1.678, 1.79, 1.806, 1.942, 2.08, 2.304, 2.316, 2.326, 2.354, 2.374, 2.416, 2.658, 2.728, 2.78, 2.818, 2.974, 3.032, 3.034, 3.038, 3.048, 3.05, 3.106, 3.138, 3.268, 3.328, 3.336, 3.6, 3.668, 3.712, 3.72, 3.84, 3.856, 4.014, 4.078, 4.084, 4.092, 4.092, 4.104, 4.234, 4.342, 4.492, 4.538, 4.62, 4.62, 4.638, 4.768, 4.972, 5.126, 5.152, 5.162, 5.18, 5.21, 5.248, 5.608, 5.64, 5.686, 5.718, 5.76, 5.906, 5.998, 6.11, 6.152, 6.332, 6.362, 6.374, 6.426, 6.466, 6.588, 6.716, 6.776, 6.826, 6.944, 6.986, 7.054, 7.148, 7.158, 7.3, 7.308, 7.332, 7.37, 7.426, 7.534, 7.57, 7.606, 7.662, 7.67, 7.864, 7.96, 7.988, 8.002, 8.194, 8.264, 8.31, 8.368, 8.698, 8.966, 8.99, 9.092, 9.144, 9.144, 9.224, 9.244, 9.288, 9.31, 9.406, 9.438, 9.54, 9.622, 9.628, 9.642, 9.668, 9.728, 9.734, 9.81, 9.836, 9.87, 10.0, 10.048, 10.082, 10.206, 10.4, 10.558, 10.59, 10.656, 10.766, 10.796, 10.978, 10.996, 11.038, 11.13, 11.248, 11.288, 11.332, 11.4, 11.404, 11.428, 11.52, 11.604, 11.622, 11.66, 11.804, 11.92, 12.042, 12.072, 12.144, 12.178, 12.2, 12.252, 12.302, 12.402, 12.52, 12.656, 12.722, 12.752, 12.792, 12.796, 12.838, 12.906, 12.974, 13.054, 13.136, 13.146, 13.156, 13.19, 13.304, 13.456, 13.466, 13.536, 13.58, 13.61, 13.696, 13.704, 13.842, 13.852, 13.914, 14.024, 14.04, 14.062, 14.134, 14.184, 14.222, 14.42, 14.47, 14.578, 14.67, 14.792, 14.958, 14.968, 15.02, 15.064, 15.09, 15.102, 15.398, 15.466, 15.524, 15.712, 15.988, 16.108, 16.16, 16.31, 16.432, 16.466, 16.558, 16.562, 16.624, 16.698, 16.7, 16.728, 16.822, 16.88, 16.886, 17.212, 17.248, 17.248, 17.29, 17.384, 17.486, 17.582, 17.75, 17.852, 17.912, 17.948, 17.962, 18.072, 18.146, 18.41, 18.422, 18.662, 18.722, 18.724, 18.942, 18.974, 18.994, 19.004, 19.046, 19.268, 19.306, 19.338, 19.364, 19.41, 19.664, 19.706, 19.71, 19.848, 19.884, 19.982, 20.014, 20.282, 20.304, 20.7, 20.802, 20.912, 21.106, 21.244, 21.636, 21.718, 22.028, 22.098, 22.212, 22.53, 22.838, 22.924, 22.948, 23.044, 23.734, 23.79, 24.564, 24.716, 24.76, 24.798, 25.438, 25.454, 25.488, 25.572, 25.688, 26.852, 26.91, 27.516, 28.05, 29.412, 31.142, 33.508, 35.426]</span><br><span class="line">Average accuracy: 11.75</span><br><span class="line">Max accuracy: 35.43</span><br><span class="line">Min accuracy: 0.49</span><br><span class="line">Median accuracy: 11.37</span><br></pre></td></tr></table></figure>

<p>泛化性能有所提升，但仍然不够好，接着增加层数，试着增加泛化性能。</p>
<h3 id="尝试2-切换顺序"><a href="#尝试2-切换顺序" class="headerlink" title="尝试2 切换顺序"></a>尝试2 切换顺序</h3><p>发现train_layer的weight和bias写反了，修改一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_layer_1 = [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_2 = [<span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_3 = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>应该是问题不大的，这里仅仅测试一下，理论上，冻结梯度、保存对应层的时候，都是<code>if name in train_layer:</code>，最后替换参数的时候，也是从网络本身的层数来一层一层判断：<code>for name, pa in model.named_parameters():</code></p>
<p>这里发现一个比较奇怪的点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Epoch 2999, global step 3000: &#x27;ae_acc&#x27; reached 2.35000 (best 2.35000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=2999-ae_acc=2.3500.ckpt&#x27; as top 1</span><br><span class="line">Epoch 5999, global step 6000: &#x27;ae_acc&#x27; reached 3.69000 (best 3.69000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=5999-ae_acc=3.6900.ckpt&#x27; as top 1</span><br><span class="line">Epoch 8999, global step 9000: &#x27;ae_acc&#x27; reached 4.73000 (best 4.73000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=8999-ae_acc=4.7300.ckpt&#x27; as top 1</span><br><span class="line">Epoch 11999, global step 12000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 14999, global step 15000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 17999, global step 18000: &#x27;ae_acc&#x27; reached 5.04000 (best 5.04000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=17999-ae_acc=5.0400.ckpt&#x27; as top 1</span><br><span class="line">Epoch 20999, global step 21000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 23999, global step 24000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 26999, global step 27000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 29999, global step 30000: &#x27;ae_acc&#x27; was not in top 1</span><br><span class="line">Epoch 32999, global step 33000: &#x27;ae_acc&#x27; reached 94.30000 (best 94.30000), saving model to &#x27;outputs/cifar10/ae_ddpm_cifar100/././checkpoints/ae-epoch=32999-ae_acc=94.3000.ckpt&#x27; as top 1</span><br></pre></td></tr></table></figure>

<p>前3w轮是在训练AE，正确率都很低，但是一旦到了3w轮后，开始训练DM，正确率马上就上来了。。。</p>
<p>结果还是不行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/load_pdiff.py </span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line">100%|██████████| 300/300 [24:07&lt;00:00,  4.82s/it]</span><br><span class="line">Sorted list of accuracies: [0.554, 0.786, 0.882, 1.226, 1.226, 1.25, 1.296, 1.324, 1.396, 1.532, 1.658, 1.66, 1.704, 1.714, 1.802, 1.924, 2.066, 2.104, 2.18, 2.222, 2.344, 2.426, 2.434, 2.484, 2.572, 2.606, 2.634, 2.7, 2.792, 2.884, 2.942, 2.97, 3.028, 3.034, 3.254, 3.274, 3.286, 3.328, 3.354, 3.462, 3.542, 3.674, 3.698, 3.788, 3.87, 3.984, 4.024, 4.068, 4.088, 4.246, 4.25, 4.26, 4.262, 4.498, 4.512, 4.53, 4.632, 4.74, 4.77, 4.776, 4.834, 4.842, 4.96, 5.056, 5.124, 5.224, 5.386, 5.396, 5.412, 5.628, 5.796, 5.93, 6.046, 6.274, 6.278, 6.294, 6.318, 6.388, 6.402, 6.448, 6.558, 6.57, 6.588, 6.616, 6.656, 6.71, 6.722, 6.822, 6.872, 6.878, 6.922, 6.94, 6.986, 6.998, 7.016, 7.038, 7.074, 7.18, 7.244, 7.282, 7.346, 7.504, 7.54, 7.6, 7.612, 7.64, 7.662, 7.702, 7.712, 7.758, 7.802, 7.866, 8.024, 8.152, 8.242, 8.444, 8.494, 8.508, 8.522, 8.578, 8.61, 8.622, 8.704, 8.74, 8.742, 8.748, 8.76, 8.764, 8.772, 8.806, 8.806, 8.82, 8.904, 8.928, 8.974, 9.038, 9.092, 9.144, 9.174, 9.206, 9.224, 9.31, 9.34, 9.39, 9.406, 9.492, 9.496, 9.508, 9.574, 9.612, 9.638, 9.65, 9.756, 9.758, 9.762, 9.81, 9.818, 9.832, 9.834, 9.866, 9.888, 9.904, 9.944, 9.956, 9.958, 9.968, 9.974, 9.986, 10.0, 10.056, 10.058, 10.102, 10.14, 10.166, 10.262, 10.27, 10.3, 10.308, 10.36, 10.714, 10.714, 10.756, 10.814, 10.818, 10.826, 10.834, 10.838, 10.888, 10.906, 10.93, 10.962, 10.966, 10.968, 10.98, 11.06, 11.078, 11.088, 11.164, 11.168, 11.204, 11.242, 11.258, 11.486, 11.534, 11.542, 11.574, 11.574, 11.678, 11.7, 11.706, 11.744, 11.79, 11.794, 11.85, 11.988, 12.084, 12.122, 12.154, 12.32, 12.37, 12.386, 12.484, 12.786, 12.814, 12.842, 12.864, 12.88, 12.98, 13.126, 13.182, 13.188, 13.214, 13.236, 13.278, 13.516, 13.528, 13.546, 13.606, 13.608, 13.62, 13.722, 13.766, 14.102, 14.19, 14.25, 14.48, 14.484, 14.492, 14.668, 14.69, 14.8, 14.806, 14.876, 15.054, 15.136, 15.146, 15.208, 15.21, 15.216, 15.314, 15.338, 15.478, 15.48, 15.522, 15.626, 15.672, 15.72, 15.752, 15.88, 15.92, 16.014, 16.1, 16.166, 16.168, 16.35, 16.366, 16.37, 16.536, 16.754, 17.194, 17.252, 17.42, 17.466, 17.528, 17.584, 17.84, 18.162, 18.692, 18.852, 18.926, 18.948, 19.224, 19.698, 19.936, 20.124, 20.764, 20.84, 22.566, 22.912, 24.076]</span><br><span class="line">Average accuracy: 9.58</span><br><span class="line">Max accuracy: 24.08</span><br><span class="line">Min accuracy: 0.55</span><br><span class="line">Median accuracy: 9.62</span><br></pre></td></tr></table></figure>

<h3 id="尝试3-加入卷积层训练"><a href="#尝试3-加入卷积层训练" class="headerlink" title="尝试3 加入卷积层训练"></a>尝试3 加入卷积层训练</h3><p>这里把ResNet18的最后两层给出来：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">layer4.0.conv1.weight</span><br><span class="line">layer4.0.bn1.weight</span><br><span class="line">layer4.0.bn1.bias</span><br><span class="line">layer4.0.conv2.weight</span><br><span class="line">layer4.0.bn2.weight</span><br><span class="line">layer4.0.bn2.bias</span><br><span class="line">layer4.0.shortcut.0.weight</span><br><span class="line">layer4.0.shortcut.1.weight</span><br><span class="line">layer4.0.shortcut.1.bias</span><br><span class="line">layer4.1.conv1.weight</span><br><span class="line">layer4.1.bn1.weight</span><br><span class="line">layer4.1.bn1.bias</span><br><span class="line">layer4.1.conv2.weight</span><br><span class="line">layer4.1.bn2.weight</span><br><span class="line">layer4.1.bn2.bias</span><br><span class="line">linear.weight</span><br><span class="line">linear.bias</span><br></pre></td></tr></table></figure>

<p>先训练这几个：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">layer4.1.conv1.weight</span><br><span class="line">layer4.1.bn1.weight</span><br><span class="line">layer4.1.bn1.bias</span><br><span class="line">layer4.1.conv2.weight</span><br><span class="line">layer4.1.bn2.weight</span><br><span class="line">layer4.1.bn2.bias</span><br><span class="line">linear.weight</span><br><span class="line">linear.bias</span><br></pre></td></tr></table></figure>

<p>效果提燃很差：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">ae param shape: torch.Size([300, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line">100%|██████████| 300/300 [24:57&lt;00:00,  4.99s/it]</span><br><span class="line">Sorted list of accuracies: [0.6, 0.654, 0.69, 0.702, 0.716, 0.868, 0.878, 0.95, 1.018, 1.124, 1.208, 1.31, 1.328, 1.338, 1.458, 1.514, 1.698, 1.704, 1.902, 1.924, 2.026, 2.074, 2.162, 2.176, 2.224, 2.224, 2.228, 2.296, 2.328, 2.388, 2.414, 2.426, 2.43, 2.464, 2.472, 2.496, 2.51, 2.52, 2.52, 2.56, 2.746, 2.8, 2.834, 2.854, 2.91, 2.93, 3.038, 3.062, 3.08, 3.092, 3.136, 3.148, 3.152, 3.198, 3.232, 3.366, 3.46, 3.464, 3.468, 3.526, 3.528, 3.536, 3.57, 3.608, 3.642, 3.674, 3.68, 3.712, 3.718, 3.81, 3.88, 3.986, 4.024, 4.048, 4.116, 4.136, 4.244, 4.332, 4.342, 4.372, 4.372, 4.444, 4.538, 4.56, 4.562, 4.676, 4.732, 4.774, 4.86, 4.886, 4.928, 4.956, 4.974, 4.982, 5.008, 5.062, 5.168, 5.206, 5.238, 5.266, 5.28, 5.298, 5.414, 5.426, 5.538, 5.57, 5.574, 5.596, 5.598, 5.604, 5.728, 5.742, 5.764, 5.772, 5.884, 5.908, 5.992, 6.004, 6.114, 6.14, 6.19, 6.222, 6.222, 6.4, 6.412, 6.446, 6.54, 6.554, 6.672, 6.766, 6.84, 7.046, 7.198, 7.332, 7.49, 7.572, 7.668, 7.674, 7.722, 8.054, 8.108, 8.114, 8.162, 8.182, 8.398, 8.518, 8.546, 8.636, 8.64, 8.73, 8.734, 8.768, 8.794, 8.818, 9.006, 9.184, 9.214, 9.29, 9.304, 9.328, 9.372, 9.428, 9.428, 9.442, 9.476, 9.486, 9.496, 9.506, 9.568, 9.578, 9.77, 9.852, 9.914, 9.962, 9.992, 10.05, 10.082, 10.102, 10.116, 10.12, 10.128, 10.15, 10.184, 10.276, 10.31, 10.362, 10.386, 10.414, 10.426, 10.464, 10.488, 10.564, 10.594, 10.674, 10.712, 10.744, 10.754, 10.772, 10.822, 10.878, 10.922, 10.944, 10.966, 11.026, 11.03, 11.03, 11.032, 11.114, 11.116, 11.118, 11.12, 11.142, 11.188, 11.204, 11.276, 11.394, 11.408, 11.422, 11.492, 11.532, 11.566, 11.596, 11.608, 11.74, 11.772, 11.94, 12.006, 12.006, 12.016, 12.05, 12.14, 12.268, 12.424, 12.448, 12.48, 12.514, 12.688, 12.708, 12.75, 12.766, 12.822, 12.862, 12.924, 12.996, 13.004, 13.116, 13.128, 13.158, 13.188, 13.218, 13.25, 13.416, 13.476, 13.568, 13.616, 13.668, 13.72, 13.95, 14.014, 14.142, 14.22, 14.324, 14.418, 14.46, 14.528, 14.542, 14.686, 14.742, 14.768, 14.988, 15.5, 15.576, 16.004, 16.012, 16.278, 16.628, 16.728, 16.754, 16.802, 16.942, 17.006, 17.288, 17.29, 17.34, 17.384, 17.424, 17.524, 17.994, 18.078, 18.092, 18.118, 18.13, 18.166, 18.288, 18.57, 18.674, 18.928, 19.316, 19.704, 22.478]</span><br><span class="line">Average accuracy: 8.50</span><br><span class="line">Max accuracy: 22.48</span><br><span class="line">Min accuracy: 0.60</span><br><span class="line">Median accuracy: 8.73</span><br></pre></td></tr></table></figure>

<h3 id="尝试4-4个bn"><a href="#尝试4-4个bn" class="headerlink" title="尝试4 4个bn"></a>尝试4 4个bn</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_layer_1 = [<span class="string">&#x27;layer4.0.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.0.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.0.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.0.bn2.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_2 = [<span class="string">&#x27;layer4.0.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.0.bn2.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_3 = [<span class="string">&#x27;layer4.1.bn1.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_4 = [<span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>, <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br><span class="line">train_layer_5 = [<span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>效果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">ae param shape: torch.Size([250, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 250/250 [20:36&lt;00:00,  4.94s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.634, 0.784, 0.808, 0.916, 1.012, 1.126, 1.286, 1.322, 1.47, 1.592, 1.718, 1.756, 1.886, 2.05, 2.072, 2.098, 2.192, 2.212, 2.246, 2.254, 2.326, 2.342, 2.504, 2.6, 2.766, 2.888, 2.928, 3.008, 3.178, 3.198, 3.3, 3.438, 3.462, 3.492, 3.534, 3.642, 4.056, 4.072, 4.262, 4.516, 4.558, 4.586, 4.632, 4.776, 4.78, 4.878, 4.938, 5.014, 5.088, 5.208, 5.296, 5.548, 5.556, 5.568, 5.586, 5.644, 5.674, 5.684, 5.802, 5.804, 5.848, 5.882, 5.92, 6.0, 6.024, 6.102, 6.506, 6.544, 6.602, 6.624, 6.714, 6.748, 6.76, 6.852, 6.864, 6.932, 7.036, 7.116, 7.128, 7.204, 7.25, 7.43, 7.45, 7.492, 7.514, 7.626, 7.632, 7.69, 7.702, 8.018, 8.068, 8.138, 8.194, 8.194, 8.252, 8.444, 8.444, 8.448, 8.456, 8.466, 8.562, 8.624, 8.65, 8.668, 8.714, 8.728, 8.752, 9.022, 9.028, 9.124, 9.136, 9.166, 9.25, 9.258, 9.276, 9.376, 9.388, 9.438, 9.582, 9.666, 9.7, 9.71, 9.734, 9.774, 9.784, 9.828, 9.832, 9.832, 9.874, 9.886, 9.898, 9.964, 10.052, 10.106, 10.13, 10.13, 10.144, 10.202, 10.236, 10.258, 10.268, 10.296, 10.302, 10.344, 10.346, 10.362, 10.366, 10.398, 10.426, 10.478, 10.514, 10.558, 10.602, 10.638, 10.656, 10.682, 10.812, 10.826, 10.83, 10.844, 10.866, 10.87, 10.942, 10.954, 11.024, 11.058, 11.08, 11.202, 11.23, 11.37, 11.508, 11.566, 11.642, 11.878, 12.166, 12.252, 12.442, 12.442, 12.472, 12.56, 12.688, 12.762, 12.852, 13.114, 13.218, 13.412, 13.532, 13.558, 13.574, 13.704, 13.722, 13.804, 13.908, 13.972, 14.414, 14.448, 14.67, 14.676, 14.774, 14.778, 14.962, 15.248, 15.254, 15.304, 15.356, 15.426, 15.564, 15.754, 15.826, 15.856, 15.88, 15.978, 15.982, 16.142, 16.318, 16.584, 16.68, 17.06, 17.15, 17.286, 17.656, 17.866, 18.176, 18.37, 18.596, 18.846, 18.898, 19.226, 19.384, 19.396, 19.468, 19.528, 19.552, 19.692, 19.806, 19.952, 19.964, 20.044, 20.088, 20.174, 20.388, 22.354, 22.43, 22.706, 23.08, 23.254, 23.296, 24.044, 26.122, 26.376]</span><br><span class="line">Average accuracy: 10.11</span><br><span class="line">Max accuracy: 26.38</span><br><span class="line">Min accuracy: 0.63</span><br><span class="line">Median accuracy: 9.81</span><br></pre></td></tr></table></figure>

<p>不行，泛化性没有提升。</p>
<h3 id="尝试5-训练-重训练"><a href="#尝试5-训练-重训练" class="headerlink" title="尝试5 训练-重训练"></a>尝试5 训练-重训练</h3><p>先训练100轮，得到一个不错的模型，然后将模型的第一层的参数重新随机初始化，继续训练n轮，直到模型正确率达到阈值$\tau$​，将这个模型训练n轮，收集FC层的参数，再重新初始化第一层的参数，如此循环下去。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">ae param shape: torch.Size([200, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line">100%|██████████| 200/200 [16:35&lt;00:00,  4.98s/it]</span><br><span class="line">Sorted list of accuracies: [0.494, 0.768, 1.67, 1.95, 2.124, 2.188, 2.38, 2.388, 2.456, 2.47, 2.564, 2.722, 2.81, 2.886, 2.948, 2.996, 3.08, 3.13, 3.166, 3.254, 3.738, 3.914, 4.008, 4.032, 4.428, 4.462, 4.648, 4.738, 4.822, 4.838, 4.874, 4.91, 4.944, 5.124, 5.262, 5.502, 5.636, 5.64, 5.67, 5.848, 5.882, 6.164, 6.188, 6.342, 6.346, 6.526, 6.556, 6.684, 6.786, 6.794, 6.812, 6.83, 6.85, 6.946, 7.262, 7.388, 7.44, 7.504, 7.542, 7.552, 7.792, 7.866, 7.952, 8.086, 8.176, 8.27, 8.434, 8.532, 8.69, 8.732, 8.87, 8.882, 8.94, 8.954, 9.034, 9.12, 9.294, 9.332, 9.354, 9.374, 9.442, 9.454, 9.458, 9.584, 9.596, 9.618, 9.636, 9.686, 9.796, 9.988, 10.186, 10.314, 10.486, 10.57, 10.58, 10.64, 10.65, 10.782, 11.04, 11.066, 11.094, 11.1, 11.126, 11.126, 11.178, 11.184, 11.25, 11.292, 11.314, 11.356, 11.402, 11.508, 11.608, 11.612, 11.62, 11.626, 11.638, 11.702, 11.898, 11.964, 12.03, 12.122, 12.282, 12.344, 12.36, 12.412, 12.532, 12.63, 12.764, 12.78, 12.83, 12.85, 12.966, 13.016, 13.07, 13.174, 13.25, 13.446, 13.702, 13.762, 13.79, 13.816, 13.838, 14.232, 14.236, 14.3, 14.372, 14.396, 14.446, 14.766, 14.844, 14.862, 15.024, 15.412, 15.456, 15.734, 15.846, 15.858, 16.028, 16.142, 16.258, 16.328, 16.546, 16.66, 16.722, 17.142, 17.246, 17.26, 17.314, 17.326, 17.536, 17.712, 17.8, 17.812, 18.058, 18.058, 18.158, 18.226, 18.286, 18.308, 18.438, 18.538, 19.256, 19.87, 20.006, 21.064, 21.558, 22.054, 22.104, 22.666, 22.688, 23.956, 23.974, 25.298, 25.642, 25.644, 25.734, 26.37, 28.938, 31.89]</span><br><span class="line">Average accuracy: 11.27</span><br><span class="line">Max accuracy: 31.89</span><br><span class="line">Min accuracy: 0.49</span><br><span class="line">Median accuracy: 11.08</span><br></pre></td></tr></table></figure>

<h3 id="尝试6-卷积层重训练"><a href="#尝试6-卷积层重训练" class="headerlink" title="尝试6 卷积层重训练"></a>尝试6 卷积层重训练</h3><p>参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init_layer = [&#x27;conv1.weight&#x27;,&#x27;layer1.0.conv1.weight&#x27;, &#x27;layer1.0.conv2.weight&#x27;, &#x27;layer1.1.conv1.weight&#x27;,&#x27;layer1.1.conv2.weight&#x27;,&#x27;linear.weight&#x27;, &#x27;linear.bias&#x27;]</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(pdiff) chengyiqiu@server:~/code/diffusion/Diffuse-Backdoor-Parameters/tools$ python eval_pdiff.py</span><br><span class="line">ae param shape: torch.Size([200, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|███████████████████████████████████████████████████████████| 200/200 [16:05&lt;00:00,  4.83s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.914, 1.544, 1.632, 1.868, 1.888, 2.2, 2.378, 2.44, 2.624, 2.658, 2.806, 2.884, 3.412, 3.672, 3.852, 3.876, 4.038, 4.624, 4.628, 4.94, 4.978, 5.212, 5.344, 5.35, 5.424, 5.644, 5.706, 5.912, 6.08, 6.088, 6.32, 6.934, 7.166, 7.32, 7.386, 7.404, 7.426, 7.482, 7.74, 7.882, 8.1, 8.164, 8.388, 8.404, 8.428, 8.52, 8.678, 8.832, 8.956, 9.032, 9.194, 9.228, 9.422, 9.508, 9.536, 9.556, 9.562, 9.57, 9.628, 9.634, 9.816, 9.836, 9.91, 9.916, 9.94, 9.942, 9.962, 10.0, 10.028, 10.05, 10.084, 10.136, 10.144, 10.144, 10.258, 10.264, 10.334, 10.39, 10.438, 10.468, 10.48, 10.496, 10.516, 10.52, 10.65, 10.674, 10.678, 10.69, 10.748, 10.752, 10.942, 11.234, 11.282, 11.422, 11.488, 11.658, 11.698, 11.784, 11.79, 11.79, 11.792, 11.92, 11.944, 11.95, 11.996, 12.06, 12.078, 12.222, 12.32, 12.402, 12.442, 12.566, 12.574, 12.598, 12.696, 12.756, 12.836, 12.836, 12.922, 12.96, 12.972, 13.01, 13.092, 13.412, 13.48, 13.55, 13.658, 13.77, 13.776, 13.932, 14.254, 14.262, 14.296, 14.326, 14.39, 14.392, 14.456, 14.526, 14.72, 14.79, 14.868, 14.962, 15.016, 15.018, 15.092, 15.116, 15.2, 15.206, 15.3, 15.35, 15.404, 15.468, 15.674, 16.334, 16.372, 16.378, 16.406, 16.458, 16.698, 16.71, 16.798, 17.088, 17.184, 17.252, 17.684, 17.908, 17.958, 18.242, 18.248, 18.314, 18.632, 18.67, 18.71, 18.716, 18.73, 19.206, 19.666, 19.67, 19.724, 19.762, 20.088, 20.242, 20.512, 20.604, 20.66, 20.912, 22.172, 22.488, 22.868, 22.97, 23.476, 25.878, 25.972, 26.558, 27.16, 29.946, 31.72, 31.974, 32.288, 32.566]</span><br><span class="line">Average accuracy: 12.50</span><br><span class="line">Max accuracy: 32.57</span><br><span class="line">Min accuracy: 0.91</span><br><span class="line">Median accuracy: 11.79</span><br></pre></td></tr></table></figure>

<p>尝试7</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">init_layer = [<span class="string">&#x27;conv1.weight&#x27;</span>, <span class="string">&#x27;bn1.weight&#x27;</span>, <span class="string">&#x27;bn1.bias&#x27;</span>, <span class="string">&#x27;layer1.0.conv1.weight&#x27;</span>, <span class="string">&#x27;layer1.0.bn1.weight&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;layer1.0.bn1.bias&#x27;</span>, <span class="string">&#x27;layer4.1.conv2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.weight&#x27;</span>, <span class="string">&#x27;layer4.1.bn2.bias&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;linear.weight&#x27;</span>, <span class="string">&#x27;linear.bias&#x27;</span>, ]</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/bin/python /home/chengyiqiu/code/diffusion/Diffuse-Backdoor-Parameters/tools/eval_pdiff.py </span><br><span class="line">/home/chengyiqiu/miniconda3/envs/pdiff/lib/python3.8/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input&#x27;s size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False</span><br><span class="line">  warnings.warn(f&quot;input&#x27;s size at dim=&#123;feature_dim&#125; does not match num_features. &quot;</span><br><span class="line">ae param shape: torch.Size([200, 5130])</span><br><span class="line">Files already downloaded and verified</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|██████████| 200/200 [17:28&lt;00:00,  5.24s/it]</span></span><br><span class="line">Sorted list of accuracies: [0.63, 0.888, 1.024, 1.078, 1.146, 1.17, 1.308, 1.386, 1.444, 1.476, 1.626, 1.828, 1.9, 2.0, 2.012, 2.168, 2.268, 2.332, 2.576, 2.638, 2.678, 2.778, 3.026, 3.028, 3.138, 3.296, 3.32, 3.598, 3.622, 3.832, 4.148, 4.162, 4.52, 4.536, 4.992, 5.018, 5.084, 5.1, 5.11, 5.338, 5.572, 5.744, 5.762, 5.772, 5.864, 5.962, 5.986, 6.116, 6.358, 6.368, 6.476, 6.546, 7.022, 7.142, 7.254, 7.3, 7.452, 7.458, 7.478, 7.522, 7.57, 7.644, 7.7, 7.77, 7.798, 7.824, 7.842, 8.414, 8.506, 8.548, 8.612, 8.636, 8.686, 8.734, 8.862, 8.862, 8.984, 8.992, 9.098, 9.136, 9.14, 9.142, 9.206, 9.312, 9.326, 9.354, 9.562, 9.568, 9.674, 9.712, 9.716, 9.776, 9.79, 9.942, 9.968, 10.0, 10.014, 10.02, 10.036, 10.14, 10.2, 10.25, 10.266, 10.296, 10.324, 10.354, 10.372, 10.39, 10.412, 10.43, 10.462, 10.532, 10.596, 10.616, 10.702, 10.72, 10.734, 10.746, 10.746, 10.76, 10.944, 10.976, 10.978, 11.018, 11.03, 11.044, 11.128, 11.152, 11.226, 11.236, 11.238, 11.398, 11.458, 11.58, 11.594, 11.676, 11.808, 11.87, 11.874, 12.148, 12.23, 12.36, 12.426, 12.51, 12.644, 12.754, 12.772, 12.85, 12.862, 12.902, 12.966, 12.988, 13.122, 13.294, 13.378, 13.458, 14.048, 14.11, 14.234, 14.454, 14.502, 14.636, 14.74, 14.804, 14.872, 14.96, 15.04, 15.32, 15.604, 15.892, 16.058, 16.114, 16.35, 16.674, 16.768, 17.258, 17.414, 17.752, 17.778, 18.206, 18.248, 18.256, 18.296, 18.374, 18.438, 18.674, 18.744, 19.124, 20.658, 20.784, 20.854, 21.198, 21.33, 22.388, 22.688, 22.874, 24.144, 25.728, 27.32, 30.836]</span><br><span class="line">Average accuracy: 10.28</span><br><span class="line">Max accuracy: 30.84</span><br><span class="line">Min accuracy: 0.63</span><br><span class="line">Median accuracy: 10.17</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/24/Neural-Network-Diffusion/" data-id="cm9l0ch1i002bmbnn8bcb95eg" data-title="Neural_Network_Diffusion" class="article-share-link">Share</a>
      
      
      
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a></li></ul>


    </footer>
  </div>
  
    
  <nav id="article-nav" class="wow fadeInUp">
    
      <div class="article-nav-link-wrap article-nav-link-left">
        
          
          
            <img data-src="/covers/IMG_2583 2.PNG" data-sizes="auto" alt="High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models" class="lazyload">
          
        
        <a href="/2024/03/24/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/"></a>
        <div class="article-nav-caption">Newer</div>
        <h3 class="article-nav-title">
          
            High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models
          
        </h3>
      </div>
    
    
    <div class="article-nav-link-wrap article-nav-link-right">
      
        
        
          <img data-src="/covers/IMG_2581.JPG" data-sizes="auto" alt="Distilling_Cognitive_Backdoor_Patterns_within_an_Image" class="lazyload">
        
      
      <a href="/2024/03/21/Distilling-Cognitive-Backdoor-Patterns-within-an-Image/"></a>
      <div class="article-nav-caption">Older</div>
      <h3 class="article-nav-title">
        
          Distilling_Cognitive_Backdoor_Patterns_within_an_Image
        
      </h3>
    </div>
    
  </nav>


  
</article>






</section>
          
            <aside id="sidebar">
  <div class="sidebar-wrap wow fadeInRight wrap-sticky">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">Contents</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%89%A9%E6%95%A3"><span class="toc-number">1.</span> <span class="toc-text">神经网络扩散</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">初步了解扩散模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">整体架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E8%87%AA%E5%8A%A8%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">1.3.</span> <span class="toc-text">参数自动编码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%94%9F%E6%88%90"><span class="toc-number">1.4.</span> <span class="toc-text">参数生成</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">2.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE"><span class="toc-number">2.1.</span> <span class="toc-text">设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB"><span class="toc-number">2.2.</span> <span class="toc-text">代码阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.1.</span> <span class="toc-text">准备训练数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E8%AE%BA"><span class="toc-number">2.3.</span> <span class="toc-text">实验结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95"><span class="toc-number">2.4.</span> <span class="toc-text">问题记录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B7%E5%8C%96%E5%8F%82%E6%95%B0%E4%BB%A5%E5%A2%9E%E5%BC%BA%E6%B3%9B%E5%8C%96%E6%80%A7%E8%83%BD"><span class="toc-number">2.5.</span> <span class="toc-text">多样化参数以增强泛化性能</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%951-%E6%85%A2%E6%85%A2%E5%87%8F%E8%AE%AD%E7%BB%83%E7%9A%84layer"><span class="toc-number">2.5.1.</span> <span class="toc-text">尝试1 慢慢减训练的layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%952-%E5%88%87%E6%8D%A2%E9%A1%BA%E5%BA%8F"><span class="toc-number">2.5.2.</span> <span class="toc-text">尝试2 切换顺序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%953-%E5%8A%A0%E5%85%A5%E5%8D%B7%E7%A7%AF%E5%B1%82%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.3.</span> <span class="toc-text">尝试3 加入卷积层训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%954-4%E4%B8%AAbn"><span class="toc-number">2.5.4.</span> <span class="toc-text">尝试4 4个bn</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%955-%E8%AE%AD%E7%BB%83-%E9%87%8D%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.5.</span> <span class="toc-text">尝试5 训练-重训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%956-%E5%8D%B7%E7%A7%AF%E5%B1%82%E9%87%8D%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.6.</span> <span class="toc-text">尝试6 卷积层重训练</span></a></li></ol></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/rabbit_1.jpg" data-sizes="auto" alt="chengyiqiu" class="lazyload">
  <div class="sidebar-author-name">chengyiqiu</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Posts</div>
    <div class="sidebar-state-number">65</div>
  </div>
  <div class="sidebar-state-category">
    <div>Categories</div>
    <div class="sidebar-state-number">13</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tags</div>
    <div class="sidebar-state-number">17</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/" aria-label="Home"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Home</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/archives" aria-label="Archives"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Archives</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/about" aria-label="About"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">About</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/friend" aria-label="Friend"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Friend</div>
    </div>
  
</div>
</div>
    
    
      <div class="sidebar-btn-wrapper" style="position:static">
        <div class="sidebar-toc-btn current"></div>
        <div class="sidebar-common-btn"></div>
      </div>
    
  </div>

  
</aside>

          
        </div>
        <footer id="footer" class="wow fadeInUp">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div class="outer">
    <div id="footer-info" class="inner">
      
      <div>
        <span class="icon-copyright"></span>
        2020-2025
        <span class="footer-info-sep"></span>
        chengyiqiu
      </div>
      
        <div>
          Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
          Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
        </div>
      
      
        <div>
          <span class="icon-brush"></span>
          129.6k
          &nbsp;|&nbsp;
          <span class="icon-coffee"></span>
          08:55
        </div>
      
      
        <div>
          <span class="icon-eye"></span>
          <span id="busuanzi_container_site_pv">Number of visits&nbsp;<span id="busuanzi_value_site_pv"></span></span>
          &nbsp;|&nbsp;
          <span class="icon-user"></span>
          <span id="busuanzi_container_site_uv">Number of visitors&nbsp;<span id="busuanzi_value_site_uv"></span></span>
        </div>
      
    </div>
  </div>
</footer>

        <div class="sidebar-top">
          <img src="/images/taichi.png" height="50" width="50" />
          <div class="arrow-up"></div>
        </div>
        <div id="mask"></div>
      </div>
      <nav id="mobile-nav">
  <div class="sidebar-wrap">
    
      <div class="sidebar-toc-sidebar"><div class="sidebar-toc">
  <h3 class="toc-title">Contents</h3>
  <div class="sidebar-toc-wrapper toc-div-class" >
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%89%A9%E6%95%A3"><span class="toc-number">1.</span> <span class="toc-text">神经网络扩散</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">初步了解扩散模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">整体架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E8%87%AA%E5%8A%A8%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">1.3.</span> <span class="toc-text">参数自动编码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%94%9F%E6%88%90"><span class="toc-number">1.4.</span> <span class="toc-text">参数生成</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">2.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE"><span class="toc-number">2.1.</span> <span class="toc-text">设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB"><span class="toc-number">2.2.</span> <span class="toc-text">代码阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.1.</span> <span class="toc-text">准备训练数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E8%AE%BA"><span class="toc-number">2.3.</span> <span class="toc-text">实验结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95"><span class="toc-number">2.4.</span> <span class="toc-text">问题记录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B7%E5%8C%96%E5%8F%82%E6%95%B0%E4%BB%A5%E5%A2%9E%E5%BC%BA%E6%B3%9B%E5%8C%96%E6%80%A7%E8%83%BD"><span class="toc-number">2.5.</span> <span class="toc-text">多样化参数以增强泛化性能</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%951-%E6%85%A2%E6%85%A2%E5%87%8F%E8%AE%AD%E7%BB%83%E7%9A%84layer"><span class="toc-number">2.5.1.</span> <span class="toc-text">尝试1 慢慢减训练的layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%952-%E5%88%87%E6%8D%A2%E9%A1%BA%E5%BA%8F"><span class="toc-number">2.5.2.</span> <span class="toc-text">尝试2 切换顺序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%953-%E5%8A%A0%E5%85%A5%E5%8D%B7%E7%A7%AF%E5%B1%82%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.3.</span> <span class="toc-text">尝试3 加入卷积层训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%954-4%E4%B8%AAbn"><span class="toc-number">2.5.4.</span> <span class="toc-text">尝试4 4个bn</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%955-%E8%AE%AD%E7%BB%83-%E9%87%8D%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.5.</span> <span class="toc-text">尝试5 训练-重训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%956-%E5%8D%B7%E7%A7%AF%E5%B1%82%E9%87%8D%E8%AE%AD%E7%BB%83"><span class="toc-number">2.5.6.</span> <span class="toc-text">尝试6 卷积层重训练</span></a></li></ol></li></ol></li></ol>
      
  </div>
</div>
</div>
      <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/rabbit_1.jpg" data-sizes="auto" alt="chengyiqiu" class="lazyload">
  <div class="sidebar-author-name">chengyiqiu</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Posts</div>
    <div class="sidebar-state-number">65</div>
  </div>
  <div class="sidebar-state-category">
    <div>Categories</div>
    <div class="sidebar-state-number">13</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tags</div>
    <div class="sidebar-state-number">17</div>
  </div>
</div>
<div class="sidebar-social">
  
</div>
<div class="sidebar-menu">
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/" aria-label="Home"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Home</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/archives" aria-label="Archives"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Archives</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/about" aria-label="About"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">About</div>
    </div>
  
    <div class="sidebar-menu-link-wrap">
      <a class="sidebar-menu-link-dummy" href="/friend" aria-label="Friend"></a>
      <span class="sidebar-menu-icon"></span>
      <div class="sidebar-menu-link">Friend</div>
    </div>
  
</div>
</div>
    
  </div>
  
    <div class="sidebar-btn-wrapper">
      <div class="sidebar-toc-btn current"></div>
      <div class="sidebar-common-btn"></div>
    </div>
  
</nav>

    </div>
    <div class="site-search">
      <div class="reimu-popup popup">
        <div class="reimu-search">
          <span class="reimu-search-input-icon"></span>
          <div class="reimu-search-input" id="reimu-search-input"></div>
        </div>
        <div class="reimu-results">
          <div id="reimu-stats"></div>
          <div id="reimu-hits"></div>
          <div id="reimu-pagination" class="reimu-pagination"></div>
        </div>
        <span class="popup-btn-close"></span>
      </div>
    </div>
    
<script src="https://npm.webcache.cn/jquery@3.7.1/dist/jquery.min.js"></script>


<script src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js"></script>



  
<script src="https://npm.webcache.cn/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" defer></script>



  
<script src="https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js" async></script>






<script src="/js/pjax_script.js" data-pjax></script>

















  
<script src="https://npm.webcache.cn/mouse-firework@0.0.4/dist/index.umd.js"></script>

  <script>
    firework(JSON.parse('{"excludeElements":["a","button"],"particles":[{"shape":"circle","move":["emit"],"easing":"easeOutExpo","colors":["#ff5252","#ff7c7c","#ffafaf","#ffd0d0"],"number":20,"duration":[1200,1800],"shapeOptions":{"radius":[16,32],"alpha":[0.3,0.5]}},{"shape":"circle","move":["diffuse"],"easing":"easeOutExpo","colors":["#ff0000"],"number":1,"duration":[1200,1800],"shapeOptions":{"radius":20,"alpha":[0.2,0.5],"lineWidth":6}}]}'))
  </script>







<script src="/js/script.js"></script>



  <script>
    console.log(String.raw`%c 
 ______     ______     __     __    __     __  __    
/\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
\ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
 \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
  \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                  
`,'color: #ff5252;')
    console.log('%c Theme.Reimu v' + '0.1.2' + ' %c https://github.com/D-Sketon/hexo-theme-reimu ', 'color: white; background: #ff5252; padding:5px 0;', 'padding:4px;border:1px solid #ff5252;')
  </script>
  

  <!-- hexo injector body_end start -->
<script src="/js/insert_highlight.js" data-pjax></script>
<!-- hexo injector body_end end --></body>
  </html>

